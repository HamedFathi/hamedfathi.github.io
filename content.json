{"posts":[{"title":"A Professional ASP.NET Core API - Background Task","text":"In ASP.NET Core, background tasks can be implemented as hosted services. A hosted service is a class with background task logic that implements the IHostedService interface. This topic provides three hosted service examples: Background task that runs on a timer. Hosted service that activates a scoped service. The scoped service can use dependency injection (DI). Queued background tasks that run sequentially. IHostedService interfaceThe IHostedService interface defines two methods for objects that are managed by the host: StartAsync(CancellationToken): StartAsync contains the logic to start the background task. StartAsync is called before: The app’s request processing pipeline is configured (Startup.Configure). The server is started and IApplicationLifetime.ApplicationStarted is triggered.The default behavior can be changed so that the hosted service’s StartAsync runs after the app’s pipeline has been configured and ApplicationStarted is called. StopAsync(CancellationToken): Triggered when the host is performing a graceful shutdown. StopAsync contains the logic to end the background task. Implement IDisposable and finalizers (destructors) to dispose of any unmanaged resources. The cancellation token has a default five second timeout to indicate that the shutdown process should no longer be graceful. When cancellation is requested on the token: Any remaining background operations that the app is performing should be aborted. Any methods called in StopAsync should return promptly. However, tasks aren’t abandoned after cancellation is requested—the caller awaits all tasks to complete. If the app shuts down unexpectedly, StopAsync might not be called. Therefore, any methods called or operations conducted in StopAsync might not occur. 1234567891011121314using Microsoft.Extensions.Hosting;using System.Threading;using System.Threading.Tasks;public class SampleHostedService : IHostedService{ public Task StartAsync(CancellationToken cancellationToken) { } public Task StopAsync(CancellationToken cancellationToken) { }} BackgroundService base classBackgroundService is a base class for implementing a long running IHostedService. ExecuteAsync(CancellationToken) is called to run the background service. The implementation returns a Task that represents the entire lifetime of the background service. No further services are started until ExecuteAsync becomes asynchronous, such as by calling await. Avoid performing long, blocking initialization work in ExecuteAsync. The host blocks in StopAsync(CancellationToken) waiting for ExecuteAsync to complete. The cancellation token is triggered when IHostedService.StopAsync is called. Your implementation of ExecuteAsync should finish promptly when the cancellation token is fired in order to gracefully shut down the service. Otherwise, the service ungracefully shuts down at the shutdown timeout. For more information, see the IHostedService interface section. 1234567891011using Microsoft.Extensions.Hosting;using System.Threading;using System.Threading.Tasks;public class SampleBackgroundService : BackgroundService{ protected override async Task ExecuteAsync(CancellationToken cancellationToken) { }} Background task that runs on a timerA timed background task makes use of the System.Threading.Timer class. The timer triggers the task’s DoWork method. The timer is disabled on StopAsync and disposed when the service container is disposed on Dispose: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152using Microsoft.Extensions.Hosting;using Microsoft.Extensions.Logging;using System;using System.Threading;using System.Threading.Tasks;namespace TaskBg.Controllers{ public class TimedHostedService : IHostedService, IDisposable { private int executionCount = 0; private readonly ILogger&lt;TimedHostedService&gt; _logger; private Timer _timer; public TimedHostedService(ILogger&lt;TimedHostedService&gt; logger) { _logger = logger; } public Task StartAsync(CancellationToken stoppingToken) { _logger.LogInformation(&quot;Timed Hosted Service running.&quot;); _timer = new Timer(DoWork, null, TimeSpan.Zero, TimeSpan.FromSeconds(5)); return Task.CompletedTask; } private void DoWork(object state) { var count = Interlocked.Increment(ref executionCount); _logger.LogInformation( &quot;Timed Hosted Service is working. Count: {Count}&quot;, count); } public Task StopAsync(CancellationToken stoppingToken) { _logger.LogInformation(&quot;Timed Hosted Service is stopping.&quot;); _timer?.Change(Timeout.Infinite, 0); return Task.CompletedTask; } public void Dispose() { _timer?.Dispose(); } }} The Timer doesn’t wait for previous executions of DoWork to finish, so the approach shown might not be suitable for every scenario. Interlocked.Increment is used to increment the execution counter as an atomic operation, which ensures that multiple threads don’t update executionCount concurrently. The service is registered in: 1234567891011121314151617181920212223242526272829303132// Startup.ConfigureServicespublic void ConfigureServices(IServiceCollection services){ services.AddControllers(); // HERE services.AddHostedService&lt;TimedHostedService&gt;();}// OR// Program.cspublic class Program{ public static void Main(string[] args) { CreateHostBuilder(args).Build().Run(); } public static IHostBuilder CreateHostBuilder(string[] args) =&gt; Host.CreateDefaultBuilder(args) .ConfigureWebHostDefaults(webBuilder =&gt; { webBuilder.UseStartup&lt;Startup&gt;(); }) .ConfigureServices(services =&gt; { // HERE services.AddHostedService&lt;VideosWatcher&gt;(); });} Consuming a scoped service in a background taskTo use scoped services within a BackgroundService, create a scope. No scope is created for a hosted service by default. The scoped background task service contains the background task’s logic. In the following example: The service is asynchronous. The DoWork method returns a Task. For demonstration purposes, a delay of ten seconds is awaited in the DoWork method.An ILogger is injected into the service. 12345678910111213141516171819202122232425262728internal interface IScopedProcessingService{ Task DoWork(CancellationToken stoppingToken);}internal class ScopedProcessingService : IScopedProcessingService{ private int executionCount = 0; private readonly ILogger _logger; public ScopedProcessingService(ILogger&lt;ScopedProcessingService&gt; logger) { _logger = logger; } public async Task DoWork(CancellationToken stoppingToken) { while (!stoppingToken.IsCancellationRequested) { executionCount++; _logger.LogInformation( &quot;Scoped Processing Service is working. Count: {Count}&quot;, executionCount); await Task.Delay(10000, stoppingToken); } }} The hosted service creates a scope to resolve the scoped background task service to call its DoWork method. DoWork returns a Task, which is awaited in ExecuteAsync: 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class ConsumeScopedServiceHostedService : BackgroundService{ private readonly ILogger&lt;ConsumeScopedServiceHostedService&gt; _logger; public ConsumeScopedServiceHostedService(IServiceProvider services, ILogger&lt;ConsumeScopedServiceHostedService&gt; logger) { Services = services; _logger = logger; } public IServiceProvider Services { get; } protected override async Task ExecuteAsync(CancellationToken stoppingToken) { _logger.LogInformation( &quot;Consume Scoped Service Hosted Service running.&quot;); await DoWork(stoppingToken); } private async Task DoWork(CancellationToken stoppingToken) { _logger.LogInformation( &quot;Consume Scoped Service Hosted Service is working.&quot;); using (var scope = Services.CreateScope()) { var scopedProcessingService = scope.ServiceProvider .GetRequiredService&lt;IScopedProcessingService&gt;(); await scopedProcessingService.DoWork(stoppingToken); } } public override async Task StopAsync(CancellationToken stoppingToken) { _logger.LogInformation( &quot;Consume Scoped Service Hosted Service is stopping.&quot;); await base.StopAsync(stoppingToken); }} The services are registered in IHostBuilder.ConfigureServices (Program.cs). The hosted service is registered with the AddHostedService extension method: 123456// Program.IHostBuilder.ConfigureServices// Or// // Startup.ConfigureServicesservices.AddHostedService&lt;ConsumeScopedServiceHostedService&gt;();services.AddScoped&lt;IScopedProcessingService, ScopedProcessingService&gt;(); Queued background tasksA background task queue is based on the .NET 4.x QueueBackgroundWorkItem: 1234567891011121314151617181920212223242526272829303132333435public interface IBackgroundTaskQueue{ void QueueBackgroundWorkItem(Func&lt;CancellationToken, Task&gt; workItem); Task&lt;Func&lt;CancellationToken, Task&gt;&gt; DequeueAsync( CancellationToken cancellationToken);}public class BackgroundTaskQueue : IBackgroundTaskQueue{ private ConcurrentQueue&lt;Func&lt;CancellationToken, Task&gt;&gt; _workItems = new ConcurrentQueue&lt;Func&lt;CancellationToken, Task&gt;&gt;(); private SemaphoreSlim _signal = new SemaphoreSlim(0); public void QueueBackgroundWorkItem( Func&lt;CancellationToken, Task&gt; workItem) { if (workItem == null) { throw new ArgumentNullException(nameof(workItem)); } _workItems.Enqueue(workItem); _signal.Release(); } public async Task&lt;Func&lt;CancellationToken, Task&gt;&gt; DequeueAsync( CancellationToken cancellationToken) { await _signal.WaitAsync(cancellationToken); _workItems.TryDequeue(out var workItem); return workItem; }} In the following QueueHostedService example: The BackgroundProcessing method returns a Task, which is awaited in ExecuteAsync.Background tasks in the queue are dequeued and executed in BackgroundProcessing.Work items are awaited before the service stops in StopAsync. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class QueuedHostedService : BackgroundService{ private readonly ILogger&lt;QueuedHostedService&gt; _logger; public QueuedHostedService(IBackgroundTaskQueue taskQueue, ILogger&lt;QueuedHostedService&gt; logger) { TaskQueue = taskQueue; _logger = logger; } public IBackgroundTaskQueue TaskQueue { get; } protected override async Task ExecuteAsync(CancellationToken stoppingToken) { _logger.LogInformation( $&quot;Queued Hosted Service is running.{Environment.NewLine}&quot; + $&quot;{Environment.NewLine}Tap W to add a work item to the &quot; + $&quot;background queue.{Environment.NewLine}&quot;); await BackgroundProcessing(stoppingToken); } private async Task BackgroundProcessing(CancellationToken stoppingToken) { while (!stoppingToken.IsCancellationRequested) { var workItem = await TaskQueue.DequeueAsync(stoppingToken); try { await workItem(stoppingToken); } catch (Exception ex) { _logger.LogError(ex, &quot;Error occurred executing {WorkItem}.&quot;, nameof(workItem)); } } } public override async Task StopAsync(CancellationToken stoppingToken) { _logger.LogInformation(&quot;Queued Hosted Service is stopping.&quot;); await base.StopAsync(stoppingToken); }} A MonitorLoop service handles enqueuing tasks for the hosted service whenever the w key is selected on an input device: The IBackgroundTaskQueue is injected into the MonitorLoop service. IBackgroundTaskQueue.QueueBackgroundWorkItem is called to enqueue a work item. The work item simulates a long-running background task: Three 5-second delays are executed (Task.Delay). A try-catch statement traps OperationCanceledException if the task is cancelled. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public class MonitorLoop{ private readonly IBackgroundTaskQueue _taskQueue; private readonly ILogger _logger; private readonly CancellationToken _cancellationToken; public MonitorLoop(IBackgroundTaskQueue taskQueue, ILogger&lt;MonitorLoop&gt; logger, IHostApplicationLifetime applicationLifetime) { _taskQueue = taskQueue; _logger = logger; _cancellationToken = applicationLifetime.ApplicationStopping; } public void StartMonitorLoop() { _logger.LogInformation(&quot;Monitor Loop is starting.&quot;); // Run a console user input loop in a background thread Task.Run(() =&gt; Monitor()); } public void Monitor() { while (!_cancellationToken.IsCancellationRequested) { var keyStroke = Console.ReadKey(); if (keyStroke.Key == ConsoleKey.W) { // Enqueue a background work item _taskQueue.QueueBackgroundWorkItem(async token =&gt; { // Simulate three 5-second tasks to complete // for each enqueued work item int delayLoop = 0; var guid = Guid.NewGuid().ToString(); _logger.LogInformation( &quot;Queued Background Task {Guid} is starting.&quot;, guid); while (!token.IsCancellationRequested &amp;&amp; delayLoop &lt; 3) { try { await Task.Delay(TimeSpan.FromSeconds(5), token); } catch (OperationCanceledException) { // Prevent throwing if the Delay is cancelled } delayLoop++; _logger.LogInformation( &quot;Queued Background Task {Guid} is running. &quot; + &quot;{DelayLoop}/3&quot;, guid, delayLoop); } if (delayLoop == 3) { _logger.LogInformation( &quot;Queued Background Task {Guid} is complete.&quot;, guid); } else { _logger.LogInformation( &quot;Queued Background Task {Guid} was cancelled.&quot;, guid); } }); } } }} The services are registered in IHostBuilder.ConfigureServices (Program.cs). The hosted service is registered with the AddHostedService extension method: 1234567// Program.IHostBuilder.ConfigureServices// Or// // Startup.ConfigureServicesservices.AddSingleton&lt;MonitorLoop&gt;();services.AddHostedService&lt;QueuedHostedService&gt;();services.AddSingleton&lt;IBackgroundTaskQueue, BackgroundTaskQueue&gt;(); MonitorLoop is started in Program.Main: 12var monitorLoop = host.Services.GetRequiredService&lt;MonitorLoop&gt;();monitorLoop.StartMonitorLoop(); Quartz.net schedulerYou are able to write any background services with the above approach but there are another options to do your background jobs via a scheduler. Quartz.net is an open-source job scheduling system for .NET and you can integrate as following: Install the below packages 1234567Install-Package Quartz -Version 3.1.0dotnet add package Quartz --version 3.1.0&lt;PackageReference Include=&quot;Quartz&quot; Version=&quot;3.1.0&quot; /&gt;Install-Package Quartz.AspNetCore -Version 3.1.0dotnet add package Quartz.AspNetCore --version 3.1.0&lt;PackageReference Include=&quot;Quartz.AspNetCore&quot; Version=&quot;3.1.0&quot; /&gt; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768// ExampleJob.cspublic class ExampleJob : IJob{ public async Task Execute(IJobExecutionContext context) { await Console.Out.WriteLineAsync(&quot;Greetings from HelloJob!&quot;).ConfigureAwait(false); }}// Startup.ConfigureServicespublic void ConfigureServices(IServiceCollection services){ services.AddControllers(); // base configuration for DI services.AddQuartz(q =&gt; { // handy when part of cluster or you want to otherwise identify multiple schedulers q.SchedulerId = &quot;Scheduler-Core&quot;; // we take this from appsettings.json, just show it's possible // q.SchedulerName = &quot;Quartz ASP.NET Core Sample Scheduler&quot;; // we could leave DI configuration intact and then jobs need to have public no-arg constructor // the MS DI is expected to produce transient job instances q.UseMicrosoftDependencyInjectionJobFactory(options =&gt; { // if we don't have the job in DI, allow fallback to configure via default constructor options.AllowDefaultConstructor = true; }); // or // q.UseMicrosoftDependencyInjectionScopedJobFactory(); // these are the defaults q.UseSimpleTypeLoader(); q.UseInMemoryStore(); q.UseDefaultThreadPool(tp =&gt; { tp.MaxConcurrency = 10; }); // configure jobs with code var jobKey = new JobKey(&quot;awesome job&quot;, &quot;awesome group&quot;); q.AddJob&lt;ExampleJob&gt;(j =&gt; j .StoreDurably() .WithIdentity(jobKey) .WithDescription(&quot;my awesome job&quot;) ); q.AddTrigger(t =&gt; t .WithIdentity(&quot;Simple Trigger&quot;) .ForJob(jobKey) .StartNow() .WithSimpleSchedule(x =&gt; x.WithInterval(TimeSpan.FromSeconds(1)).RepeatForever()) .WithDescription(&quot;my awesome simple trigger&quot;) ); }); services.AddQuartzServer(options =&gt; { // when shutting down we want jobs to complete gracefully options.WaitForJobsToComplete = true; });} Quartz.net Admin UIQuartzmin Site: https://github.com/jlucansky/Quartzmin CrystalQuartz Site: https://github.com/guryanovev/CrystalQuartz Quartz alternativeFluentScheduler Automated job scheduler with fluent interface for the .NET platform. Site: https://github.com/fluentscheduler/FluentScheduler Reference(s)Most of the information in this article has gathered from various references. https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/hosted-services https://andrewlock.net/creating-a-quartz-net-hosted-service-with-asp-net-core/ https://www.infoworld.com/article/3529418/how-to-schedule-jobs-using-quartznet-in-aspnet-core.html https://thinkrethink.net/2018/05/31/run-scheduled-background-tasks-in-asp-net-core/ https://www.stevejgordon.co.uk/asp-net-core-2-ihostedservice https://medium.com/@nickfane/introduction-to-worker-services-in-net-core-3-0-4bb3fc631225 https://www.quartz-scheduler.net/ https://github.com/quartznet/quartznet/tree/master/src/Quartz.Examples.AspNetCore https://girishgodage.in/blog/customize-hostedservices","link":"/a-professional-asp.net-core-api-background-task/"},{"title":"A Professional ASP.NET Core API - Caching","text":"Caching is a technique of storing the frequently accessed/used data so that the future requests for those sets of data can be served much faster to the client. In other terms, you take the most frequently used data, which is also least-modified, and copy it temporary storage so that it can be accessed much faster for the future calls from the client. This awesome technique can boost the performance of your application drastically by removing unnecessary and frequent requests to the data source. It is important to note that applications should be designed in a way that they never depend directly on the cached memory. The Application should use the cache data only if it is available. If the cache data has expired or not available, the application would ideally request the original data source. Caching in ASP.NET CoreASP.NET Core has some great out-of-the-box support for various types of caching as follows. In-Memory caching: Where the data is cached within the server’s memory. Distributed caching: The data is stored external to the application in sources like Redis cache etc. In-Memory CachingWith ASP.NET Core, it is now possible to cache the data within the application. This is known as In-Memory Caching in ASP.NET Core. The Application stores the data on to the server’s instance which in turn drastically improves the application’s performance. This is probably the easiest way to implement caching in your application. Pros Much quicker than other forms of distributed caching as it avoids communicating over a network. Highly reliable. Best suited for Small to Mid Scale Applications. Cons If configured incorrectly, it can consume your server’s resources. With the scaling of application and longer caching periods, it can prove to be costly to maintain the server. If deployed in the cloud, maintaining consistent caches can be difficult. How to add In-Memory caching?Add AddMemoryCache to your services as following 123456789101112// Startup.cspublic class Startup{ public void ConfigureServices(IServiceCollection services) { services.AddControllers(); // HERE services.AddMemoryCache(); }} How to use In-Memory caching?In the Controllers folder, add a new Empty API Controller and name it CacheController. Here we will define just 2 endpoints using GET and POST Methods. The POST Method will be responsible for setting the cache. Now how cache works is quite similar to a C# dictionary. That means you will need 2 parameters, a key, and a value. We will use the key to identify the value (data). The Cache that we set earlier can be viewed using the GET Endpoint. But this depends on whether the cache is available/expired/exists. Here is how the controller looks like. 12345678910111213141516171819202122232425262728293031323334353637383940// CacheRequest.cspublic class CacheRequest{ public string Key { get; set; } public string Value { get; set; }}// CacheController.cs[Route(&quot;api/[controller]&quot;)][ApiController]public class CacheController : ControllerBase{ private readonly IMemoryCache memoryCache; public CacheController(IMemoryCache memoryCache /* HERE */) { this.memoryCache = memoryCache; } [HttpGet(&quot;{key}&quot;)] public IActionResult GetCache(string key) { string value = string.Empty; memoryCache.TryGetValue(key, out value); return Ok(value); } [HttpPost] public IActionResult SetCache(CacheRequest data) { var cacheExpiryOptions = new MemoryCacheEntryOptions { AbsoluteExpiration = DateTime.Now.AddMinutes(5), Priority = CacheItemPriority.High, SlidingExpiration = TimeSpan.FromMinutes(2), Size = 1024, }; memoryCache.Set(data.Key, data.Value, cacheExpiryOptions); return Ok(); }} Settings MemoryCacheEntryOptions is used to define the crucial properties of the concerned caching technique. We will be creating an instance of this class and passing it to the memoryCache object later on. Priority: Sets the priority of keeping the cache entry in the cache. The default setting is Normal. Other options are High, Low and Never Remove. This is pretty self-explanatory. Size: Allows you to set the size of this particular cache entry, so that it doesn’t start consuming the server resources. Sliding Expiration: A defined Timespan within which a cache entry will expire if it is not used by anyone for this particular time period. In our case, we set it to 2 minutes. If, after setting the cache, no client requests for this cache entry for 2 minutes, the cache will be deleted. Absolute Expiration: The problem with Sliding Expiration is that theoretically, it can last forever. Let’s say someone requests for the data every 1.59 minutes for the next couple of days, the application would be technically serving an outdated cache for days together. With Absolute expiration, we can set the actual expiration of the cache entry. Here it is set as 5 minutes. So, every 5 minutes, without taking into consideration the sliding expiration, the cache will be expired. It’s always a good practice to use both these expirations checks to improve performance. Note: The Absolute Expiration should never be less than the Sliding Expiration. Practical In-Memory caching implementationFor testing purposes, I have set up an API and configured Entity Framework Core. This API will return a list of all customers in the database. 1234567891011121314151617181920212223242526272829[Route(&quot;api/[controller]&quot;)][ApiController]public class CustomerController : ControllerBase{ private readonly IMemoryCache memoryCache; private readonly ApplicationDbContext context; public CustomerController(IMemoryCache memoryCache, ApplicationDbContext context) { this.memoryCache = memoryCache; this.context = context; } [HttpGet] public async Task&lt;IActionResult&gt; GetAll() { var cacheKey = &quot;customerList&quot;; if(!memoryCache.TryGetValue(cacheKey, out List&lt;Customer&gt; customerList)) { customerList = await context.Customers.ToListAsync(); var cacheExpiryOptions = new MemoryCacheEntryOptions { AbsoluteExpiration = DateTime.Now.AddMinutes(5), Priority = CacheItemPriority.High, SlidingExpiration = TimeSpan.FromMinutes(2) }; memoryCache.Set(cacheKey, customerList, cacheExpiryOptions); } return Ok(customerList); }} Distributed CachingASP.NET Core supports not only in-memory application based cache, but also supports Distribited Caching. A distributed cache is something external to the application. It does not live within the application and need not be present in the infrastructure of the server machine as well. Distributed cache is a cache that can be shared by one or more applications/servers.Like in-memory cache, it can improve your application response time quite drastrically. However, the implementation of Distributed Cache is application specific. This means that there are multiple cache providers that support distributed caches. Pros Data is consistent throughout multiple servers. Multiple Applications / Servers can use one instance of Redis Server to cache data. This reduces the cost of maintanence in the longer run. Cache would not be lost on server restart and application deployment as the cache lives external to the application. It does not use local server’s resources. Cons Since it is kept external, the response time may be a bit slower depending on the connection strength to the redis server. Distributed memory cacheTo keep in line with other distributed memory cache providers that follow IDistributedCache interface there is also implementation of memory cache that follows the same interface. MemoryDistributedCache class is wrapper around IMemoryCache and we can use it as any other distributed cache. IDistributedCache interface Method(s) Description Get, GetAsync Accepts a string key and retrieves a cached item as a byte[] array if found in the cache. Set, SetAsync Adds an item (as byte[] array) to the cache using a string key. Refresh, RefreshAsync Refreshes an item in the cache based on its key, resetting its sliding expiration timeout (if any). Remove, RemoveAsync Removes a cache item based on its string key. How to add Distributed caching? Add AddDistributedMemoryCache to your services as following 123456789101112// Startup.cspublic class Startup{ public void ConfigureServices(IServiceCollection services) { services.AddControllers(); // HERE services.AddDistributedMemoryCache(); }} For example 12345678910111213141516171819202122232425262728293031323334// CacheRequest.cspublic class CacheRequest{ public string Key { get; set; } public byte[] Value { get; set; }}// CacheController.cs[Route(&quot;api/[controller]&quot;)][ApiController]public class CacheController : ControllerBase{ private readonly IDistributedCache _distributedCache; public CacheController(IDistributedCache distributedCache /* HERE */) { this._distributedCache = distributedCache; } [HttpGet(&quot;{key}&quot;)] public IActionResult GetCache(string key) { var value = _distributedCache.Get(key); // ... return Ok(/* Your object */); } [HttpPost] public IActionResult SetCache(CacheRequest data) { _distributedCache.Set(data.Key, data.Value); // ... return Ok(/* Your object */); }} There are some useful extension methods to convert your object to byte array and vice versa. 12345678910111213141516171819202122232425262728293031// ByteArrayExtensions.csusing System.IO;using System.Runtime.Serialization.Formatters.Binary;public static class ByteArrayExtensions{ public static byte[] ToByteArray&lt;T&gt;(this T obj) { if (obj == null) return null; BinaryFormatter bf = new BinaryFormatter(); using (MemoryStream ms = new MemoryStream()) { bf.Serialize(ms, obj); return ms.ToArray(); } } public static T FromByteArray&lt;T&gt;(this byte[] data) { if (data == null) return default(T); BinaryFormatter bf = new BinaryFormatter(); using (MemoryStream ms = new MemoryStream(data)) { object obj = bf.Deserialize(ms); return (T)obj; } }} In-Memory cache or Distributed memory cache?Using In-Memory cache is the option for systems running on single box. Also in development environments we could prefer In-Memory based cache to keep external services away when building the system. I think that going with IDistributedCache is better idea as there is no need for changes in controllers and other parts of application when distributed cache provider is changed. In cloud and multi-box environments some implementation of distributed cache is a must as local caches on web server are not synchronized. So, The Distributed Memory Cache is a useful implementation: In development and testing scenarios. When a single server is used in production and memory consumption isn’t an issue. Implementing the Distributed Memory Cache abstracts cached data storage. It allows for implementing a true distributed caching solution in the future if multiple nodes or fault tolerance become necessary. Distributed SQL Server CacheThe Distributed SQL Server Cache implementation (AddDistributedSqlServerCache) allows the distributed cache to use a SQL Server database as its backing store. To create a SQL Server cached item table in a SQL Server instance, you can use the sql-cache tool. The tool creates a table with the name and schema that you specify. Create a table in SQL Server by running the sql-cache create command. Provide the SQL Server instance (Server), database (Database), schema (for example, dbo), and table name (for example, TestCache): 123dotnet tool install --global dotnet-sql-cache --version 3.1.8dotnet sql-cache create &quot;Server=.;Database=DistCache;User Id=sa;Password=1234567;&quot; dbo TestCache A message is logged to indicate that the tool was successful: 1Table and index were created successfully. The sample app implements SqlServerCache in a non-Development environment in Startup.ConfigureServices: 1234567891011121314151617// Startup.ConfigureServicespublic class Startup{ public void ConfigureServices(IServiceCollection services) { services.AddControllers(); // HERE services.AddDistributedSqlServerCache(options =&gt; { options.ConnectionString = Configuration[&quot;DistCache_ConnectionString&quot;]; options.SchemaName = &quot;dbo&quot;; options.TableName = &quot;TestCache&quot;; }); }} And inside appsettings.json 123{ &quot;DistCache_ConnectionString&quot;: &quot;Server=.;Database=DistCache;User Id=sa;Password=1234567;&quot;} Distributed Redis CacheRedis is an open source data store that is used as a database, cache / messaging broker. It supports quite a lot of data structures like string, hashes, lists,, queries and much more. It’s a blazing fast key-value based database that is written in C. It’s a NoSQL Database as well, which is awesome. For these purposes, it is being used at techgiants like Stackoverflow, Flickr, Github and so on. Redis is a great option for implementing highly available cache to reduce the data access latency and improve the application response time. As a result, we can reduce the load off our database to a very good extent. Install below package 123Install-Package Microsoft.Extensions.Caching.StackExchangeRedis -Version 3.1.8dotnet add package Microsoft.Extensions.Caching.StackExchangeRedis --version 3.1.8&lt;PackageReference Include=&quot;Microsoft.Extensions.Caching.StackExchangeRedis&quot; Version=&quot;3.1.8&quot; /&gt; Register Redis as following: 12345678910111213141516// Startup.ConfigureServicespublic class Startup{ public void ConfigureServices(IServiceCollection services) { services.AddControllers(); // HERE services.AddStackExchangeRedisCache(options =&gt; { // By default, Redis runs on the local 6379 port. options.Configuration = &quot;localhost:6379&quot;; }); }} You can use it inside controller 123456789101112131415161718192021222324[ApiController][Route(&quot;[controller]&quot;)]public class WeatherForecastController : ControllerBase{ private readonly IDistributedCache _distributedCache; public WeatherForecastController(IDistributedCache distributedCache) { _distributedCache = distributedCache; // SET var options = new DistributedCacheEntryOptions() .SetAbsoluteExpiration(DateTime.Now.AddMinutes(10)) .SetSlidingExpiration(TimeSpan.FromMinutes(2)); _distributedCache.Set(&quot;test&quot;, &quot;Hello&quot;.ToByteArray(), options); } [HttpGet] public string Get() { // GET var value = _distributedCache.Get(&quot;test&quot;).FromByteArray&lt;string&gt;(); return value; }} DistributedCacheEntryOptions SetAbsoluteExpiration: You can set the expiration time of the cache object. SetSlidingExpiration: This is similar to the Absolute Expiration. It expires a cache object if it not being requested for a defined amount of time period. Note: The Absolute Expiration should never be less than the Sliding Expiration. Reference(s)Most of the information in this article has gathered from various references. https://www.codewithmukesh.com/blog/in-memory-caching-in-aspnet-core/ https://www.codewithmukesh.com/blog/redis-caching-in-aspnet-core/ https://docs.microsoft.com/en-us/aspnet/core/performance/caching/distributed https://gunnarpeipman.com/aspnet-core-memory-cache/ https://www.codewithmukesh.com/blog/redis-caching-in-aspnet-core/","link":"/a-professional-asp.net-core-api-caching/"},{"title":"A Professional ASP.NET Core API - CORS","text":"Browser security prevents a web page from making requests to a different domain than the one that served the web page. This restriction is called the same-origin policy. The same-origin policy prevents a malicious site from reading sensitive data from another site. Sometimes, you might want to allow other sites to make cross-origin requests to your app. What is the meaning of Same origin?Two URLs have the same origin if they have identical schemes, hosts, and ports. These two URLs have the same origin: https://example.com/foo.html https://example.com/bar.html These URLs have different origins than the previous two URLs: https://example.net: Different domain https://www.example.com/foo.html: Different subdomain http://example.com/foo.html: Different scheme https://example.com:9000/foo.html: Different port How to enable CORS?There are three ways to enable CORS: In middleware using a named policy or default policy. Using endpoint routing. With the [EnableCors] attribute. Warning: UseCors must be called before UseResponseCaching. CORS with named policy and middleware123456789101112131415161718192021222324252627282930313233343536373839404142434445public class Startup{ readonly string MyAllowSpecificOrigins = &quot;_myAllowSpecificOrigins&quot;; public void ConfigureServices(IServiceCollection services) { services.AddCors(options =&gt; { options.AddPolicy(name: MyAllowSpecificOrigins, builder =&gt; { builder.WithOrigins(&quot;http://example.com&quot;, &quot;http://www.contoso.com&quot;) .AllowAnyHeader() .AllowAnyMethod(); }); }); // services.AddResponseCaching(); services.AddControllers(); } public void Configure(IApplicationBuilder app, IWebHostEnvironment env) { if (env.IsDevelopment()) { app.UseDeveloperExceptionPage(); } app.UseHttpsRedirection(); app.UseStaticFiles(); app.UseRouting(); app.UseCors(MyAllowSpecificOrigins); // app.UseResponseCaching(); app.UseAuthorization(); app.UseEndpoints(endpoints =&gt; { endpoints.MapControllers(); }); }} CORS with default policy and middleware1234567891011121314151617181920212223242526272829303132333435363738394041424344public class Startup{ public void ConfigureServices(IServiceCollection services) { services.AddCors(options =&gt; { options.AddDefaultPolicy( builder =&gt; { // Be careful dont use '/' at the end of the url. // eg. 'http://example.com/' does not work correctly. builder.WithOrigins(&quot;http://example.com&quot;, &quot;http://www.contoso.com&quot;); builder.WithOrigins(&quot;http://localhost:4200&quot;) .AllowAnyMethod() .AllowAnyHeader(); }); }); services.AddControllers(); } public void Configure(IApplicationBuilder app, IWebHostEnvironment env) { if (env.IsDevelopment()) { app.UseDeveloperExceptionPage(); } app.UseHttpsRedirection(); app.UseStaticFiles(); app.UseRouting(); app.UseCors(); app.UseAuthorization(); app.UseEndpoints(endpoints =&gt; { endpoints.MapControllers(); }); }} Enable CORS with endpoint routing123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class Startup{ readonly string MyAllowSpecificOrigins = &quot;_myAllowSpecificOrigins&quot;; public void ConfigureServices(IServiceCollection services) { services.AddCors(options =&gt; { options.AddPolicy(name: MyAllowSpecificOrigins, builder =&gt; { builder.WithOrigins(&quot;http://example.com&quot;, &quot;http://www.contoso.com&quot;); }); }); services.AddControllers(); services.AddRazorPages(); } public void Configure(IApplicationBuilder app, IWebHostEnvironment env) { if (env.IsDevelopment()) { app.UseDeveloperExceptionPage(); } app.UseHttpsRedirection(); app.UseStaticFiles(); app.UseRouting(); app.UseCors(); app.UseAuthorization(); app.UseEndpoints(endpoints =&gt; { endpoints.MapGet(&quot;/echo&quot;, context =&gt; context.Response.WriteAsync(&quot;echo&quot;)) .RequireCors(MyAllowSpecificOrigins); endpoints.MapControllers() .RequireCors(MyAllowSpecificOrigins); endpoints.MapGet(&quot;/echo2&quot;, context =&gt; context.Response.WriteAsync(&quot;echo2&quot;)); endpoints.MapRazorPages(); }); }} Enable CORS with attributesEnabling CORS with the [EnableCors] attribute and applying a named policy to only those endpoints that require CORS provides the finest control. The [EnableCors] attribute provides an alternative to applying CORS globally. The [EnableCors] attribute enables CORS for selected endpoints, rather than all endpoints: [EnableCors] specifies the default policy. [EnableCors(&quot;{Policy String}&quot;)] specifies a named policy. The [EnableCors] attribute can be applied to: Razor Page PageModel Controller Controller action method Different policies can be applied to controllers, page models, or action methods with the [EnableCors] attribute. When the [EnableCors] attribute is applied to a controller, page model, or action method, and CORS is enabled in middleware, both policies are applied. We recommend against combining policies. Use the [EnableCors] attribute or middleware, not both in the same app. A different policy to each method: 12345678910111213141516171819202122232425[Route(&quot;api/[controller]&quot;)][ApiController]public class WidgetController : ControllerBase{ // GET api/values [EnableCors(&quot;AnotherPolicy&quot;)] [HttpGet] public ActionResult&lt;IEnumerable&lt;string&gt;&gt; Get() { return new string[] { &quot;green widget&quot;, &quot;red widget&quot; }; } // GET api/values/5 [EnableCors(&quot;Policy1&quot;)] [HttpGet(&quot;{id}&quot;)] public ActionResult&lt;string&gt; Get(int id) { return id switch { 1 =&gt; &quot;green widget&quot;, 2 =&gt; &quot;red widget&quot;, _ =&gt; NotFound(), }; }} Creates two CORS policies: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class Startup{ public Startup(IConfiguration configuration) { Configuration = configuration; } public IConfiguration Configuration { get; } public void ConfigureServices(IServiceCollection services) { services.AddCors(options =&gt; { options.AddPolicy(&quot;Policy1&quot;, builder =&gt; { builder.WithOrigins(&quot;http://example.com&quot;, &quot;http://www.contoso.com&quot;); }); options.AddPolicy(&quot;AnotherPolicy&quot;, builder =&gt; { builder.WithOrigins(&quot;http://www.contoso.com&quot;) .AllowAnyHeader() .AllowAnyMethod(); }); }); services.AddControllers(); } public void Configure(IApplicationBuilder app, IWebHostEnvironment env) { if (env.IsDevelopment()) { app.UseDeveloperExceptionPage(); } app.UseHttpsRedirection(); app.UseRouting(); app.UseCors(); app.UseAuthorization(); app.UseEndpoints(endpoints =&gt; { endpoints.MapControllers(); }); }} For the finest control of limiting CORS requests: Use [EnableCors(&quot;MyPolicy&quot;)] with a named policy. Don’t define a default policy. Don’t use endpoint routing. Disable CORSThe [DisableCors] attribute does not disable CORS that has been enabled by endpoint routing. The following code defines the CORS policy “MyPolicy”: 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class Startup{ public void ConfigureServices(IServiceCollection services) { services.AddCors(options =&gt; { options.AddPolicy(name: &quot;MyPolicy&quot;, builder =&gt; { builder.WithOrigins(&quot;http://example.com&quot;, &quot;http://www.contoso.com&quot;) .WithMethods(&quot;PUT&quot;, &quot;DELETE&quot;, &quot;GET&quot;); builder.WithOrigins(&quot;http://localhost:4200&quot;) .AllowAnyMethod() .AllowAnyHeader(); }); }); services.AddControllers(); services.AddRazorPages(); } public void Configure(IApplicationBuilder app, IWebHostEnvironment env) { if (env.IsDevelopment()) { app.UseDeveloperExceptionPage(); } app.UseHttpsRedirection(); app.UseStaticFiles(); app.UseRouting(); app.UseCors(); app.UseAuthorization(); app.UseEndpoints(endpoints =&gt; { endpoints.MapControllers(); endpoints.MapRazorPages(); }); }} The following code disables CORS for the GetValues2 action: 12345678910111213141516171819202122232425262728[EnableCors(&quot;MyPolicy&quot;)][Route(&quot;api/[controller]&quot;)][ApiController]public class ValuesController : ControllerBase{ // GET api/values [HttpGet] public IActionResult Get() =&gt; ControllerContext.MyDisplayRouteInfo(); // GET api/values/5 [HttpGet(&quot;{id}&quot;)] public IActionResult Get(int id) =&gt; ControllerContext.MyDisplayRouteInfo(id); // PUT api/values/5 [HttpPut(&quot;{id}&quot;)] public IActionResult Put(int id) =&gt; ControllerContext.MyDisplayRouteInfo(id); // GET: api/values/GetValues2 [DisableCors] [HttpGet(&quot;{action}&quot;)] public IActionResult GetValues2() =&gt; ControllerContext.MyDisplayRouteInfo();} CORS policy options AllowAnyOrigin: Allows CORS requests from all origins with any scheme (http or https). AllowAnyOrigin is insecure because any website can make cross-origin requests to the app. AllowAnyMethod: Allows any HTTP method. AllowAnyHeader: Ensures that the policy allows any header. AllowCredentials: The server must allow the credentials. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class Startup{ public void ConfigureServices(IServiceCollection services) { services.AddCors(options =&gt; { options.AddPolicy(name: MyAllowSpecificOrigins, builder =&gt; { // Allow Anything builder .AllowAnyOrigin() .AllowAnyMethod() .AllowAnyHeader() .AllowCredentials() ; }); }); // services.AddResponseCaching(); services.AddControllers(); } public void Configure(IApplicationBuilder app, IWebHostEnvironment env) { if (env.IsDevelopment()) { app.UseDeveloperExceptionPage(); } app.UseHttpsRedirection(); app.UseStaticFiles(); app.UseRouting(); // HERE app.UseCors(MyAllowSpecificOrigins); // app.UseResponseCaching(); app.UseAuthorization(); app.UseEndpoints(endpoints =&gt; { endpoints.MapControllers(); }); }} Reference(s)Most of the information in this article has gathered from various references. https://docs.microsoft.com/en-us/aspnet/core/security/cors","link":"/a-professional-asp.net-core-api-cors/"},{"title":"A Professional ASP.NET Core API - DryIoc","text":"DryIoc is fast, small, full-featured IoC Container for .NET. Designed for low-ceremony use, performance, and extensibility. In the following we will see how it can be added to a project. Install the below packages 1234567Install-Package DryIoc.dll -Version 4.4.1dotnet add package DryIoc.dll --version 4.4.1&lt;PackageReference Include=&quot;DryIoc.dll&quot; Version=&quot;4.4.1&quot; /&gt;Install-Package DryIoc.Microsoft.DependencyInjection -Version 4.1.0dotnet add package DryIoc.Microsoft.DependencyInjection --version 4.1.0&lt;PackageReference Include=&quot;DryIoc.Microsoft.DependencyInjection&quot; Version=&quot;4.1.0&quot; /&gt; To Plug-in the DryIoc you should introduce it inside the host builder. 1234567891011121314151617181920212223// Startup.CreateHostBuilderpublic class Program{ public static async Task Main(string[] args) =&gt; await CreateHostBuilder(args).Build().RunAsync(); public static IHostBuilder CreateHostBuilder(string[] args) =&gt; Host.CreateDefaultBuilder(args) .ConfigureLogging((hostingContext, logging) =&gt; { logging.ClearProviders(); // removes all providers from LoggerFactory logging.AddConfiguration(hostingContext.Configuration.GetSection(&quot;Logging&quot;)); logging.AddDebug(); }) // HERE .UseServiceProviderFactory(new DryIocServiceProviderFactory()) .ConfigureWebHostDefaults(webBuilder =&gt; { webBuilder.UseStartup&lt;Startup&gt;(); });} To simplify the above process you can write a custom extension method. 1234567public static class DryIocExtensions{ public static IHostBuilder UseDryIoc(this IHostBuilder hostBuilder, IServiceProviderFactory&lt;IContainer&gt; factory = null) { return hostBuilder.UseServiceProviderFactory(factory ?? new DryIocServiceProviderFactory()); }} And use it as following 1234567891011121314151617181920212223// Startup.CreateHostBuilderpublic class Program{ public static async Task Main(string[] args) =&gt; await CreateHostBuilder(args).Build().RunAsync(); public static IHostBuilder CreateHostBuilder(string[] args) =&gt; Host.CreateDefaultBuilder(args) .ConfigureLogging((hostingContext, logging) =&gt; { logging.ClearProviders(); // removes all providers from LoggerFactory logging.AddConfiguration(hostingContext.Configuration.GetSection(&quot;Logging&quot;)); logging.AddDebug(); }) // HERE .UseDryIoc() .ConfigureWebHostDefaults(webBuilder =&gt; { webBuilder.UseStartup&lt;Startup&gt;(); });} How to enable pre-configured settings?If you want to set some pre-configred settings just follow the steps: Implementation First, define a method with your custom setting. 12345678910111213// Startup.cs/// &lt;summary&gt;/// Use this method to pass your custom pre-configured container to the `IHostBuilderUseServiceProviderFactory` in &quot;Program.cs&quot;/// &lt;/summary&gt;public static IContainer CreateMyPreConfiguredContainer() =&gt; // This is an example configuration, // for possible options check the https://github.com/dadhi/DryIoc/blob/master/docs/DryIoc.Docs/RulesAndDefaultConventions.md new Container(rules =&gt; // Configures property injection for Controllers, ensure that you've added `AddControllersAsServices` in `ConfigureServices` rules.With(propertiesAndFields: request =&gt; request.ServiceType.Name.EndsWith(&quot;Controller&quot;) ? PropertiesAndFields.Properties()(request) : null) ); Registration Then, register it like the below 123456789101112131415161718192021// Startup.CreateHostBuilderpublic class Program{ public static async Task Main(string[] args) =&gt; await CreateHostBuilder(args).Build().RunAsync(); public static IHostBuilder CreateHostBuilder(string[] args) =&gt; Host.CreateDefaultBuilder(args) // Plug-in the DryIoc // CreateMyPreConfiguredContainer method is the key. .UseServiceProviderFactory(new DryIocServiceProviderFactory(Startup.CreateMyPreConfiguredContainer())) // Or // .UseDryIoc(Startup.CreateMyPreConfiguredContainer()) .ConfigureWebHostDefaults(webBuilder =&gt; { webBuilder.UseStartup&lt;Startup&gt;(); });} How to set it up?To activate all the features, write the following codes in the Startup class. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class Startup{ public Startup(IConfiguration configuration) { Configuration = configuration; } public IConfiguration Configuration { get; } public void ConfigureServices(IServiceCollection services) { var mvcBuilder = services.AddControllers(); // uses DI to construct the controllers - required for the DryIoc diagnostics, property injection, etc. to work; mvcBuilder.AddControllersAsServices(); } /// &lt;summary&gt; /// Use this method to pass your custom pre-configured container to the `IHostBuilder.UseServiceProviderFactory` in &quot;Program.cs&quot; /// &lt;/summary&gt; public static IContainer CreateMyPreConfiguredContainer() =&gt; // This is an example configuration, // for possible options check the https://github.com/dadhi/DryIoc/blob/master/docs/DryIoc.Docs/RulesAndDefaultConventions.md new Container(rules =&gt; // Configures property injection for Controllers, ensure that you've added `AddControllersAsServices` in `ConfigureServices` rules.With(propertiesAndFields: request =&gt; request.ServiceType.Name.EndsWith(&quot;Controller&quot;) ? PropertiesAndFields.Properties()(request) : null) ); // The most important conventional method to enable third-party IoCs. public void ConfigureContainer(IContainer container) { // You may place your registrations here or split them in different classes, or organize them in some kind of modules, e.g: BasicServicesRegistrator.Register(container); SpecialServicesRegistrator.Register(container); // NOTE: // Don't configure the container rules here because DryIoc uses the immutable container/configuration // and you customized container will be lost. // Instead you may use something like `CreateMyPreConfiguredContainer` above. } // This method gets called by the runtime. Use this method to configure the HTTP request pipeline. public void Configure(IApplicationBuilder app, IWebHostEnvironment env, ILoggerFactory loggerFactory) { var logger = loggerFactory.CreateLogger&lt;Startup&gt;(); // All DryIoc Container interfaces are available through the MS.DI services var container = app.ApplicationServices.GetRequiredService&lt;IContainer&gt;(); logger.LogInformation($&quot;You may use the DryIoc container here: '{container}'&quot;); if (env.IsDevelopment()) { app.UseDeveloperExceptionPage(); } app.UseHttpsRedirection(); app.UseRouting(); app.UseAuthorization(); app.UseEndpoints(endpoints =&gt; { endpoints.MapControllers(); }); }} As you can see above you can put your registration information in different classes. 12BasicServicesRegistrator.Register(container);SpecialServicesRegistrator.Register(container); And that’s exactly the way they are shaped: 123456789101112131415161718192021// BasicServicesRegistrator.cspublic static class BasicServicesRegistrator{ public static void Register(IRegistrator r) { r.Register&lt;ISingletonService, SingletonService&gt;(Reuse.Singleton); r.Register&lt;ITransientService, TransientService&gt;(Reuse.Transient); r.Register&lt;IScopedService, ScopedService&gt;(Reuse.InCurrentScope); }}// SpecialServicesRegistrator.cspublic static class SpecialServicesRegistrator{ public static void Register(IRegistrator r) { // r.Register&lt;IExportedService, ExportedService&gt;(); // Optionally using the MEF Exported services r.RegisterExports(typeof(ExportedService)); }} Reference(s)Most of the information in this article has gathered from various references. https://github.com/dadhi/DryIoc","link":"/a-professional-asp.net-core-api-dryioc/"},{"title":"A Professional ASP.NET Core API - External APIs","text":"In many projects we want to call external APIs and use their results in our application. In this article, we will address the following: HttpClientFactory Refit Polly HttpClientFactoryMicrosoft introduced the HttpClient in .Net Framework 4.5 and is the most popular way to consume a Web API in your .NET server-side code. But it has some serious issues like disposing the HttpClient object doesn’t close the socket immediately, too many instances affecting the performance and Singleton HttpClient or shared HttpClient instance not respecting the DNS Time to Live (TTL) settings. HttpClientFactory solves the all these problems. It is one of the newest feature of ASP.NET Core 2.1. It provides a central location for naming and configuring and consuming logical HttpClients in your application, and this post talks about 3 ways to use HTTPClientFactory in ASP.NET Core 2.1. There are 3 different ways to use it and we’ll see an example of each of them. Using HttpClientFactory Directly Named Clients Typed Clients Using HttpClientFactory Directly you’ll always have to register the HttpClient in ConfigureServices method of the Startup.cs class. The following line of code registers HttpClient with no special configuration. 123456789// Startup.ConfigureServicespublic void ConfigureServices(IServiceCollection services){ services.AddControllers(); // HERE services.AddHttpClient();} You can use it in the following way in the API controller. 123456789101112131415161718public class ValuesController : Controller{ private readonly IHttpClientFactory _httpClientFactory; public ValuesController(IHttpClientFactory httpClientFactory) { _httpClientFactory = httpClientFactory; } [HttpGet] public async Task&lt;ActionResult&gt; Get() { var client = _httpClientFactory.CreateClient(); client.BaseAddress = new Uri(&quot;http://api.github.com&quot;); string result = await client.GetStringAsync(&quot;/&quot;); return Ok(result); }} Named Clients The basic use of HTTPClientFactory in above example is ideal in a situation where you need to make a quick request from a single place in the code. When you need to make multiple requests from multiple places from your code, “Named Clients” will help you. With named clients, you can define the HTTP client with some pre-configured settings which will be applied when creating the HttpClient. Like, 123456789101112131415// Startup.ConfigureServicespublic void ConfigureServices(IServiceCollection services){ services.AddControllers(); // HERE services.AddHttpClient(); services.AddHttpClient(&quot;github&quot;, c =&gt; { c.BaseAddress = new Uri(&quot;https://api.github.com/&quot;); c.DefaultRequestHeaders.Add(&quot;Accept&quot;, &quot;application/vnd.github.v3+json&quot;); c.DefaultRequestHeaders.Add(&quot;User-Agent&quot;, &quot;HttpClientFactory-Sample&quot;); });} Here we call AddHttpClient twice, once with the name “github” and once without. The github client has some default configuration applied, namely the base address and two headers required to work with the GitHub API. The overload of AddHttpClient method accepts two parameters, a name and an Action delegate taking a HttpClient which allows us to configure the HttpClient. You can use named client in the following way in the API controller. 1234567891011121314151617public class ValuesController : Controller{ private readonly IHttpClientFactory _httpClientFactory; public ValuesController(IHttpClientFactory httpClientFactory) { _httpClientFactory = httpClientFactory; } [HttpGet] public async Task&lt;ActionResult&gt; Get() { var client = _httpClientFactory.CreateClient(&quot;github&quot;); string result = await client.GetStringAsync(&quot;/&quot;); return Ok(result); }} Here, we are passing the registered name of the client in CreateClient() method to create HttpClient. This is useful as the default configuration defined at the time of registration will be pre-applied when we ask for a named client. Typed Client Using Typed clients, you can define pre-configuration for your HttpClient inside a custom class. This custom class can be registered as Typed client, and later when needed, it can be injected via the calling class constructor. I prefer Typed Client for the following reasons, Flexible approach compare to named clients. You no longer have to deal with strings (like in named clients). You can encapsulate the HTTP calls and all logic dealing with that endpoint. Let’s see an example. Below is a custom class defined for Github client. 123456789101112public class GitHubClient{ public HttpClient Client { get; private set; } public GitHubClient(HttpClient httpClient) { httpClient.BaseAddress = new Uri(&quot;https://api.github.com/&quot;); httpClient.DefaultRequestHeaders.Add(&quot;Accept&quot;, &quot;application/vnd.github.v3+json&quot;); httpClient.DefaultRequestHeaders.Add(&quot;User-Agent&quot;, &quot;HttpClientFactory-Sample&quot;); Client = httpClient; }} You can register this as a typed client using the following line. 1services.AddHttpClient&lt;GitHubClient&gt;(); And, use it in the following way in the API controller. 12345678910111213141516public class ValuesController : Controller{ private readonly GitHubClient _gitHubClient;; public ValuesController(GitHubClient gitHubClient) { _gitHubClient = gitHubClient; } [HttpGet] public async Task&lt;ActionResult&gt; Get() { string result = await _gitHubClient.client.GetStringAsync(&quot;/&quot;); return Ok(result); }} This works great. There is another better way of making typed client work. Here, the HttpClient is exposed directly, but you can encapsulate the HttpClient entirely using the following way. First, define a contract for the GitHubClient. 12345678910111213141516171819202122public interface IGitHubClient{ Task&lt;string&gt; GetData();} public class GitHubClient : IGitHubClient{ private readonly HttpClient _client; public GitHubClient(HttpClient httpClient) { httpClient.BaseAddress = new Uri(&quot;https://api.github.com/&quot;); httpClient.DefaultRequestHeaders.Add(&quot;Accept&quot;, &quot;application/vnd.github.v3+json&quot;); httpClient.DefaultRequestHeaders.Add(&quot;User-Agent&quot;, &quot;HttpClientFactory-Sample&quot;); _client = httpClient; } public async Task&lt;string&gt; GetData() { return await _client.GetStringAsync(&quot;/&quot;); }} Register this as a typed client using the following line. 1services.AddHttpClient&lt;IGitHubClient, GitHubClient&gt;(); And, use it in the following way in the API controller. 12345678910111213141516public class ValuesController : Controller{ private readonly IGitHubClient _gitHubClient;; public ValuesController(IGitHubClient gitHubClient) { _gitHubClient = gitHubClient; } [HttpGet] public async Task&lt;ActionResult&gt; Get() { string result = await _gitHubClient.GetData(); return Ok(result); }} This approach also makes unit testing easy while testing HttpClients as you no longer have to mock them. RefitRefit is a library heavily inspired by Square's Retrofit library, and it turns your REST API into a live interface: Install below packages 1234567891011Install-Package refit -Version 5.2.1dotnet add package refit --version 5.2.1&lt;PackageReference Include=&quot;refit&quot; Version=&quot;5.2.1&quot; /&gt;Install-Package Refit.HttpClientFactory -Version 5.2.1dotnet add package Refit.HttpClientFactory --version 5.2.1&lt;PackageReference Include=&quot;Refit.HttpClientFactory&quot; Version=&quot;5.2.1&quot; /&gt;Install-Package Newtonsoft.Json -Version 12.0.3dotnet add package Newtonsoft.Json --version 12.0.3&lt;PackageReference Include=&quot;Newtonsoft.Json&quot; Version=&quot;12.0.3&quot; /&gt; Suppose in our project we want to call the following address to get comprehensive information about the country we want. The documentation and how to call it is as follows: Doc: https://restcountries.eu/ API: https://restcountries.eu/rest/v2/name/usa Based on the documentation and results provided as an example, we want to have a strongly typed output so I used json2csharp to convert JSON to C# but I made some changes to the result like the following: Replace all int with double Removed Root class Changed MyArray to Country JsonProperty uses for Newtonsoft.Json library but if you want to use the new System.Text.Json library, you should change it to JsonPropertyName. C# Class 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134public class Currency{ [JsonProperty(&quot;code&quot;)] public string Code { get; set; } [JsonProperty(&quot;name&quot;)] public string Name { get; set; } [JsonProperty(&quot;symbol&quot;)] public string Symbol { get; set; }}public class Language{ [JsonProperty(&quot;iso639_1&quot;)] public string Iso6391 { get; set; } [JsonProperty(&quot;iso639_2&quot;)] public string Iso6392 { get; set; } [JsonProperty(&quot;name&quot;)] public string Name { get; set; } [JsonProperty(&quot;nativeName&quot;)] public string NativeName { get; set; }}public class Translations{ [JsonProperty(&quot;de&quot;)] public string De { get; set; } [JsonProperty(&quot;es&quot;)] public string Es { get; set; } [JsonProperty(&quot;fr&quot;)] public string Fr { get; set; } [JsonProperty(&quot;ja&quot;)] public string Ja { get; set; } [JsonProperty(&quot;it&quot;)] public string It { get; set; } [JsonProperty(&quot;br&quot;)] public string Br { get; set; } [JsonProperty(&quot;pt&quot;)] public string Pt { get; set; } [JsonProperty(&quot;nl&quot;)] public string Nl { get; set; } [JsonProperty(&quot;hr&quot;)] public string Hr { get; set; } [JsonProperty(&quot;fa&quot;)] public string Fa { get; set; }}public class Country{ [JsonProperty(&quot;name&quot;)] public string Name { get; set; } [JsonProperty(&quot;topLevelDomain&quot;)] public List&lt;string&gt; TopLevelDomain { get; set; } [JsonProperty(&quot;alpha2Code&quot;)] public string Alpha2Code { get; set; } [JsonProperty(&quot;alpha3Code&quot;)] public string Alpha3Code { get; set; } [JsonProperty(&quot;callingCodes&quot;)] public List&lt;string&gt; CallingCodes { get; set; } [JsonProperty(&quot;capital&quot;)] public string Capital { get; set; } [JsonProperty(&quot;altSpellings&quot;)] public List&lt;string&gt; AltSpellings { get; set; } [JsonProperty(&quot;region&quot;)] public string Region { get; set; } [JsonProperty(&quot;subregion&quot;)] public string Subregion { get; set; } [JsonProperty(&quot;population&quot;)] public double Population { get; set; } [JsonProperty(&quot;latlng&quot;)] public List&lt;double&gt; Latlng { get; set; } [JsonProperty(&quot;demonym&quot;)] public string Demonym { get; set; } [JsonProperty(&quot;area&quot;)] public double Area { get; set; } [JsonProperty(&quot;gini&quot;)] public object Gini { get; set; } [JsonProperty(&quot;timezones&quot;)] public List&lt;string&gt; Timezones { get; set; } [JsonProperty(&quot;borders&quot;)] public List&lt;object&gt; Borders { get; set; } [JsonProperty(&quot;nativeName&quot;)] public string NativeName { get; set; } [JsonProperty(&quot;numericCode&quot;)] public string NumericCode { get; set; } [JsonProperty(&quot;currencies&quot;)] public List&lt;Currency&gt; Currencies { get; set; } [JsonProperty(&quot;languages&quot;)] public List&lt;Language&gt; Languages { get; set; } [JsonProperty(&quot;translations&quot;)] public Translations Translations { get; set; } [JsonProperty(&quot;flag&quot;)] public string Flag { get; set; } [JsonProperty(&quot;regionalBlocs&quot;)] public List&lt;object&gt; RegionalBlocs { get; set; } [JsonProperty(&quot;cioc&quot;)] public string Cioc { get; set; }} Now, We want to use Refit to fetch data so write the following interface. 123456public interface ICountryApi{ // You have to start the URL with '/' [Get(&quot;/{version}/name/{country}&quot;)] Task&lt;List&lt;Country&gt;&gt; GetCountry(string version,string country);} And write your base address in appsettings.json 12345// appsettings.json// Don't use '/' at the end of the URL.&quot;MyRefitOptions&quot;: { &quot;BaseAddress&quot;: &quot;https://restcountries.eu/rest&quot;} Register Refit client like below 12345678public void ConfigureServices(IServiceCollection services){ services.AddControllers(); services.AddRefitClient&lt;ICountryApi&gt;(settings) .ConfigureHttpClient(c =&gt; c.BaseAddress = new Uri(Configuration[&quot;MyRefitOptions:BaseAddress&quot;])) ;} Use it inside a controller as following 123456789101112131415161718[ApiController][Route(&quot;[controller]&quot;)]public class CountryController : ControllerBase{ private readonly ICountryApi _countryApi; public CountryController(ICountryApi countryApi) { _countryApi = countryApi; } [HttpGet] public IEnumerable&lt;Country&gt; Get() { var countries = _countryApi.GetCountry(&quot;v2&quot;, &quot;usa&quot;).GetAwaiter().GetResult(); return countries; }} Using Refit with the System.Text.JsonUsing Refit with the new System.Text.Json APIs in .NET Core 3.0 to boost performance: 12345678910111213141516using System.Text.Json;var options = new JsonSerializerOptions(){ PropertyNamingPolicy = JsonNamingPolicy.CamelCase, WriteIndented = true,};var settings = new RefitSettings(){ ContentSerializer = new SystemTextJsonContentSerializer(options)};services.AddRefitClient&lt;ICountryApi&gt;(settings /*HERE*/) .ConfigureHttpClient(c =&gt; c.BaseAddress = new Uri(Configuration[&quot;MyRefitOptions:BaseAddress&quot;])) ; Polly123Install-Package Polly -Version 7.2.1dotnet add package Polly --version 7.2.1&lt;PackageReference Include=&quot;Polly&quot; Version=&quot;7.2.1&quot; /&gt; Polly is a .NET resilience and transient-fault-handling library that allows developers to express policies such as Retry, Circuit Breaker, Timeout, Bulkhead Isolation, and Fallback in a fluent and thread-safe manner. There are many topics in which you can use Polly and for this you should refer to its site. But one of the most important reasons for using Polly is the retry process. Retry 12345678910111213141516171819202122232425262728// Retry oncePolicy .Handle&lt;SomeExceptionType&gt;() .Retry()// Retry multiple timesPolicy .Handle&lt;SomeExceptionType&gt;() .Retry(3)// Retry multiple times, calling an action on each retry // with the current exception and retry countPolicy .Handle&lt;SomeExceptionType&gt;() .Retry(3, onRetry: (exception, retryCount) =&gt; { // Add logic to be executed before each retry, such as logging });// Retry multiple times, calling an action on each retry // with the current exception, retry count and context // provided to Execute()Policy .Handle&lt;SomeExceptionType&gt;() .Retry(3, onRetry: (exception, retryCount, context) =&gt; { // Add logic to be executed before each retry, such as logging }); Retry forever (until succeeds) 12345678910111213141516171819202122// Retry foreverPolicy .Handle&lt;SomeExceptionType&gt;() .RetryForever()// Retry forever, calling an action on each retry with the // current exceptionPolicy .Handle&lt;SomeExceptionType&gt;() .RetryForever(onRetry: exception =&gt; { // Add logic to be executed before each retry, such as logging });// Retry forever, calling an action on each retry with the// current exception and context provided to Execute()Policy .Handle&lt;SomeExceptionType&gt;() .RetryForever(onRetry: (exception, context) =&gt; { // Add logic to be executed before each retry, such as logging }); Wait and retry 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697// Retry, waiting a specified duration between each retry. // (The wait is imposed on catching the failure, before making the next try.)Policy .Handle&lt;SomeExceptionType&gt;() .WaitAndRetry(new[] { TimeSpan.FromSeconds(1), TimeSpan.FromSeconds(2), TimeSpan.FromSeconds(3) });// Retry, waiting a specified duration between each retry, // calling an action on each retry with the current exception// and durationPolicy .Handle&lt;SomeExceptionType&gt;() .WaitAndRetry(new[] { TimeSpan.FromSeconds(1), TimeSpan.FromSeconds(2), TimeSpan.FromSeconds(3) }, (exception, timeSpan) =&gt; { // Add logic to be executed before each retry, such as logging }); // Retry, waiting a specified duration between each retry, // calling an action on each retry with the current exception, // duration and context provided to Execute()Policy .Handle&lt;SomeExceptionType&gt;() .WaitAndRetry(new[] { TimeSpan.FromSeconds(1), TimeSpan.FromSeconds(2), TimeSpan.FromSeconds(3) }, (exception, timeSpan, context) =&gt; { // Add logic to be executed before each retry, such as logging });// Retry, waiting a specified duration between each retry, // calling an action on each retry with the current exception, // duration, retry count, and context provided to Execute()Policy .Handle&lt;SomeExceptionType&gt;() .WaitAndRetry(new[] { TimeSpan.FromSeconds(1), TimeSpan.FromSeconds(2), TimeSpan.FromSeconds(3) }, (exception, timeSpan, retryCount, context) =&gt; { // Add logic to be executed before each retry, such as logging });// Retry a specified number of times, using a function to // calculate the duration to wait between retries based on // the current retry attempt (allows for exponential backoff)// In this case will wait for// 2 ^ 1 = 2 seconds then// 2 ^ 2 = 4 seconds then// 2 ^ 3 = 8 seconds then// 2 ^ 4 = 16 seconds then// 2 ^ 5 = 32 secondsPolicy .Handle&lt;SomeExceptionType&gt;() .WaitAndRetry(5, retryAttempt =&gt; TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)) );// Retry a specified number of times, using a function to // calculate the duration to wait between retries based on // the current retry attempt, calling an action on each retry // with the current exception, duration and context provided // to Execute()Policy .Handle&lt;SomeExceptionType&gt;() .WaitAndRetry( 5, retryAttempt =&gt; TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)), (exception, timeSpan, context) =&gt; { // Add logic to be executed before each retry, such as logging } );// Retry a specified number of times, using a function to // calculate the duration to wait between retries based on // the current retry attempt, calling an action on each retry // with the current exception, duration, retry count, and context // provided to Execute()Policy .Handle&lt;SomeExceptionType&gt;() .WaitAndRetry( 5, retryAttempt =&gt; TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)), (exception, timeSpan, retryCount, context) =&gt; { // Add logic to be executed before each retry, such as logging } ); Wait and retry forever (until succeeds) 12345678910111213141516171819202122232425262728// Wait and retry foreverPolicy .Handle&lt;SomeExceptionType&gt;() .WaitAndRetryForever(retryAttempt =&gt; TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)) );// Wait and retry forever, calling an action on each retry with the // current exception and the time to waitPolicy .Handle&lt;SomeExceptionType&gt;() .WaitAndRetryForever( retryAttempt =&gt; TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)), (exception, timespan) =&gt; { // Add logic to be executed before each retry, such as logging });// Wait and retry forever, calling an action on each retry with the// current exception, time to wait, and context provided to Execute()Policy .Handle&lt;SomeExceptionType&gt;() .WaitAndRetryForever( retryAttempt =&gt; TimeSpan.FromSeconds(Math.Pow(2, retryAttempt)), (exception, timespan, context) =&gt; { // Add logic to be executed before each retry, such as logging }); Therefore, according to the above examples, we can implement our scenario as follows to see if the requested country is valid or not. 123456789101112131415161718192021222324252627282930313233using Polly;using System.Net;using System.Net.Http;[ApiController][Route(&quot;[controller]&quot;)]public class CountryController : ControllerBase{ private readonly IHttpClientFactory _httpClientFactory; public CountryController(IHttpClientFactory httpClientFactory) { _httpClientFactory = httpClientFactory; } // http://localhost:5000/Country?country=usa // Result: true [HttpGet] public async Task&lt;bool&gt; IsValid(string country) { var retryPolicy = Policy .Handle&lt;HttpRequestException&gt;() .WaitAndRetryAsync(5, _ =&gt; TimeSpan.FromSeconds(2)); var result = await retryPolicy.ExecuteAsync(async () =&gt; { var status = await _httpClientFactory.CreateClient().GetAsync($&quot;https://restcountries.eu/rest/v2/name/{country}&quot;).ConfigureAwait(false); return status.StatusCode == HttpStatusCode.OK; }); return result; }} Polly &amp; HttpClientFactoryThe following steps show how you can use Http retries with Polly integrated into IHttpClientFactory, which is explained in the previous section. Install the below package 123Install-Package Microsoft.Extensions.Http.Polly -Version 3.1.8dotnet add package Microsoft.Extensions.Http.Polly --version 3.1.8&lt;PackageReference Include=&quot;Microsoft.Extensions.Http.Polly&quot; Version=&quot;3.1.8&quot; /&gt; Register your Polly policy to HttpClient client 1234567891011121314public void ConfigureServices(IServiceCollection services){ services.AddControllers(); // HERE AsyncRetryPolicy&lt;HttpResponseMessage&gt; retryPolicy = HttpPolicyExtensions .HandleTransientHttpError() .OrResult(msg =&gt; msg.StatusCode == System.Net.HttpStatusCode.NotFound) .WaitAndRetryAsync(6, retryAttempt =&gt; TimeSpan.FromSeconds(Math.Pow(2, retryAttempt))); services.AddHttpClient&lt;IBasketService, BasketService&gt;() .SetHandlerLifetime(TimeSpan.FromMinutes(5)) //Set lifetime to five minutes .AddPolicyHandler(retryPolicy); // HERE} Polly &amp; RefitInstall the below package 123Install-Package Microsoft.Extensions.Http.Polly -Version 3.1.8dotnet add package Microsoft.Extensions.Http.Polly --version 3.1.8&lt;PackageReference Include=&quot;Microsoft.Extensions.Http.Polly&quot; Version=&quot;3.1.8&quot; /&gt; Register your Polly policy to Refit client 1234567891011121314151617181920212223242526public void ConfigureServices(IServiceCollection services){ services.AddControllers(); // HERE AsyncRetryPolicy&lt;HttpResponseMessage&gt; retryPolicy = HttpPolicyExtensions .HandleTransientHttpError() .Or&lt;TimeoutRejectedException&gt;() // Thrown by Polly's TimeoutPolicy if the inner call gets timeout. .OrResult(msg =&gt; msg.StatusCode == System.Net.HttpStatusCode.NotFound) .WaitAndRetryAsync(6, retryAttempt =&gt; TimeSpan.FromSeconds(Math.Pow(2, retryAttempt))); var options = new JsonSerializerOptions() { PropertyNamingPolicy = JsonNamingPolicy.CamelCase, WriteIndented = true, }; var settings = new RefitSettings() { ContentSerializer = new SystemTextJsonContentSerializer(options) }; services.AddRefitClient&lt;ICountryApi&gt;(settings) .ConfigureHttpClient(c =&gt; c.BaseAddress = new Uri(Configuration[&quot;MyRefitOptions:BaseAddress&quot;])) .AddPolicyHandler(retryPolicy) /*HERE*/ ;} Reference(s)Most of the information in this article has gathered from various references. https://json2csharp.com/ https://github.com/App-vNext/Polly https://github.com/reactiveui/refit https://github.com/19balazs86/PlayingWithRefit https://github.com/App-vNext/Polly.Extensions.Http https://anthonygiretti.com/2019/08/31/building-a-typed-httpclient-with-refit-in-asp-net-core-3/ https://blog.martincostello.com/refit-and-system-text-json/ https://www.talkingdotnet.com/3-ways-to-use-httpclientfactory-in-asp-net-core-2-1/ https://docs.microsoft.com/en-us/dotnet/architecture/microservices/implement-resilient-applications/implement-http-call-retries-exponential-backoff-polly","link":"/a-professional-asp.net-core-api-external-apis/"},{"title":"A Professional ASP.NET Core API - Feature Management","text":"The .NET Core Feature Management libraries provide idiomatic support for implementing feature flags in a .NET or ASP.NET Core application. These libraries allow you to declaratively add feature flags to your code so that you don’t have to write all the if statements for them manually. Install the below packages 1234567Install-Package Microsoft.FeatureManagement -Version 2.2.0dotnet add package Microsoft.FeatureManagement --version 2.2.0&lt;PackageReference Include=&quot;Microsoft.FeatureManagement&quot; Version=&quot;2.2.0&quot; /&gt;Install-Package Microsoft.FeatureManagement.AspNetCore -Version 2.2.0dotnet add package Microsoft.FeatureManagement.AspNetCore --version 2.2.0&lt;PackageReference Include=&quot;Microsoft.FeatureManagement.AspNetCore&quot; Version=&quot;2.2.0&quot; /&gt; The .NET Core feature manager IFeatureManager gets feature flags from the framework’s native configuration system. As a result, you can define your application’s feature flags by using any configuration source that .NET Core supports, including the local appsettings.json file or environment variables. IFeatureManager relies on .NET Core dependency injection. You can register the feature management services by using standard conventions: 1234567891011// Startup.ConfigureServicesusing Microsoft.FeatureManagement;public class Startup{ public void ConfigureServices(IServiceCollection services) { services.AddFeatureManagement(); }} By default, the feature manager retrieves feature flags from the “FeatureManagement” section of the .NET Core configuration data (appsettings.json). 123&quot;FeatureManagement&quot;: { &quot;MoreResults&quot;: true} The following example tells the feature manager to read from a different section called “MyFeatureFlags” instead: 1234567891011121314// Startup.ConfigureServicesusing Microsoft.FeatureManagement;public class Startup{ public void ConfigureServices(IServiceCollection services) { services.AddFeatureManagement(options =&gt; { options.UseConfiguration(Configuration.GetSection(&quot;MyFeatureFlags&quot;)); }); }} 123&quot;MyFeatureFlags&quot;: { &quot;MoreResults&quot;: true} Adding simple feature flagsThe IFeatureManager service allows you to interrogate the feature management system to identify whether a feature flag is enabled or not. IFeatureManager exposes a single method, for checking whether a feature flag is enabled: 12345678910111213141516171819202122232425262728293031323334353637383940[ApiController][Route(&quot;[controller]&quot;)]public class WeatherForecastController : ControllerBase{ private readonly IFeatureManager _featureManager; private static readonly string[] Summaries = new[] { &quot;Freezing&quot;, &quot;Bracing&quot;, &quot;Chilly&quot;, &quot;Cool&quot;, &quot;Mild&quot;, &quot;Warm&quot;, &quot;Balmy&quot;, &quot;Hot&quot;, &quot;Sweltering&quot;, &quot;Scorching&quot; }; public WeatherForecastController(IFeatureManager featureManager /* HERE */) { _featureManager = featureManager; } [HttpGet] public IEnumerable&lt;WeatherForecast&gt; Get() { var rng = new Random(); IEnumerable&lt;int&gt; range = null; // HERE if (_featureManager.IsEnabledAsync(&quot;MoreResults&quot;).GetAwaiter().GetResult()) { range = Enumerable.Range(1, 50); } else { range = Enumerable.Range(1, 5); } return range.Select(index =&gt; new WeatherForecast { Date = DateTime.Now.AddDays(index), TemperatureC = rng.Next(-20, 55), Summary = Summaries[rng.Next(Summaries.Length)] }) .ToArray(); }} Avoid stringsFeature flags are identified in code using magic-strings: “MoreResults” in the previous example. Instead of scattering these around your code, the official docs recommend creating a FeatureFlags enum, and calling nameof() to reference the values, e.g: 123456789// Define your flags in an enum// Be careful not to refactor/rename any typos, as that will break configurationpublic enum FeatureFlags{ MoreResults}// Reference the feature flags using nameof()var isEnabled = await _featureManager.IsEnabledAsync(nameof(FeatureFlags.MoreResults)); Static class Using a static class and string constants, it reduces the verbosity at the call site. 123456789// Using a static class separates the &quot;name&quot; of the feature flag// from its string valuepublic static class FeatureFlags{ public const string MoreResults = &quot;MoreResults&quot;;}// No need for nameof() at the call sitevar isEnabled = await _featureManager.IsEnabledAsync(FeatureFlags.MoreResults); FeatureGateWe can block access to entire controllers or action methods using the FeatureGate action filter. 1234567891011121314// BetaController.csusing Microsoft.AspNetCore.Mvc;using Microsoft.FeatureManagement.Mvc;// HERE[FeatureGate(&quot;Beta&quot;)] // Beta feature flag must be enabledpublic class BetaController : Controller{ public IActionResult Index() { return View(); }} If you try to navigate to this page (/Beta) when the feature is enabled, you’ll see the View rendered. However, if the Beta feature flag is disabled, you’ll get a 404 when trying to view the page: The [FeatureGate] attribute takes an array of feature flags, in its constructor. If any of those features are enabled, the controller is enabled. 12345678[FeatureGate(&quot;Beta&quot;, &quot;Alpha&quot;)]public class BetaController : Controller{ public IActionResult Index() { return View(); }} Custom handling of missing actionsIf an action is removed due to a feature being disabled, the default is to generate a 404 response. That may be fine for some applications, especially if you’re using error handling middleware to customise error responses to avoid ugly “raw” 404. However, it’s also possible that you may want to generate a different response in this situation. Maybe you want to redirect users to a “stable” page, return a “join the waiting list” view, or simply return a different response, like a 403 Forbidden. You can achieve any of these approaches by creating a service that implements the IDisabledFeaturesHandler interface. Implementers are invoked as part of the action filter pipeline, when an action method is “removed” due to a feature being disabled. In the example below, I show how to generate a 403 Forbidden response, but you have access to the whole ActionExecutingContext in the method, so you can do anything you can in a standard action filter: 12345678910using Microsoft.FeatureManagement.Mvc;public class RedirectDisabledFeatureHandler : IDisabledFeaturesHandler{ public Task HandleDisabledFeatures(IEnumerable&lt;string&gt; features, ActionExecutingContext context) { context.Result = new ForbidResult(); // generate a 403 return Task.CompletedTask; }} To register the handler, update your call to AddFeatureManagement(): 123456789101112// Startup.ConfigureServicesusing Microsoft.FeatureManagement;public class Startup{ public void ConfigureServices(IServiceCollection services) { services.AddFeatureManagement() .UseDisabledFeaturesHandler(new RedirectDisabledFeatureHandler()); /* HERE */ }} With the handler registered, if you now try to access a disabled feature, a 403 response is generated, which is intercepted by the error handling middleware, and you’re redirected to the “Access Denied” page for the app: RazorYou can use feature flags inside your Views. Dependency injection You can inject the IFeatureManager service into views using dependency injection. You could use the @inject directive, and check for the feature manually: 1234567891011121314 &lt;!-- Inject the service using DI --&gt;@inject Microsoft.FeatureManagement.IFeatureManager _featureManager; &lt;nav&gt; &lt;ul&gt; &lt;!-- Check if the feature is enabled --&gt; @if (await _featureManager.IsEnabledAsync(FeatureFlags.PromotionDiscounts)) { &lt;li class=&quot;nav-item&quot;&gt; &lt;a class=&quot;nav-link text-dark&quot; asp-controller=&quot;PromotionDiscount&quot; asp-action=&quot;Index&quot;&gt;Discount&lt;/a&gt; &lt;/li&gt; } &lt;/ul&gt;&lt;/nav&gt; Using Tag Helper If you have any UI elements you want to hide under feature flags you can use the tag helper provided in Microsoft.FeatureManagement.AspNetCore library to do that. First, you need to add the tag helper to the _ViewImports.cshtml so your views can access it. 1@addTagHelper *, Microsoft.FeatureManagement.AspNetCore Next, you can use &lt;feature&gt; tag helper to wrap the UI elements you want to put behind a feature flag. 12345678910111213@model HomeViewModel@{ ViewData[&quot;Title&quot;] = &quot;Home Page&quot;;}&lt;div class=&quot;text-center&quot;&gt; &lt;feature name=&quot;@Features.PromotionDiscounts&quot; negate=&quot;true&quot;&gt;&lt;h1 class=&quot;display-4&quot;&gt;Enjoy the latest music from your favorite artist&lt;/h1&gt;&lt;/feature&gt; &lt;feature name=&quot;@Features.PromotionDiscounts&quot;&gt;&lt;h1 class=&quot;display-4&quot;&gt;Enjoy 25% off for selected albums from your favorite artist&lt;/h1&gt;&lt;/feature&gt; &lt;feature name=&quot;@Features.UserSuggestions&quot;&gt; &lt;partial name=&quot;_UserSuggestionsPartial&quot; model=&quot;@Model.Suggestions&quot; /&gt; &lt;/feature&gt;&lt;/div&gt; We can use negate attribute and set it to true if you want to show the content between feature tag helper when the feature is disabled. Dynamic FeaturesWe introduce feature filters, which are a much more powerful way of working with feature flags. These let you enable a feature based on arbitrary data. For example, you could enable a feature based on headers in an incoming request, based on the current time, or based on the current user’s claims. 12345{ &quot;FeatureManagement&quot;: { &quot;Beta&quot;: false }} With this configuration, the Beta feature flag is always false for all users (until configuration changes). While this will be useful in some cases, you may often want to enable features for only some of your users, or only some of the time. Microsoft.FeatureManagement introduces an interface IFeatureFilter which can be used to decide whether a feature is enabled or not based on any logic you require. Enabling a feature flag based on the current time with TimeWindowFilter The TimeWindowFilter does as its name suggests - it enables a feature for a given time window. You provide the start and ending DateTime, and any calls to IFeatureManager.IsEnabledAsync() for the feature will be true only between those times. Add the feature management services in Startup.ConfigureServices, by calling AddFeatureManagement(), which returns an IFeatureManagementBuilder. You can enable the time window filter by calling AddFeatureFilter&lt;&gt;() on the builder: 12345678910111213// Startup.ConfigureServicesusing Microsoft.FeatureManagement;using Microsoft.FeatureManagement.FeatureFilters;public class Startup { public void ConfigureServices(IServiceCollection services) { services.AddFeatureManagement() .AddFeatureFilter&lt;TimeWindowFilter&gt;(); // HERE }} This adds the IFeatureFilter to your app, but you need to configure it using the configuration system. Each IFeatureFilter can have an associated “settings” object, depending on the implementation. For the TimeWindowFilter, this looks like: 1234567// TimeWindowSettings.cspublic class TimeWindowSettings{ public DateTimeOffset? Start { get; set; } public DateTimeOffset? End { get; set; }} So let’s consider a scenario: I want to enable a custom Christmas banner which goes live on boxing day at 2am UTC, and ends three days later at 1am UTC. We’ll start by creating a feature flag for it in code called ChristmasBanner 1234public static class FeatureFlags{ public const string ChristmasBanner = &quot;ChristmasBanner&quot;;} Now we’ll add the configuration. As before, we nest the configuration under the FeatureManagement key and provide the name of the feature. However, instead of using a Boolean for the feature, we use EnabledFor, and specify an array of feature filters. 12345678910111213&quot;FeatureManagement&quot;: { &quot;ChristmasBanner&quot;: { &quot;EnabledFor&quot;: [ { &quot;Name&quot;: &quot;Microsoft.TimeWindow&quot;, &quot;Parameters&quot;: { &quot;Start&quot;: &quot;26 Dec 2019 02:00:00 +00:00&quot;, &quot;End&quot;: &quot;29 Dec 2019 01:00:00 +00:00&quot; } } ] }} It’s important you get the configuration correct here. The general pattern is identical for all feature filters: The feature name (“ChristmasBanner”) should be the key of an object: This object should contains a single property, EnabledFor, which is an array of objects. Each of the objects in the array represents an IFeatureFilter. For each filter Provide the Name of the filter (“Microsoft.TimeWindow” for the TimeWindowFilter) Optionally provide a Parameters object, which is bound to the settings object of the feature filter (TimeWindowSettings in this case). If any of the feature filters in the array are satisfied for a given request, the feature is enabled. It is only disabled if all IFeatureFilters indicate it should be disabled. With this configuration, the ChristmasBanner feature flag will return false until DateTime.UtcNow falls between the provided dates: 12345678910111213141516// WeatherForecastController.csusing Microsoft.FeatureManagement;[ApiController][Route(&quot;[controller]&quot;)]public class WeatherForecastController : ControllerBase{ private readonly IFeatureManager _featureManager; public WeatherForecastController(IFeatureManager featureManager) { _featureManager = featureManager; // only returns true during provided time window var showBanner = await _featureManager.IsEnabledAsync(FeatureFlags.ChristmasBanner); }} The real benefit to using IFeatureFilters is that you get dynamic behaviour, but you can still control it from configuration. Note: that TimeWindowSettings has nullable values for Start and End, to give you open-ended time windows e.g. always enable until a given date, or only enable from a given date. Rolling features out slowly with PercentageFilter The PercentageFilter also behaves as you might expect - it only enables a feature for x percent of requests, where x is controlled via settings. Enabling the PercentageFilter follows the same procedure as for TimeWindowFilter. 12345678910111213// Startup.ConfigureServicesusing Microsoft.FeatureManagement;using Microsoft.FeatureManagement.FeatureFilters;public class Startup { public void ConfigureServices(IServiceCollection services) { services.AddFeatureManagement() .AddFeatureFilter&lt;PercentageFilter&gt;(); // HERE }} Create a feature flag: 1234public static class FeatureFlags{ public const string FancyFonts = &quot;FancyFonts&quot;;} Configure the feature in configuration: 123456789101112&quot;FeatureManagement&quot;: { &quot;FancyFonts&quot;: { &quot;EnabledFor&quot;: [ { &quot;Name&quot;: &quot;Microsoft.Percentage&quot;, &quot;Parameters&quot;: { &quot;Value&quot;: 10 } } ] }} The PercentageSettings object consists of a single int, which is the percentage of the time the flag should be enabled. In the example above, the flag will be enabled for 10% of calls to IFeatureManager.IsEnabledAsync(FeatureFlags.FancyFonts). Creating a custom IFeatureFilterThe example in this post looks for a Claim in the currently logged-in user’s ClaimsPrincipal and enables a feature flag if it’s present. You could use this filter to enable a feature for a subset of your users. Creating a custom feature filter requires two things: Create a class that derives from IFeatureFilter. Optionally create a settings class to control your feature filter. Creating the filter settings class For this example, we want to enable a feature for only those users that have a certain set of claims. For simplicity, I’m only going to require the presence of a claim type and ignore the claim’s value, but extending the example in this post should be simple enough. The settings object contains an array of claim types: 1234public class ClaimsFilterSettings{ public string[] RequiredClaims { get; set; }} Implementing IFeatureFilter To create a feature filter, you must implement the IFeatureFilter interface, which consists of a single method: 1234public interface IFeatureFilter{ bool Evaluate(FeatureFilterEvaluationContext context);} The FeatureFilterEvaluationContext argument passed in to the method contains the name of the feature requested, and an IConfiguration object that allows you to access the settings for the feature: 12345public class FeatureFilterEvaluationContext{ public string FeatureName { get; set; } public IConfiguration Parameters { get; set; }} It’s worth noting that there’s nothing specific to ASP.NET Core here - there’s no HttpContext, and no IServiceProvider. Luckily, your class is pulled from the DI container, so you should be able to get everything you need in your feature filter’s constructor. Creating the custom feature filter In order to implement our custom feature filter, we need to know who the current user is for the request. To do so, we need to access the HttpContext. The correct way to do that (when you don’t have direct access to it as you do in MVC controllers etc) is to use the IHttpContextAccessor. The ClaimsFeatureFilter below takes an IHttpContextAccessor in its constructor and uses the exposed HttpContext to retrieve the current user from the request. 12345678910111213141516171819202122232425[FilterAlias(&quot;Claims&quot;)] // How we will refer to the filter in configurationpublic class ClaimsFeatureFilter : IFeatureFilter{ // Used to access HttpContext private readonly IHttpContextAccessor _httpContextAccessor; public ClaimsFeatureFilter(IHttpContextAccessor httpContextAccessor) { _httpContextAccessor = httpContextAccessor; } public bool Evaluate(FeatureFilterEvaluationContext context) { // Get the ClaimsFilterSettings from configuration var settings = context.Parameters.Get&lt;ClaimsFilterSettings&gt;(); // Retrieve the current user (ClaimsPrincipal) var user = _httpContextAccessor.HttpContext.User; // Only enable the feature if the user has ALL the required claims var isEnabled = settings.RequiredClaims .All(claimType =&gt; user.HasClaim(claim =&gt; claim.Type == claimType)); return isEnabled; }} I named this feature filter “Claims” using the [FilterAlias] attribute. This is the string you need to add in configuration to enable the filter, as you’ll see shortly. You can retrieve the ClaimsFilterSettings associated with a given instance of the custom feature filter by calling context.Parameters.Get&lt;&gt;(). The logic of the filter is relatively straightforward - if the ClaimsPrincipal for the request has all of the required claims, the associated feature is enabled, otherwise the feature is disabled. Using the custom feature filter To use the custom feature filter, you must explicitly register it with the feature management system in Startup.ConfigureServices(). We also need to make sure the IHttpContextAccessor is available in DI: 1234567891011121314using Microsoft.FeatureManagement;public class Startup { public void ConfigureServices(IServiceCollection services) { // Add IHttpContextAccessor if it's not yet added services.AddHttpContextAccessor(); services.AddFeatureManagement() // HERE .AddFeatureFilter&lt;ClaimsFeatureFilter&gt;(); // add our custom filter }} That’s all the custom configuration needed to enable our ClaimsFeatureFilter. To actually use it in an app, we’ll add a feature flag called “Beta”: 1234public static class FeatureFlags{ public const string Beta = &quot;Beta&quot;;} and enable the filter in configuration using the format: 123456789101112&quot;FeatureManagement&quot;: { &quot;Beta&quot;: { &quot;EnabledFor&quot;: [ { &quot;Name&quot;: &quot;Claims&quot;, &quot;Parameters&quot;: { &quot;RequiredClaims&quot;: [ &quot;Internal&quot; ] } } ] }} Notice that I’ve used the [FilterAlias] value of “Claims” as the filter’s Name. The Parameters object corresponds to the ClaimsFilterSettings settings object. With this configuration, user’s who have the “Internal” claim will have the Beta feature flag enabled - other user’s will find it’s disabled. Testing the ClaimsFeatureFilter To test out the feature filter, it’s easiest to start with an ASP.NET Core app that has individual authentication enabled. For demonstration purposes, I updated the home page Index.cshtml to show a banner when the Beta feature flag is enabled using the FeatureTagHelper: 1234567891011121314@page@model IndexModel@{ ViewData[&quot;Title&quot;] = &quot;Home page&quot;;}&lt;!-- Only visible when Beta feature flag is enabled --&gt;&lt;feature name=&quot;@FeatureFlags.Beta&quot;&gt; &lt;div class=&quot;alert alert-primary&quot; role=&quot;alert&quot;&gt; Congratulations - You're in the Beta test! &lt;/div&gt;&lt;/feature&gt;&lt;!-- ... --&gt; Limitations with the ClaimsFeatureFilterThe custom feature filter ClaimsFeatureFilter described in this post is only intended as an example of a filter you could use. The reliance on HttpContext gives it a specific limitation: it can’t be used outside the context of an HTTP request. Attempting to access HttpContext outside of an HTTP request can result in a NullReferenceException. You also need to be careful about using it in a background thread, as HttpContext is not thread safe. One of the slightly dangerous implications of this is that consumers of the feature flags don’t necessarily know which features are safe to interrogate in which context. There’s nothing in the following code that suggests it could throw when used on a background thread, or in a hosted service. 1var isEnabled = await _featureManager.IsEnabledAsync(FeatureFlags.Beta); // may throw! One basic option to avoid this situation is to use naming conventions for your feature flags. For example, you could use a convention where feature flags prefixed with “UI_” are only considered “safe” to access when withan an HTTP request context. 1234567891011121314public static class FeatureFlags{ // These flags are safe to access in any context public const string NewBranding = &quot;NewBranding&quot;; public const string AlternativeColours = &quot;AlternativeColours&quot;; // These flags are only safe to access from an HttpContext-safe request public static class Ui { const string _prefix = &quot;UI_&quot;; public const string Beta = _prefix + &quot;Beta&quot;; public const string NewOnboardingExperiences = _prefix + &quot;NewOnboardingExperiences&quot;; }} This at least gives an indication to the caller when the flag is used. Obviously it requires you configure the flags correctly, but it’s a step in the right direction! 12345// Flags on the main FeatureFlags class are safe to use everywherevar isEnabled = await _featureManager.IsEnabledAsync(FeatureFlags.NewBranding); // Flags on the nested Ui class are only safe when HttpContext is availablevar isEnabled = await _featureManager.IsEnabledAsync(FeatureFlags.Ui.Beta); Reference(s)Most of the information in this article has gathered from various references. https://docs.microsoft.com/en-us/azure/azure-app-configuration/use-feature-flags-dotnet-core https://docs.microsoft.com/en-us/azure/azure-app-configuration/quickstart-feature-flag-aspnet-core http://dontcodetired.com/blog/post/Using-the-Microsoft-Feature-Toggle-Library-in-ASPNET-Core-(MicrosoftFeatureManagement) https://andrewlock.net/introducing-the-microsoft-featuremanagement-library-adding-feature-flags-to-an-asp-net-core-app-part-1/ https://andrewlock.net/filtering-action-methods-with-feature-flags-adding-feature-flags-to-an-asp-net-core-app-part-2/ https://andrewlock.net/creating-dynamic-feature-flags-with-feature-filters-adding-feature-flags-to-an-asp-net-core-app-part-3/ https://andrewlock.net/creating-a-custom-feature-filter-adding-feature-flags-to-an-asp-net-core-app-part-4/ https://andrewlock.net/keeping-consistent-feature-flags-across-requests-adding-feature-flags-to-an-asp-net-core-app-part-5/ https://kasunkodagoda.com/2020/01/16/implementing-feature-flags-for-asp-net-core-applications-using-microsoft-featuremanagement-library/","link":"/a-professional-asp.net-core-api-feature-management/"},{"title":"A Professional ASP.NET Core API - FluentValidation","text":"FluentValidation is a A .NET library for building strongly-typed validation rules. It uses lambda expressions for building validation rules for your business objects. If you want to do simple validation in asp.net mvc application then data annotations validation is good but in case if you want to implement complex validation then you need to use FluentValidation. In the following we will see how it can be added to a project and how it works. Install the below packages 1234567Install-Package FluentValidation -Version 9.2.2dotnet add package FluentValidation --version 9.2.2&lt;PackageReference Include=&quot;FluentValidation&quot; Version=&quot;9.2.2&quot; /&gt;Install-Package FluentValidation.AspNetCore -Version 9.2.0dotnet add package FluentValidation.AspNetCore --version 9.2.0&lt;PackageReference Include=&quot;FluentValidation.AspNetCore&quot; Version=&quot;9.2.0&quot; /&gt; Register FluentValidation as following 12345678public void ConfigureServices(IServiceCollection services){ services .AddControllers() // HERE .AddFluentValidation() ;} In order for ASP.NET to discover your validators, they must be registered with the services collection. You can either do this by calling the AddTransient method for each of your validators: 12345678910public void ConfigureServices(IServiceCollection services){ services .AddControllers() // HERE .AddFluentValidation() ; services.AddTransient&lt;IValidator&lt;Person&gt;, PersonValidator&gt;(); } Using the validator in a controller 123456789101112131415public class Person { public int Id { get; set; } public string Name { get; set; } public string Email { get; set; } public int Age { get; set; }}public class PersonValidator : AbstractValidator&lt;Person&gt; { public PersonValidator() { RuleFor(x =&gt; x.Id).NotNull(); RuleFor(x =&gt; x.Name).Length(6, 16); RuleFor(x =&gt; x.Email).EmailAddress(); RuleFor(x =&gt; x.Age).InclusiveBetween(18, 60); }} We can use the Person class within our controller and associated view: 12345678910111213141516171819202122232425[ApiController][Route(&quot;[controller]&quot;)]public class WeatherForecastController : ControllerBase{ /* { &quot;id&quot;: 1, &quot;name&quot;: &quot;hamed&quot;, &quot;email&quot;: &quot;hamedfathi@outlook.com&quot;, &quot;age&quot;: 32 } */ [HttpPost] public IActionResult Create(Person person) { if (ModelState.IsValid) { return Ok(); } else { return NotFound(); } }} Now, If you call the Create API with above JSON data you will see the below result 1234567891011{ &quot;type&quot;: &quot;https://tools.ietf.org/html/rfc7231#section-6.5.1&quot;, &quot;title&quot;: &quot;One or more validation errors occurred.&quot;, &quot;status&quot;: 400, &quot;traceId&quot;: &quot;|4e6b48f8-4d5461460c3f9b04.&quot;, &quot;errors&quot;: { &quot;Name&quot;: [ &quot;'Name' must be between 6 and 16 characters. You entered 5 characters.&quot; ] }} Automatic RegistrationYou can also use the below methods to automatically register all validators within a particular assembly. This will automatically find any public, non-abstract types that inherit from AbstractValidator and register them with the container (open generics are not supported). 123456789101112131415161718public void ConfigureServices(IServiceCollection services){ services .AddControllers() .AddFluentValidation(options =&gt; { // HERE options.RegisterValidatorsFromAssembly(Assembly.GetExecutingAssembly()); // OR options.RegisterValidatorsFromAssemblyContaining&lt;Startup&gt;(); // OR options.RegisterValidatorsFromAssemblyContaining&lt;PersonValidator&gt;(); // OR options.RegisterValidatorsFromAssemblyContaining&lt;PersonValidator&gt;(lifetime:ServiceLifetime.Singleton); // OR options.RegisterValidatorsFromAssemblyContaining&lt;PersonValidator&gt;(discoveredType =&gt; discoveredType.ValidatorType != typeof(SomeValidatorToExclude)); });} Compatibility with ASP.NET’s built-in ValidationBy default, after FluentValidation is executed, any other validator providers will also have a chance to execute. This means you can mix FluentValidation with DataAnnotations attributes (or any other ASP.NET ModelValidatorProvider implementation). If you want to disable this behaviour so that FluentValidation is the only validation library that executes, you can set the RunDefaultMvcValidationAfterFluentValidationExecutes to false in your application startup routine: 12345678910public void ConfigureServices(IServiceCollection services){ services .AddControllers() .AddFluentValidation(options =&gt; { // HERE options.RunDefaultMvcValidationAfterFluentValidationExecutes = false; });} Built-in Validators NotNull (&quot;NotNull&quot;): to check the property is null. NotEmpty (&quot;NotEmpty&quot;): to check the property is null, empty or has whitespace. NotEqual (&quot;NotEqual&quot;): to check the specified property is not equal to a particular value. Equal Validator (&quot;Equal&quot;): to check the value of the specified property is equal to a particular value. Length Validator (&quot;Length&quot;): to check the length of a particular string property is within the specified range. MaxLength Validator (&quot;MaximumLength&quot;): to check the length of a particular string property is no longer than the * specified value. MinLength Validator (&quot;MinimumLength&quot;): to check the length of a particular string property is longer than the * specified value. Less Than Validator (&quot;LessThan&quot;): to check the length of the specified property is less than a particular value LessThanOrEqual Validator (&quot;LessThanOrEqualTo&quot;): to check the value of the specified property is less than or * equal to a particular value. Greater Than Validator (&quot;GreaterThan&quot;): to check the value of the specified property is greater than a particular * value. Regular Expression Validator (&quot;Matches&quot;): to check the value of the specified property matches the given regular * expression. Email Validator Validator (&quot;EmailAddress&quot;): to check the value of the specified property is a valid email address. Implicit vs Explicit Child Property ValidationWhen validating complex object graphs, by default, you must explicitly specify any child validators for complex properties by using SetValidator. When running an ASP.NET MVC application, you can also optionally enable implicit validation for child properties. When this is enabled, instead of having to specify child validators using SetValidator, MVC’s validation infrastructure will recursively attempt to automatically find validators for each property. This can be done by setting ImplicitlyValidateChildProperties to true: 12345678910public void ConfigureServices(IServiceCollection services){ services .AddControllers() .AddFluentValidation(options =&gt; { // HERE options.ImplicitlyValidateChildProperties = true; });} Manual validationSometimes you may want to manually validate an object in a MVC project. In this case, the validation results can be copied to MVC’s modelstate dictionary: 1234567891011121314151617181920212223[HttpPost]public async Task&lt;IActionResult&gt; Create(){ TesterValidator validator = new TesterValidator(); List&lt;string&gt; ValidationMessages = new List&lt;string&gt;(); var tester = new Tester { FirstName = &quot;&quot;, Email = &quot;bla!&quot; }; var validationResult = validator.Validate(tester); var response = new ResponseModel(); if (!validationResult.IsValid) { response.IsValid = false; foreach (ValidationFailure failure in validationResult.Errors) { ValidationMessages.Add(failure.ErrorMessage); } response.ValidationMessages = ValidationMessages; } return Ok(response);} Custom messagesWe can extend the above example to include a more useful error message. At the moment, our custom validator always returns the message “The list contains too many items” if validation fails. Instead, let’s change the message so it returns “’Pets’ must contain fewer than 10 items.” This can be done by using custom message placeholders. FluentValidation supports several message placeholders by default including {PropertyName} and {PropertyValue} (see this list for more), but we can also add our own. 12345678public class PersonValidator : AbstractValidator&lt;Person&gt; { public PersonValidator() { RuleFor(x =&gt; x.Id).NotNull().WithMessage(&quot;{PropertyName} should be not null. NEVER!&quot;);; RuleFor(x =&gt; x.Name).Length(6, 16); RuleFor(x =&gt; x.Email).EmailAddress(); RuleFor(x =&gt; x.Age).InclusiveBetween(18, 60); }} LocalizationYou can add IStringLocalizer&lt;T&gt; to the ctor of a validator 12345678910111213141516public class PersonValidator : AbstractValidator&lt;Person&gt;{ public PersonValidator(IStringLocalizer&lt;Person&gt; localizer /*HERE*/) { RuleFor(e =&gt; e.Name).MinimumLength(5) .WithMessage(e =&gt; string.Format(localizer[Name], nameof(e.Name) /* {0} placeholder */ )); RuleFor(e =&gt; e.FamilyName).MinimumLength(5) .WithMessage(e =&gt; string.Format(localizer[Name], nameof(e.Name) /* {0} placeholder */ )); RuleFor(e =&gt; e.Address).MinimumLength(10) .WithMessage(e =&gt; localizer[Address]); RuleFor(e =&gt; e.EmailAddress).EmailAddress() .WithMessage(e =&gt; localizer[EmailAddress]); RuleFor(e =&gt; e.Age).InclusiveBetween(20, 60) .WithMessage(e =&gt; localizer[Age]); }} And these are our resources 123456789101112131415161718192021222324// person.en-US.json{ &quot;Name&quot;: &quot;'{0}' must be at least 5 characters length.&quot;, &quot;Address&quot;: &quot;'Address' must be at least 10 characters length.&quot;, &quot;EmailAddress&quot;: &quot;'EmailAddress' is not valid.&quot;, &quot;Age&quot;: &quot;'Age' must be between 20 and 60.&quot;,}// person.de.json{ &quot;Name&quot;: &quot;'{0}' muss mindestens 5 Zeichen lang sein.&quot;, &quot;Address&quot;: &quot;'Address' muss mindestens 10 Zeichen lang sein.&quot;, &quot;EmailAddress&quot;: &quot;'EmailAddress' ist ungültig.&quot;, &quot;Age&quot;: &quot;'Age' muss zwischen 20 und 60 liegen.&quot;,}// person.fa-IR.json{ &quot;Country&quot;: &quot;کشور وارد شده معتبر نیست.&quot;, &quot;Name&quot;: &quot;{0} نباید کمتر از 5 کاراکتر باشد.&quot;, &quot;Address&quot;: &quot;آدرس نباید کمتر از 10 کاراکتر باشد.&quot;, &quot;EmailAddress&quot;: &quot;ایمیل وارد شده معتبر نیست.&quot;, &quot;Age&quot;: &quot;سن باید بین 20 تا 60 باشد.&quot;,} Swagger integrationUse FluentValidation rules instead of ComponentModel attributes to define swagger schema. Install below package 123Install-Package MicroElements.Swashbuckle.FluentValidation -Version 4.0.0dotnet add package MicroElements.Swashbuckle.FluentValidation --version 4.0.0&lt;PackageReference Include=&quot;MicroElements.Swashbuckle.FluentValidation&quot; Version=&quot;4.0.0&quot; /&gt; Change Startup.cs as following 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// Startup.cspublic void ConfigureServices(IServiceCollection services){ // HttpContextServiceProviderValidatorFactory requires access to HttpContext services.AddHttpContextAccessor(); services .AddControllers() // Adds fluent validators to Asp.net .AddFluentValidation(c =&gt; { c.RegisterValidatorsFromAssemblyContaining&lt;Startup&gt;(); //HERE // Optionally set validator factory if you have problems with scope resolve inside validators. c.ValidatorFactoryType = typeof(HttpContextServiceProviderValidatorFactory); }) services.AddSwaggerGen(c =&gt; { c.SwaggerDoc(&quot;v1&quot;, new OpenApiInfo { Title = &quot;My API&quot;, Version = &quot;v1&quot; }); // HERE // Adds fluent validation rules to swagger c.AddFluentValidationRules(); }); // Adds logging services.AddLogging(builder =&gt; builder.AddConsole());}// This method gets called by the runtime. Use this method to configure the HTTP request pipeline.public void Configure(IApplicationBuilder app, IHostingEnvironment env){ app.UseRouting(); app.UseEndpoints(endpoints =&gt; { endpoints.MapControllers(); }); // Adds swagger app.UseSwagger(); // Adds swagger UI app.UseSwaggerUI(c =&gt; { c.SwaggerEndpoint(&quot;/swagger/v1/swagger.json&quot;, &quot;My API V1&quot;); });} Extensibility You can register FluentValidationRule in ServiceCollection. User defined rule name replaces default rule with the same. Full list of default rules can be get by FluentValidationRules.CreateDefaultRules() List or default rules: Required NotEmpty Length Pattern Comparison Between Example of rule: 123456789new FluentValidationRule(&quot;Pattern&quot;){ Matches = propertyValidator =&gt; propertyValidator is IRegularExpressionValidator, Apply = context =&gt; { var regularExpressionValidator = (IRegularExpressionValidator)context.PropertyValidator; context.Schema.Properties[context.PropertyKey].Pattern = regularExpressionValidator.Expression; }}, Reference(s)Most of the information in this article has gathered from various references. https://docs.fluentvalidation.net/en/latest/index.html https://www.codewithmukesh.com/blog/fluent-validation-aspnet-core/ https://github.com/micro-elements/MicroElements.Swashbuckle.FluentValidation","link":"/a-professional-asp.net-core-api-fluent-validation/"},{"title":"A Professional ASP.NET Core API - Global Exception Handling","text":"ASP.NET Core gives provides the ability to write middleware, which is logic inserted into the pipeline that the framework runs for every request that is received by the application. ASP.NET Core ships with core middleware components that enable things like rendering MVC pages, defining endpoint routes, and adding authentication support, and these things are configured in the application’s Startup class, where you can also add your own custom middleware components. This ability to easily configure and customize how ASP.NET Core processes requests is tremendously useful and powerful. We will be creating exception-handling middleware to catch and handle any exceptions that are thrown during the execution of a request to our service. So, Create a model for your error details as below 123456789101112public class ExceptionResult{ public ExceptionResult(string exception, int statusCode, string requestId) { Exception = exception; StatusCode = statusCode; RequestId = requestId; } public string Exception { get; set; } public string RequestId { get; set; } public int StatusCode { get; set; }} Create the Global Exception middleware which will handle exceptions globally in your API 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263using Microsoft.AspNetCore.Hosting;using Microsoft.AspNetCore.Http;using Microsoft.Extensions.Hosting;using Microsoft.Extensions.Logging;using System;using System.Collections.Generic;using System.Net;using System.Text.Json;using System.Threading.Tasks;public class GlobalExceptionMiddleware{ private readonly RequestDelegate _next; private readonly ILogger&lt;GlobalExceptionMiddleware&gt; _logger; private readonly IWebHostEnvironment _env; public GlobalExceptionMiddleware(RequestDelegate next, ILogger&lt;GlobalExceptionMiddleware&gt; logger, IWebHostEnvironment env) { _next = next; _logger = logger; _env = env; } public async Task Invoke(HttpContext context) { string message = null; HttpStatusCode httpStatusCode = HttpStatusCode.InternalServerError; var requestId = Activity.Current?.Id ?? context.TraceIdentifier; try { await _next(context); } catch (Exception ex) { _logger.LogError($&quot;An unhandled exception has occurred while executing the request. {ex}&quot;); // ASPNETCORE_ENVIRONMENT = Development if (_env.IsDevelopment()) { var dic = new Dictionary&lt;string, string&gt; { [&quot;StackTrace&quot;] = ex.StackTrace, [&quot;Message&quot;] = ex.Message }; message = JsonSerializer.Serialize(dic); } else { message = &quot;An internal server error has occurred.&quot;; } await WriteToReponseAsync(); } async Task WriteToReponseAsync() { if (context.Response.HasStarted) throw new InvalidOperationException(&quot;The response has already started&quot;); var exceptionResult = new ExceptionResult(message, (int)httpStatusCode, requestId); var result = JsonSerializer.Serialize(exceptionResult); context.Response.StatusCode = (int)httpStatusCode; context.Response.ContentType = &quot;application/json&quot;; await context.Response.WriteAsync(result); } }} You may notice that the other middleware components all have custom extension methods to make adding them easy. Let’s add an extension method for our custom middleware too. 123456789using Microsoft.AspNetCore.Builder;public static class ExceptionHandlerMiddlewareExtension{ public static void UseGlobalException(this IApplicationBuilder app) { app.UseMiddleware&lt;GlobalExceptionMiddleware&gt;(); }} Register GlobalException middleware in your API. It should be before other middlewares to catch exceptions correctly. 123456789101112public void Configure(IApplicationBuilder app){ app.UseGlobalException(); // HERE app.UseHttpsRedirection(); app.UseRouting(); app.UseAuthorization(); app.UseEndpoints(endpoints =&gt; { endpoints.MapControllers(); });} Reference(s)Most of the information in this article has gathered from various references. https://blog.jonblankenship.com/2020/04/12/global-exception-handling-in-aspnet-core-api/ https://dotnetdocs.ir/Post/28/%D9%85%D8%AF%DB%8C%D8%B1%DB%8C%D8%AA-%D8%AE%D8%B7%D8%A7%D9%87%D8%A7-(-exception-handling-)-%D8%AF%D8%B1-asp.net-core-3.1","link":"/a-professional-asp.net-core-api-global-exception/"},{"title":"A Professional ASP.NET Core API - HealthCheck","text":"ASP.NET Core offers Health Checks Middleware and libraries for reporting the health of app infrastructure components. Health checks are exposed by an app as HTTP endpoints. Health check endpoints can be configured for a variety of real-time monitoring scenarios: Health probes can be used by container orchestrators and load balancers to check an app’s status. For example, a container orchestrator may respond to a failing health check by halting a rolling deployment or restarting a container. A load balancer might react to an unhealthy app by routing traffic away from the failing instance to a healthy instance. Use of memory, disk, and other physical server resources can be monitored for healthy status. Health checks can test an app’s dependencies, such as databases and external service endpoints, to confirm availability and normal functioning. Install the below package 123Install-Package Microsoft.AspNetCore.Diagnostics.HealthChecks -Version 2.2.0dotnet add package Microsoft.AspNetCore.Diagnostics.HealthChecks --version 2.2.0&lt;PackageReference Include=&quot;Microsoft.AspNetCore.Diagnostics.HealthChecks&quot; Version=&quot;2.2.0&quot; /&gt; To start working with HealthCheck system you should add configs as following 12345678910111213141516171819202122232425262728293031// Startup.cspublic class Startup{ public void ConfigureServices(IServiceCollection services) { services.AddControllers(); // HERE services.AddHealthChecks(); } public void Configure(IApplicationBuilder app, IWebHostEnvironment env) { if (env.IsDevelopment()) { app.UseDeveloperExceptionPage(); } app.UseRouting(); app.UseAuthorization(); app.UseEndpoints(endpoints =&gt; { endpoints.MapControllers(); // HERE endpoints.MapHealthChecks(&quot;/health&quot;); }); }} Now, You are able to browse http://localhost:PORT/health to see Healthy! Create health checksHealth checks are created by implementing the IHealthCheck interface. The CheckHealthAsync method returns a HealthCheckResult that indicates the health as Healthy, Degraded, or Unhealthy. The result is written as a plaintext response with a configurable status code. HealthCheckResult can also return optional key-value pairs. The following ExampleHealthCheck class demonstrates the layout of a health check. The health checks logic is placed in the CheckHealthAsync method. The following example sets a dummy variable, healthCheckResultHealthy, to true. If the value of healthCheckResultHealthy is set to false, the HealthCheckResult.Unhealthy status is returned. 1234567891011121314151617181920212223// ExampleHealthCheck.csusing System.Threading;using Microsoft.Extensions.Diagnostics.HealthChecks;public class ExampleHealthCheck : IHealthCheck{ public Task&lt;HealthCheckResult&gt; CheckHealthAsync( HealthCheckContext context, CancellationToken cancellationToken = default) { var healthCheckResultHealthy = true; if (healthCheckResultHealthy) { return Task.FromResult( HealthCheckResult.Healthy(&quot;A healthy result.&quot;)); } return Task.FromResult( HealthCheckResult.Unhealthy(&quot;An unhealthy result.&quot;)); }} Register health check servicesThe ExampleHealthCheck type is added to health check services with AddCheck in Startup.ConfigureServices: 1234567891011121314// Startup.ConfigureServices.cspublic class Startup{ public void ConfigureServices(IServiceCollection services) { services.AddControllers(); // HERE services.AddHealthChecks() .AddCheck&lt;ExampleHealthCheck&gt;(&quot;example_health_check&quot;) /* HERE */ ; }} Tags They can be used to filter health checks. 123456789101112131415// Startup.ConfigureServices.cspublic class Startup{ public void ConfigureServices(IServiceCollection services) { services.AddControllers(); services.AddHealthChecks() .AddCheck&lt;ExampleHealthCheck&gt;( &quot;example_health_check&quot;, failureStatus: HealthStatus.Degraded, tags: new[] { &quot;example&quot; }); }} AddCheck can also execute a lambda function. In the following example, the health check name is specified as Example and the check always returns a healthy state: 12345678910111213// Startup.ConfigureServices.cspublic class Startup{ public void ConfigureServices(IServiceCollection services) { services.AddControllers(); services.AddHealthChecks() .AddCheck(&quot;Example&quot;, () =&gt; HealthCheckResult.Healthy(&quot;Example is OK!&quot;), tags: new[] { &quot;example&quot; }); }} Health check with arguments Call AddTypeActivatedCheck to pass arguments to a health check implementation. In the following example, TestHealthCheckWithArgs accepts an integer and a string for use when CheckHealthAsync is called: 123456789101112131415161718public class TestHealthCheckWithArgs : IHealthCheck{ public TestHealthCheckWithArgs(int i, string s) { I = i; S = s; } public int I { get; set; } public string S { get; set; } public Task&lt;HealthCheckResult&gt; CheckHealthAsync(HealthCheckContext context, CancellationToken cancellationToken = default) { ... }} TestHealthCheckWithArgs is registered by calling AddTypeActivatedCheck with the integer and string passed to the implementation: 123456services.AddHealthChecks() .AddTypeActivatedCheck&lt;TestHealthCheckWithArgs&gt;( &quot;test&quot;, failureStatus: HealthStatus.Degraded, tags: new[] { &quot;example&quot; }, args: new object[] { 5, &quot;string&quot; }); HealthStatus Represents the reported status of a health check result. Status Description Degraded It could be used for checks that did succeed but are slow or unstable. For example, A simple database query did succeed but took more than a second. Moving traffic to another instance is probably a good idea until the problem has resolved. Healthy Indicates that the health check determined that the component was healthy. Unhealthy It means that the component does not work at all. For example, A connection to the Redis cache could no be established. Restarting the instance could solve this issue. Health Checks RoutingIn Startup.Configure, call MapHealthChecks on the endpoint builder with the endpoint URL or relative path: 1234app.UseEndpoints(endpoints =&gt;{ endpoints.MapHealthChecks(&quot;/health&quot;);}); Require host Call RequireHost to specify one or more permitted hosts for the health check endpoint. Hosts should be Unicode rather than punycode and may include a port. If a collection isn’t supplied, any host is accepted. 1234app.UseEndpoints(endpoints =&gt;{ endpoints.MapHealthChecks(&quot;/health&quot;).RequireHost(&quot;www.contoso.com:5001&quot;);}); Require authorization Call RequireAuthorization to run Authorization Middleware on the health check request endpoint. A RequireAuthorization overload accepts one or more authorization policies. If a policy isn’t provided, the default authorization policy is used. 1234app.UseEndpoints(endpoints =&gt;{ endpoints.MapHealthChecks(&quot;/health&quot;).RequireAuthorization();}); Filter health checksBy default, Health Checks Middleware runs all registered health checks. To run a subset of health checks, provide a function that returns a boolean to the Predicate option. In the following example, the Bar health check is filtered out by its tag (bar_tag) in the function’s conditional statement, where true is only returned if the health check’s Tags property matches foo_tag or baz_tag: 1234567services.AddHealthChecks() .AddCheck(&quot;Foo&quot;, () =&gt; HealthCheckResult.Healthy(&quot;Foo is OK!&quot;), tags: new[] { &quot;foo_tag&quot; }) .AddCheck(&quot;Bar&quot;, () =&gt; HealthCheckResult.Unhealthy(&quot;Bar is unhealthy!&quot;), tags: new[] { &quot;bar_tag&quot; }) .AddCheck(&quot;Baz&quot;, () =&gt; HealthCheckResult.Healthy(&quot;Baz is OK!&quot;), tags: new[] { &quot;baz_tag&quot; }); In Startup.Configure, the Predicate filters out the ‘Bar’ health check. Only Foo and Baz execute.: 123456789app.UseEndpoints(endpoints =&gt;{ endpoints.MapHealthChecks(&quot;/health&quot;, new HealthCheckOptions() { // HERE Predicate = (check) =&gt; check.Tags.Contains(&quot;foo_tag&quot;) || check.Tags.Contains(&quot;baz_tag&quot;) });}); Suppress cache headersAllowCachingResponses controls whether the Health Checks Middleware adds HTTP headers to a probe response to prevent response caching. If the value is false (default), the middleware sets or overrides the Cache-Control, Expires, and Pragma headers to prevent response caching. If the value is true, the middleware doesn’t modify the cache headers of the response. 1234567app.UseEndpoints(endpoints =&gt;{ endpoints.MapHealthChecks(&quot;/health&quot;, new HealthCheckOptions() { AllowCachingResponses = false });}); Customize outputIn order to generate a more readable response that makes sense, let’s add a bunch of reponse classes. Response Class for Overall Health Response Class for Component-wise Health 123456789101112131415161718// HealthCheckResponse.cspublic class HealthCheckResponse{ public string Status { get; set; } public string Component { get; set; } public string Description { get; set; } public IEnumerable&lt;string&gt; Tags { get; set; } public string Exception { get; set; }}// HealthCheckResult.cs// The aggregation of all health check responses, even if one is unhealthy, 'Status' will be unhealthy.public class HealthCheckResult{ public string Status { get; set; } public IEnumerable&lt;HealthCheckResponse&gt; HealthChecks { get; set; } public string HealthCheckDuration { get; set; }} ResponseWriter is responsible for how the response is displayed. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// Startup.Configureusing System.Text.Json;using Microsoft.AspNetCore.Diagnostics.HealthChecks;using Microsoft.Extensions.Diagnostics.HealthChecks;using Microsoft.AspNetCore.Http;using System.Linq;public class Startup{ public void Configure(IApplicationBuilder app, IWebHostEnvironment env) { if (env.IsDevelopment()) { app.UseDeveloperExceptionPage(); } app.UseRouting(); app.UseAuthorization(); app.UseEndpoints(endpoints =&gt; { endpoints.MapControllers(); // HERE endpoints.MapHealthChecks(&quot;/health&quot;, new HealthCheckOptions { ResponseWriter = async (context, report) =&gt; { context.Response.ContentType = &quot;application/json&quot;; var response = new HealthCheckResult { Status = report.Status.ToString(), HealthChecks = report.Entries.Select(x =&gt; new HealthCheckResponse { Component = x.Key, Status = x.Value.Status.ToString(), Description = x.Value.Description, Exception = x.Value.Exception?.Message, Tags = x.Value.Tags }), HealthCheckDuration = report.TotalDuration.ToString() }; await context.Response.WriteAsync(JsonSerializer.Serialize(response)); } }); }); }} Based on above sample the result will be: 123456789101112131415{ &quot;Status&quot;:&quot;Healthy&quot;, &quot;HealthChecks&quot;:[ { &quot;Status&quot;:&quot;Healthy&quot;, &quot;Component&quot;:&quot;example_health_check&quot;, &quot;Description&quot;:&quot;A healthy result.&quot;, &quot;Tags&quot;:[ &quot;example&quot; ], &quot;Exception&quot;:null } ], &quot;HealthCheckDuration&quot;:&quot;00:00:00.0010732&quot;} Enterprise solutionAspNetCore.Diagnostics.HealthChecks is an enterprise HealthChecks for ASP.NET Core Diagnostics Package. There are a lot of HealthChecks packages that you can find in above link. URIs Install the below package 123Install-Package AspNetCore.HealthChecks.Uris -Version 3.1.2dotnet add package AspNetCore.HealthChecks.Uris --version 3.1.2&lt;PackageReference Include=&quot;AspNetCore.HealthChecks.Uris&quot; Version=&quot;3.1.2&quot; /&gt; Register you site’s URL via AddUrlGroup 1234567891011121314// Startup.ConfigureServicesusing System;public void ConfigureServices(IServiceCollection services){ services.AddControllers(); services.AddHealthChecks() // HERE .AddUrlGroup(new Uri(&quot;https://hamedfathi.me&quot;), name: &quot;Hamed Fathi's Blog&quot;, tags: new[] { &quot;blog&quot;, &quot;tutorial&quot; } );} System Install the below package 123Install-Package AspNetCore.HealthChecks.System -Version 3.1.2dotnet add package AspNetCore.HealthChecks.System --version 3.1.2&lt;PackageReference Include=&quot;AspNetCore.HealthChecks.System&quot; Version=&quot;3.1.2&quot; /&gt; Register it inside ConfigureServices 12345678910111213// Startup.ConfigureServicesusing System;public void ConfigureServices(IServiceCollection services){ services.AddControllers(); services.AddHealthChecks() // HERE .AddDiskStorageHealthCheck(s =&gt; s.AddDrive(&quot;C:\\\\&quot;, 1024)) // 1024 MB (1 GB) free minimum .AddProcessAllocatedMemoryHealthCheck(512) // 512 MB max allocated memory .AddProcessHealthCheck(&quot;svchost&quot;, p =&gt; p.Length &gt; 0) // The process is available} HealthChecks UI The project HealthChecks.UI is a minimal UI interface that stores and shows the health checks results from the configured HealthChecks URIs, So: Install the below packages 1234567891011Install-Package AspNetCore.HealthChecks.UI -Version 3.1.3dotnet add package AspNetCore.HealthChecks.UI --version 3.1.3&lt;PackageReference Include=&quot;AspNetCore.HealthChecks.UI&quot; Version=&quot;3.1.3&quot; /&gt;Install-Package AspNetCore.HealthChecks.UI.Client -Version 3.1.2dotnet add package AspNetCore.HealthChecks.UI.Client --version 3.1.2&lt;PackageReference Include=&quot;AspNetCore.HealthChecks.UI.Client&quot; Version=&quot;3.1.2&quot; /&gt;Install-Package AspNetCore.HealthChecks.UI.InMemory.Storage -Version 3.1.2dotnet add package AspNetCore.HealthChecks.UI.InMemory.Storage --version 3.1.2&lt;PackageReference Include=&quot;AspNetCore.HealthChecks.UI.InMemory.Storage&quot; Version=&quot;3.1.2&quot; /&gt; To config the HealthChecks.UI you should do as following: 123456789101112131415161718192021222324252627282930313233343536373839404142public class Startup{ public void ConfigureServices(IServiceCollection services) { services.AddControllers(); // HERE services.AddHealthChecks(); services.AddHealthChecksUI(options =&gt; { options.AddHealthCheckEndpoint(&quot;endpoint1&quot;, &quot;http://localhost:5000/health&quot;); }) .AddInMemoryStorage(); } public void Configure(IApplicationBuilder app, IWebHostEnvironment env) { if (env.IsDevelopment()) { app.UseDeveloperExceptionPage(); } app.UseRouting(); app.UseAuthorization(); // HERE app.UseHealthChecksUI(); app.UseEndpoints(endpoints =&gt; { endpoints.MapControllers(); // HERE endpoints.MapHealthChecks(&quot;/health&quot;, new HealthCheckOptions() { Predicate = _ =&gt; true, ResponseWriter = UIResponseWriter.WriteHealthCheckUIResponse }); }); }} Now, Browse your UI via http://localhost:PORT/healthchecks-ui. The important part of configuration is AddHealthCheckEndpoint. HealthChecks UI SettingsHere are some important settings: UI Polling interval You can configure the polling interval in seconds for the UI inside the setup method. Default value is 10 seconds: 12345678910111213141516// Startup.ConfigureServicespublic void ConfigureServices(IServiceCollection services){ services.AddControllers(); services.AddHealthChecks(); services.AddHealthChecksUI(options =&gt; { options.AddHealthCheckEndpoint(&quot;endpoint1&quot;, &quot;http://localhost:5000/health&quot;); // Configures the UI to poll for healthchecks updates every 5 seconds options.SetEvaluationTimeInSeconds(5); }) .AddInMemoryStorage();} UI API max active requests You can configure max active requests to the HealthChecks UI backend api using the setup method. Default value is 3 active requests: 123456789101112131415161718// Startup.ConfigureServicespublic void ConfigureServices(IServiceCollection services){ services.AddControllers(); services.AddHealthChecks(); services.AddHealthChecksUI(options =&gt; { options.AddHealthCheckEndpoint(&quot;endpoint1&quot;, &quot;http://localhost:5000/health&quot;); options.SetEvaluationTimeInSeconds(5); // Only one active request will be executed at a time. // All the excedent requests will result in 429 (Too many requests) options.SetApiMaxActiveRequests(1); }) .AddInMemoryStorage();} HealthChecks UI JSON SettingsIt is possible for you to customize your settings in appsettings.json: 12345678910&quot;HealthChecksUI&quot;: { &quot;HealthChecks&quot;: [ { &quot;Name&quot;: &quot;endpoint1&quot;, &quot;Uri&quot;: &quot;http://localhost:5000/health&quot; } ], &quot;EvaluationTimeOnSeconds&quot;: 10, &quot;MinimumSecondsBetweenFailureNotifications&quot;: 60} Reference(s)Most of the information in this article has gathered from various references. https://docs.microsoft.com/en-us/aspnet/core/host-and-deploy/health-checks https://www.codewithmukesh.com/blog/healthchecks-in-aspnet-core-explained/ https://blog.zhaytam.com/2020/04/30/health-checks-aspnetcore/ https://volosoft.com/blog/Using-Health-Checks-in-ASP.NET-Boilerplate https://github.com/Xabaril/AspNetCore.Diagnostics.HealthChecks","link":"/a-professional-asp.net-core-api-health-check/"},{"title":"A Professional ASP.NET Core API - Localization","text":"Globalization and localization are two important concepts that you should be aware of to internationalize your applications. In essence, globalization and localization are concepts that help you reach a wider audience. The former relates to building applications that support various cultures and the latter relates to how you can build your application that can support a particular locale and culture. In other words, an application takes advantage of globalization to be able to cater to different languages based on user choice. Localization is adopted by the application to adapt the content of a website to various regions or cultures. IStringLocalizer and IStringLocalizer&lt;T&gt; were architected to improve productivity when developing localized apps. IStringLocalizer uses the ResourceManager and ResourceReader to provide culture-specific resources at run time. The interface has an indexer and an IEnumerable for returning localized strings. IStringLocalizer doesn’t require storing the default language strings in a resource file. You can develop an app targeted for localization and not need to create resource files early in development. The code below shows how to wrap the string “About Title” for localization. Register AddLocalization service. 12345678// Startup.ConfigureServicespublic void ConfigureServices(IServiceCollection services){ services.AddControllers(); // HERE services.AddLocalization();} And, Use it via IStringLocalizer 12345678910111213141516171819202122using Microsoft.AspNetCore.Mvc;using Microsoft.Extensions.Localization;namespace WebApplicationSample.Controllers{ [Route(&quot;api/[controller]&quot;)] public class AboutController : Controller { private readonly IStringLocalizer&lt;AboutController&gt; _localizer; public AboutController(IStringLocalizer&lt;AboutController&gt; localizer) { _localizer = localizer; } [HttpGet] public string Get() { return _localizer[&quot;About Title&quot;]; } }} There are three methods used to configure localization in ASP.NET Core. These include the following: AddDataAnnotationsLocalization: This method is used to provide support for DataAnnotations validation messages. AddLocalization: This method is used to add localization services to the services container. AddViewLocalization: This method is used to provide support for localized views. Define the Allowed Cultures12345678910111213141516171819// Startup.csprivate RequestLocalizationOptions GetLocalizationOptions(){ var supportedCultures = new List&lt;CultureInfo&gt; { new CultureInfo(&quot;en-US&quot;), new CultureInfo(&quot;de-DE&quot;), new CultureInfo(&quot;fr-FR&quot;), new CultureInfo(&quot;en-GB&quot;) }; var options = new RequestLocalizationOptions { DefaultRequestCulture = new RequestCulture(&quot;en-GB&quot;), SupportedCultures = supportedCultures, SupportedUICultures = supportedCultures }; return options;} Add above option to UseRequestLocalization middleware 123456789101112131415161718// Startup.Configurepublic void Configure(IApplicationBuilder app, IWebHostEnvironment env){ if (env.IsDevelopment()) { app.UseDeveloperExceptionPage(); } // HERE app.UseRequestLocalization(GetLocalizationOptions()); app.UseRouting(); app.UseAuthorization(); app.UseEndpoints(endpoints =&gt; { endpoints.MapControllers(); });} The middleware adds three providers for the request culture by default: QueryStringRequestCultureProvider: Gets the culture from query string values CookieRequestCultureProvider: Gets the culture from a cookie AcceptLanguageHeaderRequestCultureProvider: Gets the culture from the Accept-Language request header Create Resource Files for Each LocaleThere are various ways in which you can create resource files. In this example, you’ll take advantage of the Visual Studio Resource Designer to create an XML-based .resx file. To specify a specific rsource folder, we should change our service settings like below 12345678// Startup.ConfigureServicespublic void ConfigureServices(IServiceCollection services){ services.AddControllers(); // HERE services.AddLocalization(opt =&gt; opt.ResourcesPath = &quot;Resources&quot;);} ResourcesPath property has been used to set the path to the folder where resource files (for various locales) will reside. If you don’t specify any value for this property, the application will expect the resource files to be available in the application’s root directory. Select the project in the Solution Explorer Window and create a new folder named Resources in it. Resources in .NET are comprised of key/value pair of data that are compiled to a .resources file. A resource file is one where you can store strings, images, or object data - resources of the application. Next, add a resources file into the newly created folder. Name the resource files as Controllers.AboutController.en-GB.resx Controllers.AboutController.en-US.resx Controllers.AboutController.de-DE.resx Controllers.AboutController.fr-FR.resx Resource file namingResources are named for the full type name of their class minus the assembly name. For example, a French resource in a project whose main assembly is LocalizationWebsite.Web.dll for the class LocalizationWebsite.Web.Startup would be named Startup.fr.resx. A resource for the class LocalizationWebsite.Web.Controllers.HomeController would be named Controllers.HomeController.fr.resx. If your targeted class’s namespace isn’t the same as the assembly name you will need the full type name. For example, in the sample project a resource for the type ExtraNamespace.Tools would be named ExtraNamespace.Tools.fr.resx. In the sample project, the ConfigureServices method sets the ResourcesPath to “Resources”, so the project relative path for the home controller’s French resource file is Resources/Controllers.HomeController.fr.resx. Alternatively, you can use folders to organize resource files. For the about controller, the path would be Resources/Controllers/AboutController.fr.resx. If you don’t use the ResourcesPath option, the .resx file would go in the project base directory. The resource file for AboutController would be named Controllers.HomeController.fr.resx. The choice of using the dot or path naming convention depends on how you want to organize your resource files. In our sample, WebApplicationSample is the assembly name so we should create our resources inside Resources folder with this way. [NamespaceWithoutAssemblyName].[ControllerName].[Culture].resx Or [NamespaceWithoutAssemblyName]/[ControllerName].[Culture].resx How to use resource files?Write below key-values: Controllers.AboutController.en-GB.resx Key Value GreetingMessage Hello {0} SayHello Hello Controllers.AboutController.de-DE.resx Key Value GreetingMessage Hallo {0} SayHello Hallo Now, You can use them via controllers 1234567891011121314151617181920212223242526272829303132333435namespace WebApplicationSample.Controllers{ [ApiController] [Route(&quot;[controller]&quot;)] public class AboutController : ControllerBase { private readonly IStringLocalizer&lt;AboutController&gt; _localizer; public AboutController(IStringLocalizer&lt;AboutController&gt; localizer) { _localizer = localizer; } // http://localhost:PORT/weatherforecast // http://localhost:PORT/weatherforecast?culture=en-GB // http://localhost:PORT/weatherforecast?culture=de-DE [HttpGet] public string Get() { return _localizer[&quot;SayHello&quot;]; } // http://localhost:PORT/weatherforecast/hamed // http://localhost:PORT/weatherforecast/hamed?culture=en-GB // http://localhost:PORT/weatherforecast/hamed?culture=de-DE [HttpGet(&quot;{name}&quot;)] public string Get(string name) { return _localizer[string.Format(_localizer[&quot;GreetingMessage&quot;], name)]; } }} SayHello returns a simple text based on your culture.GreetingMessage returns a text but accept variable too. You can use unlimited place holders ({0} {1} {2} {3} , ...) and pass your variables via string.Format(). If IStringLocalizer does not find any value for the key, It will return the key itself as a result. JSON Localization ResourcesYou may want to use .json files as a resource instead of .resx files, so Install below package 123Install-Package My.Extensions.Localization.Json -Version 2.1.0dotnet add package My.Extensions.Localization.Json --version 2.1.0&lt;PackageReference Include=&quot;My.Extensions.Localization.Json&quot; Version=&quot;2.1.0&quot; /&gt; Remove services.AddLocalization(); and replace it with services.AddJsonLocalization(): 1234567891011121314// Startup.ConfigureServicesusing System.IO;public void ConfigureServices(IServiceCollection services){ services.AddControllers(); // REMOVE THIS // services.AddLocalization(opt =&gt; opt.ResourcesPath = &quot;Resources&quot;); // HERE services.AddJsonLocalization(opt =&gt; opt.ResourcesPath = &quot;Resources&quot;);} Write below JSON files: Controllers.AboutController.en-GB.json 1234{ &quot;GreetingMessage&quot;: &quot;Hello {0}&quot;, &quot;SayHello&quot;: &quot;Hello&quot;} Controllers.AboutController.de-DE.json 1234{ &quot;GreetingMessage&quot;: &quot;Hallo {0}&quot;, &quot;SayHello&quot;: &quot;Hallo&quot;} Now, You can use them via controllers 123456789101112131415161718192021222324252627282930313233343536namespace WebApplicationSample.Controllers{ [ApiController] [Route(&quot;[controller]&quot;)] public class AboutController : ControllerBase { private readonly IStringLocalizer&lt;AboutController&gt; _localizer; public AboutController(IStringLocalizer&lt;AboutController&gt; localizer) { _localizer = localizer; } // http://localhost:PORT/weatherforecast // http://localhost:PORT/weatherforecast?culture=en-GB // http://localhost:PORT/weatherforecast?culture=de-DE [HttpGet] public string Get() { return _localizer[&quot;SayHello&quot;]; } // http://localhost:PORT/weatherforecast/hamed // http://localhost:PORT/weatherforecast/hamed?culture=en-GB // http://localhost:PORT/weatherforecast/hamed?culture=de-DE [HttpGet(&quot;{name}&quot;)] public string Get(string name) { return _localizer[string.Format(_localizer[&quot;GreetingMessage&quot;], name)]; } }} DataAnnotation &amp; LocalizationInstall below package 123Install-Package Microsoft.AspNetCore.Mvc.DataAnnotations -Version 2.2.0dotnet add package Microsoft.AspNetCore.Mvc.DataAnnotations --version 2.2.0&lt;PackageReference Include=&quot;Microsoft.AspNetCore.Mvc.DataAnnotations&quot; Version=&quot;2.2.0&quot; /&gt; You can use DataAnnotation and Localization together. Update your ConfigureServices as following: 123456789101112131415161718// Startup.ConfigureServicespublic class Startup{ public void ConfigureServices(IServiceCollection services) { // Be Careful, You must register 'AddLocalization' before 'AddDataAnnotationsLocalization' like below. services.AddLocalization(opt =&gt; opt.ResourcesPath = &quot;Resources&quot;); services.AddControllers() // HERE .AddDataAnnotationsLocalization(options =&gt; { options.DataAnnotationLocalizerProvider = (type, factory) =&gt; factory.Create(typeof(DataAnnotationValidation)); }) ; }} Based on above configuration, you must add below files in Resources folder. DataAnnotationValidation.en-GB.resx Key Value Name ‘{0}’ is required DataAnnotationValidation.de-DE.resx Key Value Name ‘{0}’ ist erforderlich We want to validate Person class. 123456789101112// Person.cspublic class Person{ // The string of 'ErrorMessage' is the key. [Required(ErrorMessage = &quot;Name&quot;)] public string Name { get; set; } public string FamilyName { get; set; } public string Address { get; set; } public string EmailAddress { get; set; } public int Age { get; set; }} And you controller will be 1234567891011121314151617181920212223242526[ApiController][Route(&quot;[controller]&quot;)]public class WeatherForecastController : ControllerBase{ private readonly IStringLocalizer&lt;WeatherForecastController&gt; _localizer; public WeatherForecastController(IStringLocalizer&lt;WeatherForecastController&gt; localizer) { _localizer = localizer; } // http://localhost:PORT/weatherforecast // http://localhost:PORT/weatherforecast?culture=en-GB // http://localhost:PORT/weatherforecast?culture=de-DE [HttpPost] public IActionResult Post([FromBody] Person person) { if (!ModelState.IsValid) { return BadRequest(ModelState); } else { return Ok(); } }} And the result is 1234567891011121314151617181920212223{ &quot;type&quot;: &quot;https://tools.ietf.org/html/rfc7231#section-6.5.1&quot;, &quot;title&quot;: &quot;One or more validation errors occurred.&quot;, &quot;status&quot;: 400, &quot;traceId&quot;: &quot;|82e992e6-411f3f305ff4df95.&quot;, &quot;errors&quot;: { &quot;Name&quot;: [ &quot;'Name' is required&quot; ] }}{ &quot;type&quot;: &quot;https://tools.ietf.org/html/rfc7231#section-6.5.1&quot;, &quot;title&quot;: &quot;One or more validation errors occurred.&quot;, &quot;status&quot;: 400, &quot;traceId&quot;: &quot;|82e992e5-411f3f305ff4df95.&quot;, &quot;errors&quot;: { &quot;Name&quot;: [ &quot;'Name' ist erforderlich&quot; ] }} DataAnnotation &amp; JSON LocalizationYou can also use DataAnnotation and JSON Localization together. Make an emptyu class as following 123public class DataAnnotationValidation{} Update your ConfigureServices as following: 123456789101112131415161718// Startup.ConfigureServicespublic class Startup{ public void ConfigureServices(IServiceCollection services) { // Be Careful, You must register 'AddJsonLocalization' before 'AddDataAnnotationsLocalization' like below. services.AddJsonLocalization(opt =&gt; opt.ResourcesPath = &quot;Resources&quot;); services.AddControllers() // HERE .AddDataAnnotationsLocalization(options =&gt; { options.DataAnnotationLocalizerProvider = (type, factory) =&gt; factory.Create(typeof(DataAnnotationValidation)); }) ; }} Then write below JSON files in Resources folder. DataAnnotationValidation.en-GB.json 123{ &quot;Name&quot;: &quot;'{0}' is required&quot;} DataAnnotationValidation.de-DE.json 123{ &quot;Name&quot;: &quot;'{0}' ist erforderlich&quot;} We want to validate Person class. 123456789101112// Person.cspublic class Person{ // The string of 'ErrorMessage' is the key. [Required(ErrorMessage = &quot;Name&quot;)] public string Name { get; set; } public string FamilyName { get; set; } public string Address { get; set; } public string EmailAddress { get; set; } public int Age { get; set; }} And you controller will be 1234567891011121314151617181920212223242526[ApiController][Route(&quot;[controller]&quot;)]public class WeatherForecastController : ControllerBase{ private readonly IStringLocalizer&lt;WeatherForecastController&gt; _localizer; public WeatherForecastController(IStringLocalizer&lt;WeatherForecastController&gt; localizer) { _localizer = localizer; } // http://localhost:PORT/weatherforecast // http://localhost:PORT/weatherforecast?culture=en-GB // http://localhost:PORT/weatherforecast?culture=de-DE [HttpPost] public IActionResult Post([FromBody] Person person) { if (!ModelState.IsValid) { return BadRequest(ModelState); } else { return Ok(); } }} And the result is 1234567891011121314151617181920212223{ &quot;type&quot;: &quot;https://tools.ietf.org/html/rfc7231#section-6.5.1&quot;, &quot;title&quot;: &quot;One or more validation errors occurred.&quot;, &quot;status&quot;: 400, &quot;traceId&quot;: &quot;|82e992e6-411f3f305ff4df95.&quot;, &quot;errors&quot;: { &quot;Name&quot;: [ &quot;'Name' is required&quot; ] }}{ &quot;type&quot;: &quot;https://tools.ietf.org/html/rfc7231#section-6.5.1&quot;, &quot;title&quot;: &quot;One or more validation errors occurred.&quot;, &quot;status&quot;: 400, &quot;traceId&quot;: &quot;|82e992e5-411f3f305ff4df95.&quot;, &quot;errors&quot;: { &quot;Name&quot;: [ &quot;'Name' ist erforderlich&quot; ] }} FluentValidation &amp; LocalizationInstall below packages 1234567Install-Package FluentValidation -Version 9.2.2dotnet add package FluentValidation --version 9.2.2&lt;PackageReference Include=&quot;FluentValidation&quot; Version=&quot;9.2.2&quot; /&gt;Install-Package FluentValidation.AspNetCore -Version 9.2.0dotnet add package FluentValidation.AspNetCore --version 9.2.0&lt;PackageReference Include=&quot;FluentValidation.AspNetCore&quot; Version=&quot;9.2.0&quot; /&gt; Register FluentValidation as following 123456789101112public void ConfigureServices(IServiceCollection services){ services .AddControllers() .AddFluentValidation() // HERE ; // HERE services.AddTransient&lt;IValidator&lt;Person&gt;, PersonValidator&gt;(); } To use localization, pass IStringLocalizer&lt;T&gt; to the constructor and do the same as we explained before. 123456789101112131415161718192021222324252627// Person.cspublic class Person { public string Name { get; set; } public string FamilyName { get; set; } public string Address { get; set; } public string EmailAddress { get; set; } public int Age { get; set; }}// PersonValidator.cspublic class PersonValidator : AbstractValidator&lt;Person&gt;{ public PersonValidator(IStringLocalizer&lt;Person&gt; localizer) { RuleFor(e =&gt; e.Name).MinimumLength(5) .WithMessage(e =&gt; string.Format(localizer[Name], nameof(e.Name))); RuleFor(e =&gt; e.FamilyName).MinimumLength(5) .WithMessage(e =&gt; string.Format(localizer[Name], nameof(e.FamilyName))); RuleFor(e =&gt; e.Address).MinimumLength(10).WithMessage(e =&gt; localizer[Address]); RuleFor(e =&gt; e.EmailAddress).EmailAddress().WithMessage(e =&gt; localizer[EmailAddress]); RuleFor(e =&gt; e.Age).InclusiveBetween(20, 60).WithMessage(e =&gt; localizer[Age]); }} Reference(s)Most of the information in this article has gathered from various references. https://docs.microsoft.com/en-us/aspnet/core/fundamentals/localization https://www.codemag.com/Article/2009081/A-Deep-Dive-into-ASP.NET-Core-Localization https://github.com/hishamco/My.Extensions.Localization.Json https://joonasw.net/view/aspnet-core-localization-deep-dive","link":"/a-professional-asp.net-core-api-localization/"},{"title":"A Professional ASP.NET Core API - MiniProfiler","text":"MiniProfiler is a library and UI for profiling your application. By letting you see where your time is spent, which queries are run, and any other custom timings you want to add, MiniProfiler helps you debug issues and optimize performance. Install the below package 123Install-Package MiniProfiler.AspNetCore.Mvc -Version 4.2.1dotnet add package MiniProfiler.AspNetCore.Mvc --version 4.2.1&lt;PackageReference Include=&quot;MiniProfiler.AspNetCore.Mvc&quot; Version=&quot;4.2.1&quot; /&gt; ASP.NET CoreEdit your Startup.cs to add the middleware and configure options: 123456789101112// Startup.ConfigureServicespublic void ConfigureServices(IServiceCollection services){ // The services.AddMemoryCache(); code is required // There is a bug in MiniProfiler, if we have not configured MemoryCache, it will fail. services.AddMemoryCache(); // HERE services.AddMiniProfiler(options =&gt; options.RouteBasePath = &quot;/profiler&quot;); services.AddControllers();} Once, you configure the RouteBasePath property, We are able access to /profiler/results-index: Get list of all requests. /profiler/results: Get the current request. /profiler/results-list: Get list of all requests as JSON. Next we need add the MiniProfiler middleware, You can do like this. 12345678910111213141516171819// Startup.Configurepublic void Configure(IApplicationBuilder app, IWebHostEnvironment env){ if (env.IsDevelopment()) { app.UseDeveloperExceptionPage(); } app.UseRouting(); app.UseAuthorization(); // HERE app.UseMiniProfiler(); app.UseEndpoints(endpoints =&gt; { endpoints.MapControllers(); });} Custom profilingIf you want to your own code profiling you can use the MiniProfiler.Current object, like this. 12345678910111213141516171819202122232425262728public IActionResult Put([FromRoute]int id, [FromBody]WeatherForecast weatherForecast){ // HERE using (MiniProfiler.Current.Step(&quot;PUT method for WeatherForecast controller&quot;)) { WeatherForecast weatherForecastById = null; using (MiniProfiler.Current.Step(&quot;Getting Weather Forecase for the Id&quot;)) { weatherForecastById = GetWeatherForecast(id); } if (weatherForecastById == null) { return NotFound(); } if (weatherForecastById.Id != id) { return BadRequest(); } using (MiniProfiler.Current.Step(&quot;Updating the Data&quot;)) { _databaseContext.Entry(weatherForecast).State = EntityState.Modified; _databaseContext.SaveChanges(); } return NoContent(); }} Entity Framework CoreHooking up profiling to Entity Framework Core is easy to do: Install the below package 123Install-Package MiniProfiler.EntityFrameworkCore -Version 4.2.1dotnet add package MiniProfiler.EntityFrameworkCore --version 4.2.1&lt;PackageReference Include=&quot;MiniProfiler.EntityFrameworkCore&quot; Version=&quot;4.2.1&quot; /&gt; And, In your Startup.cs, call AddEntityFramework(): 123456789101112// Startup.ConfigureServicespublic void ConfigureServices(IServiceCollection services){ services.AddMemoryCache(); services.AddMiniProfiler(options =&gt; options.RouteBasePath = &quot;/profiler&quot;) .AddEntityFramework(); // HERE services.AddEntityFrameworkSqlite().AddDbContext&lt;DatabaseContext&gt;(); services.AddControllers();} Reference(s)Most of the information in this article has gathered from various references. https://dotnetthoughts.net/using-miniprofiler-in-aspnetcore-webapi/ https://miniprofiler.com/dotnet/AspDotNetCore","link":"/a-professional-asp.net-core-api-mini-profiler/"},{"title":"A Professional ASP.NET Core API - Paging","text":"Paging refers to getting partial results from an API. Imagine having millions of results in the database and having your application try to return all of them at once. Not only that would be an extremely ineffective way of returning the results, but it could also possibly have devastating effects on the application itself or the hardware it runs on. Moreover, every client has limited memory resources and it needs to restrict the number of shown results. Thus, we need a way to return a set number of results to the client in order to avoid these consequences. Fake data generatorTo work with a big list for paging we need a library to generate fake data. We use Bogus for this goal. Install below package 123Install-Package Bogus -Version 31.0.2dotnet add package Bogus --version 31.0.2&lt;PackageReference Include=&quot;Bogus&quot; Version=&quot;31.0.2&quot; /&gt; Our Models We want to return list of people so I should write the following classes 123456789101112131415161718192021222324252627282930313233// Person.cspublic class Person{ public Guid Id { get; set; } public string Name { get; set; } public string FamilyName { get; set; } public float Age { get; set; } public DateTimeOffset BithDate { get; set; } public IEnumerable&lt;Phone&gt; Phones { get; set; } public IEnumerable&lt;Address&gt; Addresses { get; set; } public Person() { Phones = new List&lt;Phone&gt;(); Addresses = new List&lt;Address&gt;(); }}// Address.cspublic class Address{ public string Country { get; set; } public string City { get; set; } public string MainStreet { get; set; } public string Info { get; set; } public string No { get; set; }}// Phone.cspublic class Phone{ public string Code { get; set; } public string Number { get; set; }} Generator To generate fake data we should do like below 123456789101112131415161718192021222324252627282930313233// PeopleDataGenerator.csusing Bogus;public static class PeopleDataGenerator{ public static IEnumerable&lt;Person&gt; GetPeople(int count = 200) { var testPhone = new Faker&lt;Phone&gt;() .StrictMode(true) .RuleFor(p =&gt; p.Code, f =&gt; f.Address.CountryCode()) .RuleFor(p =&gt; p.Number, f =&gt; f.Phone.PhoneNumber()) ; var testAddress = new Faker&lt;Address&gt;() .StrictMode(true) .RuleFor(a =&gt; a.Country, f =&gt; f.Address.Country()) .RuleFor(a =&gt; a.City, f =&gt; f.Address.City()) .RuleFor(a =&gt; a.No, f =&gt; f.Address.BuildingNumber()) .RuleFor(a =&gt; a.Info, f =&gt; f.Address.FullAddress()) .RuleFor(a =&gt; a.MainStreet, f =&gt; f.Address.StreetAddress()) ; var testPerson = new Faker&lt;Person&gt;() .StrictMode(true) .RuleFor(p =&gt; p.Id, f =&gt; Guid.NewGuid()) .RuleFor(p =&gt; p.Name, f =&gt; f.Name.FirstName()) .RuleFor(p =&gt; p.FamilyName, f =&gt; f.Name.LastName()) .RuleFor(p =&gt; p.Age, f =&gt; f.Random.Float(1, 120)) .RuleFor(p =&gt; p.BithDate, f =&gt; f.Person.DateOfBirth) .RuleFor(p =&gt; p.Phones, f =&gt; testPhone.Generate(15)) .RuleFor(p =&gt; p.Addresses, f =&gt; testAddress.Generate(10)) ; return testPerson.Generate(count); }} GetPeople() will generate 200 people in default mode. Goal Our goal is make pagination for Get() action method: 123456789101112[ApiController][Route(&quot;[controller]&quot;)]public class WeatherForecastController : ControllerBase{ [HttpGet] public IEnumerable&lt;Person&gt; Get() { // OUR GOAL var data = PeopleDataGenerator.GetPeople(); return data; }} New paging resultIt’s always a good practice to add wrappers to your API response. What is a wrapper? Instead of just returning the data in the response, you have a possibility to return other parameters like error messages, response status, page number, data, page size, and so on. So, write the following classes 123456789101112131415161718192021222324252627282930313233343536373839404142// Response.cspublic class Response&lt;T&gt;{ public Response(T data) { Succeeded = true; Message = string.Empty; Errors = null; Data = data; } public T Data { get; set; } public bool Succeeded { get; set; } public string[] Errors { get; set; } public string Message { get; set; }}// PagedResponse.csusing System;public class PagedResponse&lt;T&gt; : Response&lt;T&gt;{ public int PageNumber { get; set; } public int PageSize { get; set; } public Uri FirstPage { get; set; } public Uri LastPage { get; set; } public int TotalPages { get; set; } public int TotalRecords { get; set; } public Uri NextPage { get; set; } public Uri PreviousPage { get; set; } public PagedResponse(T data, int pageNumber, int pageSize) : base(data) { PageNumber = pageNumber; PageSize = pageSize; Data = data; Message = null; Succeeded = true; Errors = null; } public PagedResponse(T data, PaginationFilter paginationFilter) : this(data, paginationFilter.PageNumber, paginationFilter.PageSize) { }} To send our filtering config we need another class 123456789101112131415public class PaginationFilter{ public int PageNumber { get; set; } public int PageSize { get; set; } public PaginationFilter() { PageNumber = 1; PageSize = 10; } public PaginationFilter(int pageNumber, int pageSize) { PageNumber = pageNumber &lt; 1 ? 1 : pageNumber; PageSize = pageSize &lt; 1 ? 1 : pageSize; }} Now, we are able to do something like this: 123456789101112131415// http://localhost:PORT/weatherforecast?pageNumber=2&amp;pageSize=10[ApiController][Route(&quot;[controller]&quot;)]public class WeatherForecastController : ControllerBase{ [HttpGet] public IEnumerable&lt;Person&gt; Get([FromQuery] PaginationFilter filter) { var data = PeopleDataGenerator.GetPeople() .Skip((filter.PageNumber - 1) * filter.PageSize) .Take(filter.PageSize); return data; }} [FromQuery] is necessary because we will send our parameters via query strings. Generating Pagination URLsOne of the most challenging sections is building URIs. For this purpose we need to define a PagedUriService to generate the URI: 12345678910111213141516171819202122// IPagedUriService.cspublic interface IPagedUriService{ public Uri GetPageUri(PaginationFilter filter, string route);}// PagedUriService.cspublic class PagedUriService : IPagedUriService{ private readonly string _baseUri; public PagedUriService(string baseUri) { _baseUri = baseUri; } public Uri GetPageUri(PaginationFilter filter, string route) { var _enpointUri = new Uri(string.Concat(_baseUri, route)); var modifiedUri = QueryHelpers.AddQueryString(_enpointUri.ToString(), &quot;pageNumber&quot;, filter.PageNumber.ToString()); modifiedUri = QueryHelpers.AddQueryString(modifiedUri, &quot;pageSize&quot;, filter.PageSize.ToString()); return new Uri(modifiedUri); }} We should register PagedUriService into the DI. 12345678910111213141516171819// PagingServiceExtension.csusing Microsoft.AspNetCore.Http;using Microsoft.Extensions.DependencyInjection;public static class PagingServiceExtension{ public static IServiceCollection AddPaging(this IServiceCollection services) { services.AddHttpContextAccessor(); services.AddSingleton&lt;IPagedUriService&gt;(o =&gt; { var accessor = o.GetRequiredService&lt;IHttpContextAccessor&gt;(); var request = accessor.HttpContext.Request; var uri = string.Concat(request.Scheme, &quot;://&quot;, request.Host.ToUriComponent()); return new PagedUriService(uri); }); return services; }} Finally, we need some functionalities to convert our raw list to paged result: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677// PagingExtensions.cspublic static class PagingExtensions{ public static PagedResponse&lt;IEnumerable&lt;T&gt;&gt; ToPagedReponse&lt;T&gt;(this IEnumerable&lt;T&gt; pagedData, PaginationFilter validFilter, int totalRecords, IPagedUriService uriService, string route) { var respose = new PagedResponse&lt;IEnumerable&lt;T&gt;&gt;(pagedData, validFilter.PageNumber, validFilter.PageSize); var totalPages = totalRecords / (double)validFilter.PageSize; int roundedTotalPages = Convert.ToInt32(Math.Ceiling(totalPages)); if (string.IsNullOrEmpty(route) || uriService == null) { respose.FirstPage = null; respose.PreviousPage = null; respose.NextPage = null; respose.LastPage = null; } else { respose.NextPage = validFilter.PageNumber &gt;= 1 &amp;&amp; validFilter.PageNumber &lt; roundedTotalPages ? uriService.GetPageUri(new PaginationFilter(validFilter.PageNumber + 1, validFilter.PageSize), route) : null; respose.PreviousPage = validFilter.PageNumber - 1 &gt;= 1 &amp;&amp; validFilter.PageNumber &lt;= roundedTotalPages ? uriService.GetPageUri(new PaginationFilter(validFilter.PageNumber - 1, validFilter.PageSize), route) : null; respose.FirstPage = uriService.GetPageUri(new PaginationFilter(1, validFilter.PageSize), route); respose.LastPage = uriService.GetPageUri(new PaginationFilter(roundedTotalPages, validFilter.PageSize), route); } respose.TotalPages = roundedTotalPages; respose.TotalRecords = totalRecords; return respose; } public static PagedResponse&lt;IEnumerable&lt;T&gt;&gt; ToPagedReponse&lt;T&gt;(this IEnumerable&lt;T&gt; pagedData, int pageNumber, int pageSize, int totalRecords, IPagedUriService uriService, string route) { return pagedData.ToPagedReponse(new PaginationFilter(pageNumber, pageSize), totalRecords, uriService, route); } public static IActionResult ToPagedResult&lt;T&gt;(this IEnumerable&lt;T&gt; pagedData, int pageNumber, int pageSize, int totalRecords, IPagedUriService uriService, string route) { return new OkObjectResult(pagedData.ToPagedReponse(new PaginationFilter(pageNumber, pageSize), totalRecords, uriService, route)); } public static IActionResult ToPagedResult&lt;T&gt;(this IEnumerable&lt;T&gt; pagedData, PaginationFilter validFilter, int totalRecords, IPagedUriService uriService, string route) { return new OkObjectResult(pagedData.ToPagedReponse(validFilter, totalRecords, uriService, route)); } public static PagedResponse&lt;IQueryable&lt;T&gt;&gt; ToPagedReponse&lt;T&gt;(this IQueryable&lt;T&gt; pagedData, PaginationFilter validFilter, int totalRecords, IPagedUriService uriService, string route) { return pagedData.ToPagedReponse(validFilter, totalRecords, uriService, route); } public static PagedResponse&lt;IQueryable&lt;T&gt;&gt; ToPagedReponse&lt;T&gt;(this IQueryable&lt;T&gt; pagedData, int pageNumber, int pageSize, int totalRecords, IPagedUriService uriService, string route) { return pagedData.ToPagedReponse(new PaginationFilter(pageNumber, pageSize), totalRecords, uriService, route); } public static IActionResult ToPagedResult&lt;T&gt;(this IQueryable&lt;T&gt; pagedData, int pageNumber, int pageSize, int totalRecords, IPagedUriService uriService, string route) { return new OkObjectResult(pagedData.ToPagedReponse(new PaginationFilter(pageNumber, pageSize), totalRecords, uriService, route)); } public static IActionResult ToPagedResult&lt;T&gt;(this IQueryable&lt;T&gt; pagedData, PaginationFilter validFilter, int totalRecords, IPagedUriService uriService, string route) { return new OkObjectResult(pagedData.ToPagedReponse(validFilter, totalRecords, uriService, route)); } public static IActionResult ToOnePagedResult&lt;T&gt;(this IQueryable&lt;T&gt; pagedData, int totalRecords, IPagedUriService uriService, string route) { return pagedData.ToPagedResult(1, totalRecords, totalRecords, uriService, route); } public static IActionResult ToOnePagedResult&lt;T&gt;(this IEnumerable&lt;T&gt; pagedData, int totalRecords, IPagedUriService uriService, string route) { return pagedData.ToPagedResult(1, totalRecords, totalRecords, uriService, route); } public static PagedResponse&lt;IEnumerable&lt;T&gt;&gt; ToOnePagedReponse&lt;T&gt;(this IEnumerable&lt;T&gt; pagedData, int totalRecords, IPagedUriService uriService, string route) { return pagedData.ToPagedReponse(1, totalRecords, totalRecords, uriService, route); } public static PagedResponse&lt;IQueryable&lt;T&gt;&gt; ToOnePagedReponse&lt;T&gt;(this IQueryable&lt;T&gt; pagedData, int totalRecords, IPagedUriService uriService, string route) { return pagedData.ToPagedReponse(1, totalRecords, totalRecords, uriService, route); }} How to use?Using a new paging functionality is so easy, Just follow bellow steps: First, Register AddPaging service. 123456public void ConfigureServices(IServiceCollection services){ services.AddControllers(); // HERE services.AddPaging();} Second, Pass IPagedUriService to the constructor of controller.Third, Use Request.Path.Value to get the route data.Fourth, Use ToPagedResult to convert the list to a paged result as an IActionResult. 12345678910111213141516171819[ApiController][Route(&quot;[controller]&quot;)]public class WeatherForecastController : ControllerBase{ private readonly IPagedUriService _uriService; public WeatherForecastController(IPagedUriService uriService /* HERE */) { _uriService = uriService; } [HttpGet] public IActionResult Get([FromQuery] PaginationFilter filter) { var route = Request.Path.Value; var data = PeopleDataGenerator.GetPeople(); var count = data.Count(); var pagedData = data.ToPagedResult(filter, count, _uriService, route); return pagedData; }} You result will be like below 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299// https://localhost:5001/weatherforecast?pageNumber=2&amp;pageSize=10{ &quot;pageNumber&quot;: 2, &quot;pageSize&quot;: 10, &quot;firstPage&quot;: &quot;https://localhost:5001/weatherforecast?pageNumber=1&amp;pageSize=10&quot;, &quot;lastPage&quot;: &quot;https://localhost:5001/weatherforecast?pageNumber=20&amp;pageSize=10&quot;, &quot;totalPages&quot;: 20, &quot;totalRecords&quot;: 200, &quot;nextPage&quot;: &quot;https://localhost:5001/weatherforecast?pageNumber=3&amp;pageSize=10&quot;, &quot;previousPage&quot;: &quot;https://localhost:5001/weatherforecast?pageNumber=1&amp;pageSize=10&quot;, &quot;data&quot;: [ { &quot;id&quot;: &quot;20f216f8-1c28-40e3-8687-30414e0b1e43&quot;, &quot;name&quot;: &quot;Norris&quot;, &quot;familyName&quot;: &quot;Gaylord&quot;, &quot;age&quot;: 93.91649, &quot;bithDate&quot;: &quot;1983-08-19T20:29:12.2566788+04:30&quot;, &quot;phones&quot;: [ { &quot;code&quot;: &quot;CG&quot;, &quot;number&quot;: &quot;1-990-301-7170&quot; }, { &quot;code&quot;: &quot;GF&quot;, &quot;number&quot;: &quot;435-648-1211 x2527&quot; }, { &quot;code&quot;: &quot;EE&quot;, &quot;number&quot;: &quot;452-350-1534 x565&quot; }, { &quot;code&quot;: &quot;HU&quot;, &quot;number&quot;: &quot;454-359-3006&quot; }, { &quot;code&quot;: &quot;UG&quot;, &quot;number&quot;: &quot;848.828.2965&quot; }, { &quot;code&quot;: &quot;AR&quot;, &quot;number&quot;: &quot;(481) 493-4770&quot; }, { &quot;code&quot;: &quot;WS&quot;, &quot;number&quot;: &quot;764.491.4668&quot; }, { &quot;code&quot;: &quot;FK&quot;, &quot;number&quot;: &quot;(927) 724-4714 x1111&quot; }, { &quot;code&quot;: &quot;AW&quot;, &quot;number&quot;: &quot;348.380.0028 x0504&quot; }, { &quot;code&quot;: &quot;KE&quot;, &quot;number&quot;: &quot;(222) 317-4262 x221&quot; }, { &quot;code&quot;: &quot;LA&quot;, &quot;number&quot;: &quot;(864) 234-4896&quot; }, { &quot;code&quot;: &quot;CY&quot;, &quot;number&quot;: &quot;1-596-579-7108 x764&quot; }, { &quot;code&quot;: &quot;RU&quot;, &quot;number&quot;: &quot;378.786.5243&quot; }, { &quot;code&quot;: &quot;ZM&quot;, &quot;number&quot;: &quot;(233) 668-1087&quot; }, { &quot;code&quot;: &quot;LK&quot;, &quot;number&quot;: &quot;442.582.0962 x311&quot; } ], &quot;addresses&quot;: [ { &quot;country&quot;: &quot;San Marino&quot;, &quot;city&quot;: &quot;Lake Shaniya&quot;, &quot;mainStreet&quot;: &quot;4821 Federico Burg&quot;, &quot;info&quot;: &quot;2724 Brakus Spurs, East Kenyattaport, French Guiana&quot;, &quot;no&quot;: &quot;43796&quot; }, { &quot;country&quot;: &quot;Cuba&quot;, &quot;city&quot;: &quot;Lubowitzborough&quot;, &quot;mainStreet&quot;: &quot;396 Murazik Roads&quot;, &quot;info&quot;: &quot;268 Heathcote Extension, Toytown, Uruguay&quot;, &quot;no&quot;: &quot;72283&quot; }, { &quot;country&quot;: &quot;Lao People's Democratic Republic&quot;, &quot;city&quot;: &quot;Dickinsonview&quot;, &quot;mainStreet&quot;: &quot;7750 Dimitri Rapids&quot;, &quot;info&quot;: &quot;360 David Run, Boyleborough, Marshall Islands&quot;, &quot;no&quot;: &quot;22955&quot; }, { &quot;country&quot;: &quot;Vietnam&quot;, &quot;city&quot;: &quot;East Rosemary&quot;, &quot;mainStreet&quot;: &quot;055 Paolo Glen&quot;, &quot;info&quot;: &quot;71691 Hammes Locks, Port Mackenzieborough, Swaziland&quot;, &quot;no&quot;: &quot;710&quot; }, { &quot;country&quot;: &quot;China&quot;, &quot;city&quot;: &quot;South Casandrafurt&quot;, &quot;mainStreet&quot;: &quot;894 Stiedemann Via&quot;, &quot;info&quot;: &quot;60676 Fay Isle, Juvenalbury, Namibia&quot;, &quot;no&quot;: &quot;38640&quot; }, { &quot;country&quot;: &quot;Lebanon&quot;, &quot;city&quot;: &quot;Dorcasshire&quot;, &quot;mainStreet&quot;: &quot;49750 Flatley Groves&quot;, &quot;info&quot;: &quot;7761 Howell Springs, West Quintonside, Mexico&quot;, &quot;no&quot;: &quot;4452&quot; }, { &quot;country&quot;: &quot;Libyan Arab Jamahiriya&quot;, &quot;city&quot;: &quot;Amiyashire&quot;, &quot;mainStreet&quot;: &quot;112 Baumbach Field&quot;, &quot;info&quot;: &quot;61227 Nils Flat, Lafayettefurt, Mexico&quot;, &quot;no&quot;: &quot;0611&quot; }, { &quot;country&quot;: &quot;Rwanda&quot;, &quot;city&quot;: &quot;McCulloughhaven&quot;, &quot;mainStreet&quot;: &quot;503 Anthony Extensions&quot;, &quot;info&quot;: &quot;336 Kling Mission, East Parisshire, Uganda&quot;, &quot;no&quot;: &quot;67206&quot; }, { &quot;country&quot;: &quot;Zimbabwe&quot;, &quot;city&quot;: &quot;North Garrisonton&quot;, &quot;mainStreet&quot;: &quot;56022 Cecile Place&quot;, &quot;info&quot;: &quot;52476 Wyman Branch, Sporerview, Sao Tome and Principe&quot;, &quot;no&quot;: &quot;34449&quot; }, { &quot;country&quot;: &quot;Nigeria&quot;, &quot;city&quot;: &quot;North Isadore&quot;, &quot;mainStreet&quot;: &quot;2893 Alvera Greens&quot;, &quot;info&quot;: &quot;590 Rupert Avenue, Lake Alexys, China&quot;, &quot;no&quot;: &quot;91788&quot; } ] }, { &quot;id&quot;: &quot;da39bc7a-cdfa-49a6-8eda-2d8578a10a95&quot;, &quot;name&quot;: &quot;Loyal&quot;, &quot;familyName&quot;: &quot;Simonis&quot;, &quot;age&quot;: 13.926475, &quot;bithDate&quot;: &quot;1999-04-08T18:35:10.3663495+04:30&quot;, &quot;phones&quot;: [ { &quot;code&quot;: &quot;CL&quot;, &quot;number&quot;: &quot;611-390-0679&quot; }, { &quot;code&quot;: &quot;JM&quot;, &quot;number&quot;: &quot;333-284-4157 x15776&quot; }, { &quot;code&quot;: &quot;BH&quot;, &quot;number&quot;: &quot;(775) 257-6981 x8944&quot; }, { &quot;code&quot;: &quot;SA&quot;, &quot;number&quot;: &quot;(925) 759-5904 x70541&quot; }, { &quot;code&quot;: &quot;IN&quot;, &quot;number&quot;: &quot;1-287-226-3739 x26113&quot; }, { &quot;code&quot;: &quot;IN&quot;, &quot;number&quot;: &quot;1-835-217-5850 x0543&quot; }, { &quot;code&quot;: &quot;ZM&quot;, &quot;number&quot;: &quot;239-517-9971 x933&quot; }, { &quot;code&quot;: &quot;UG&quot;, &quot;number&quot;: &quot;587.700.3823&quot; }, { &quot;code&quot;: &quot;TM&quot;, &quot;number&quot;: &quot;1-729-462-2169 x5501&quot; }, { &quot;code&quot;: &quot;HN&quot;, &quot;number&quot;: &quot;925.856.6956 x9365&quot; }, { &quot;code&quot;: &quot;BO&quot;, &quot;number&quot;: &quot;436.252.3008 x641&quot; }, { &quot;code&quot;: &quot;GB&quot;, &quot;number&quot;: &quot;(969) 740-3197 x2393&quot; }, { &quot;code&quot;: &quot;SV&quot;, &quot;number&quot;: &quot;(392) 998-7274 x247&quot; }, { &quot;code&quot;: &quot;AI&quot;, &quot;number&quot;: &quot;899.370.6658&quot; }, { &quot;code&quot;: &quot;UM&quot;, &quot;number&quot;: &quot;1-983-472-3551&quot; } ], &quot;addresses&quot;: [ { &quot;country&quot;: &quot;Anguilla&quot;, &quot;city&quot;: &quot;Bradleyside&quot;, &quot;mainStreet&quot;: &quot;81514 Nicklaus View&quot;, &quot;info&quot;: &quot;031 Kohler Dam, South Dave, Heard Island and McDonald Islands&quot;, &quot;no&quot;: &quot;2989&quot; }, { &quot;country&quot;: &quot;Lesotho&quot;, &quot;city&quot;: &quot;Lindaberg&quot;, &quot;mainStreet&quot;: &quot;143 O'Connell Points&quot;, &quot;info&quot;: &quot;862 Hoeger Lodge, North Sid, Algeria&quot;, &quot;no&quot;: &quot;87646&quot; }, { &quot;country&quot;: &quot;Singapore&quot;, &quot;city&quot;: &quot;Lake Stephon&quot;, &quot;mainStreet&quot;: &quot;85625 Kub Isle&quot;, &quot;info&quot;: &quot;6441 Bruen Parkways, North Crystal, Togo&quot;, &quot;no&quot;: &quot;8897&quot; }, { &quot;country&quot;: &quot;Cayman Islands&quot;, &quot;city&quot;: &quot;Lake Ethelland&quot;, &quot;mainStreet&quot;: &quot;40312 Herzog Walks&quot;, &quot;info&quot;: &quot;8711 Roberts Center, South Sophiaborough, Bosnia and Herzegovina&quot;, &quot;no&quot;: &quot;969&quot; }, { &quot;country&quot;: &quot;Singapore&quot;, &quot;city&quot;: &quot;Alfordchester&quot;, &quot;mainStreet&quot;: &quot;391 Corkery Junction&quot;, &quot;info&quot;: &quot;4566 Erwin Greens, West Marshall, Pakistan&quot;, &quot;no&quot;: &quot;3716&quot; }, { &quot;country&quot;: &quot;United States of America&quot;, &quot;city&quot;: &quot;West Kadin&quot;, &quot;mainStreet&quot;: &quot;1807 Reinger Place&quot;, &quot;info&quot;: &quot;265 Evalyn Flats, Klinghaven, Honduras&quot;, &quot;no&quot;: &quot;389&quot; }, { &quot;country&quot;: &quot;Cote d'Ivoire&quot;, &quot;city&quot;: &quot;Kesslerberg&quot;, &quot;mainStreet&quot;: &quot;6985 Lenore Isle&quot;, &quot;info&quot;: &quot;50346 Parisian Viaduct, West Efrain, Ukraine&quot;, &quot;no&quot;: &quot;1107&quot; }, { &quot;country&quot;: &quot;Serbia&quot;, &quot;city&quot;: &quot;South Velvashire&quot;, &quot;mainStreet&quot;: &quot;573 Pfeffer Courts&quot;, &quot;info&quot;: &quot;472 Brekke Knolls, Darronchester, Hong Kong&quot;, &quot;no&quot;: &quot;70450&quot; }, { &quot;country&quot;: &quot;Taiwan&quot;, &quot;city&quot;: &quot;Kaleside&quot;, &quot;mainStreet&quot;: &quot;94647 Murphy Vista&quot;, &quot;info&quot;: &quot;8682 Stoltenberg Flats, Port Tianafurt, Bouvet Island (Bouvetoya)&quot;, &quot;no&quot;: &quot;3502&quot; }, { &quot;country&quot;: &quot;Cayman Islands&quot;, &quot;city&quot;: &quot;South Demetrischester&quot;, &quot;mainStreet&quot;: &quot;50811 Orn Shore&quot;, &quot;info&quot;: &quot;1378 Lehner Rest, Lake Irma, Cook Islands&quot;, &quot;no&quot;: &quot;0960&quot; } ] }, ... ], &quot;succeeded&quot;: true, &quot;errors&quot;: null, &quot;message&quot;: null} Reference(s)Most of the information in this article has gathered from various references. https://www.codewithmukesh.com/blog/pagination-in-aspnet-core-webapi/ https://code-maze.com/paging-aspnet-core-webapi/ https://medium.com/@zarkopafilis/asp-net-core-2-2-3-rest-api-26-pagination-650d0363ccf6 https://www.carlrippon.com/scalable-and-performant-asp-net-core-web-apis-paging/ https://schneids.net/paging-in-asp-net-web-api","link":"/a-professional-asp.net-core-api-paging/"},{"title":"A Professional ASP.NET Core API - RabbitMQ","text":"RabbitMQ is an open-source message-broker software that originally implemented the Advanced Message Queuing Protocol (AMQP) and has since been extended with a plug-in architecture to support Streaming Text Oriented Messaging Protocol, MQ Telemetry Transport, and other protocols. A message broker acts as a middleman for various services (e.g. a web application, as in this example). They can be used to reduce loads and delivery times of web application servers by delegating tasks that would normally take up a lot of time or resources to a third party that has no other job. A message can include any kind of information. It could, for example, have information about a process or task that should start on another application (which could even be on another server), or it could be just a simple text message. The queue-manager software stores the messages until a receiving application connects and takes a message off the queue. The receiving application then processes the message. When the user has entered user information into the web interface, the web application will create a “PDF processing” message that includes all of the important information the user needs into a message and place it onto a queue defined in RabbitMQ. The basic architecture of a message queue is simple - there are client applications called producers that create messages and deliver them to the broker (the message queue). Other applications, called consumers, connect to the queue and subscribe to the messages to be processed. Software may act as a producer, or consumer, or both a consumer and a producer of messages. Messages placed onto the queue are stored until the consumer retrieves them. When and why should you use RabbitMQ?Message queueing allows web servers to respond to requests quickly instead of being forced to perform resource-heavy procedures on the spot that may delay response time. Message queueing is also good when you want to distribute a message to multiple consumers or to balance loads between workers. The consumer takes a message off the queue and starts processing the PDF. At the same time, the producer is queueing up new messages. The consumer can be on a totally different server than the producer or they can be located on the same server. The request can be created in one programming language and handled in another programming language. The point is, the two applications will only communicate through the messages they are sending to each other, which means the sender and receiver have low coupling. The user sends a PDF creation request to the web application. The web application (the producer) sends a message to RabbitMQ that includes data from the request such as name and email. An exchange accepts the messages from the producer and routes them to correct message queues for PDF creation. The PDF processing worker (the consumer) receives the task message and starts processing the PDF. ExchangesMessages are not published directly to a queue; instead, the producer sends messages to an exchange. An exchange is responsible for routing the messages to different queues with the help of bindings and routing keys. Binding is a link that you set up to bind a queue to an exchange (A link between a queue and an exchange). Routing key is a message attribute the exchange looks at when deciding how to route the message to queues (depending on exchange type). Exchanges, connections, and queues can be configured with parameters such as durable, temporary, and auto delete upon creation. Durable exchanges survive server restarts and last until they are explicitly deleted. Temporary exchanges exist until RabbitMQ is shut down. Auto-deleted exchanges are removed once the last bound object is unbound from the exchange. In RabbitMQ, there are four different types of exchanges that route the message differently using different parameters and bindings setups. Clients can create their own exchanges or use the predefined default exchanges which are created when the server starts for the first time. Message flow in RabbitMQ The producer publishes a message to an exchange. When creating an exchange, the type must be specified. This topic will be covered later on. The exchange receives the message and is now responsible for routing the message. The exchange takes different message attributes into account, such as the routing key, depending on the exchange type. Bindings must be created from the exchange to queues. In this case, there are two bindings to two different queues from the exchange. The exchange routes the message into the queues depending on message attributes. The messages stay in the queue until they are handled by a consumer The consumer handles the message. Types of exchanges Direct: The message is routed to the queues whose binding key exactly matches the routing key of the message. For example, if the queue is bound to the exchange with the binding key pdfprocess, a message published to the exchange with a routing key pdfprocess is routed to that queue. Fanout: A fanout exchange routes messages to all of the queues bound to it. Topic: The topic exchange does a wildcard match between the routing key and the routing pattern specified in the binding. Headers: Headers exchanges use the message header attributes for routing. Direct ExchangeA direct exchange delivers messages to queues based on a message routing key. The routing key is a message attribute added to the message header by the producer. Think of the routing key as an “address” that the exchange is using to decide how to route the message. A message goes to the queue(s) with the binding key that exactly matches the routing key of the message. The direct exchange type is useful to distinguish messages published to the same exchange using a simple string identifier. The default exchange AMQP brokers must provide for the direct exchange is “amq.direct”. Imagine that queue A (create_pdf_queue) in the image below (Direct Exchange Figure) is bound to a direct exchange (pdf_events) with the binding key pdf_create. When a new message with routing key pdf_create arrives at the direct exchange, the exchange routes it to the queue where the binding_key = routing_key, in the case to queue A (create_pdf_queue). Scenario 1 Exchange: pdf_events Queue A: create_pdf_queue Binding key between exchange (pdf_events) and Queue A (create_pdf_queue): pdf_create Scenario 2 Exchange: pdf_events Queue B: pdf_log_queue Binding key between exchange (pdf_events) and Queue B (pdf_log_queue): pdf_log Example A message with routing key pdf_log is sent to the exchange pdf_events. The messages is routed to pdf_log_queue because the routing key (pdf_log) matches the binding key (pdf_log). If the message routing key does not match any binding key, the message is discarded. Default Exchange The default exchange is a pre-declared direct exchange with no name, usually referred by an empty string. When you use default exchange, your message is delivered to the queue with a name equal to the routing key of the message. Every queue is automatically bound to the default exchange with a routing key which is the same as the queue name. Topic ExchangeTopic exchanges route messages to queues based on wildcard matches between the routing key and the routing pattern, which is specified by the queue binding. Messages are routed to one or many queues based on a matching between a message routing key and this pattern. The routing key must be a list of words, delimited by a period (.). Examples are agreements.us and agreements.eu.stockholm which in this case identifies agreements that are set up for a company with offices in lots of different locations. The routing patterns may contain an asterisk (“”) to match a word in a specific position of the routing key (e.g., a routing pattern of “agreements...b.“ only match routing keys where the first word is “agreements” and the fourth word is “b”). A pound symbol (“#”) indicates a match of zero or more words (e.g., a routing pattern of “agreements.eu.berlin.#” matches any routing keys beginning with “agreements.eu.berlin”). The consumers indicate which topics they are interested in (like subscribing to a feed for an individual tag). The consumer creates a queue and sets up a binding with a given routing pattern to the exchange. All messages with a routing key that match the routing pattern are routed to the queue and stay there until the consumer consumes the message. The default exchange AMQP brokers must provide for the topic exchange is “amq.topic”. Scenario 1 The image to the right shows an example where consumer A is interested in all the agreements in Berlin. Exchange: agreements Queue A: berlin_agreements Routing pattern between exchange (agreements) and Queue A (berlin_agreements): agreements.eu.berlin.# Example of message routing key that matches: agreements.eu.berlin and agreements.eu.berlin.headstore Scenario 2 Consumer B is interested in all the agreements. Exchange: agreements Queue B: all_agreements Routing pattern between exchange (agreements) and Queue B (all_agreements): agreements.# Example of message routing key that matches: agreements.eu.berlin and agreements.us Scenario 3 Consumer C is interested in all agreements for European head stores. Exchange: agreements Queue C: headstore_agreements Routing pattern between exchange (agreements) and Queue C (headstore_agreements): agreements.eu.*.headstore Example of message routing keys that will match: agreements.eu.berlin.headstore and agreements.eu.stockholm.headstore Example A message with routing key agreements.eu.berlin is sent to the exchange agreements. The messages are routed to the queue berlin_agreements because the routing pattern of “agreements.eu.berlin.#” matches the routing keys beginning with “agreements.eu.berlin”. The message is also routed to the queue all_agreements because the routing key (agreements.eu.berlin) matches the routing pattern (agreements.#). Fanout ExchangeA fanout exchange copies and routes a received message to all queues that are bound to it regardless of routing keys or pattern matching as with direct and topic exchanges. The keys provided will simply be ignored. Fanout exchanges can be useful when the same message needs to be sent to one or more queues with consumers who may process the same message in different ways. The image to the right (Fanout Exchange) shows an example where a message received by the exchange is copied and routed to all three queues bound to the exchange. It could be sport or weather updates that should be sent out to each connected mobile device when something happens, for instance. The default exchange AMQP brokers must provide for the topic exchange is “amq.fanout”. Scenario 1 Exchange: sport_news Queue A: Mobile client queue A Binding: Binding between the exchange (sport_news) and Queue A (Mobile client queue A) Example A message is sent to the exchange sport_news. The message is routed to all queues (Queue A, Queue B, Queue C) because all queues are bound to the exchange. Provided routing keys are ignored. Headers ExchangeA headers exchange routes messages based on arguments containing headers and optional values. Headers exchanges are very similar to topic exchanges, but route messages based on header values instead of routing keys. A message matches if the value of the header equals the value specified upon binding. A special argument named “x-match”, added in the binding between exchange and queue, specifies if all headers must match or just one. Either any common header between the message and the binding count as a match, or all the headers referenced in the binding need to be present in the message for it to match. The “x-match” property can have two different values: “any” or “all”, where “all” is the default value. A value of “all” means all header pairs (key, value) must match, while value of “any” means at least one of the header pairs must match. Headers can be constructed using a wider range of data types, integer or hash for example, instead of a string. The headers exchange type (used with the binding argument “any”) is useful for directing messages which contain a subset of known (unordered) criteria. The default exchange AMQP brokers must provide for the topic exchange is “amq.headers”. Example Exchange: Binding to Queue A with arguments (key = value): format = pdf, type = report, x-match = all Exchange: Binding to Queue B with arguments (key = value): format = pdf, type = log, x-match = any Exchange: Binding to Queue C with arguments (key = value): format = zip, type = report, x-match = all Scenario 1 Message 1 is published to the exchange with header arguments (key = value): “format = pdf”, “type = report”. Message 1 is delivered to Queue A because all key/value pairs match, and Queue B since “format = pdf” is a match (binding rule set to “x-match =any”). Scenario 2 Message 2 is published to the exchange with header arguments of (key = value): “format = pdf”. Message 2 is only delivered to Queue B. Because the binding of Queue A requires both “format = pdf” and “type = report” while Queue B is configured to match any key-value pair (x-match = any) as long as either “format = pdf” or “type = log” is present. Scenario 3 Message 3 is published to the exchange with header arguments of (key = value): “format = zip”, “type = log”. Message 3 is delivered to Queue B since its binding indicates that it accepts messages with the key-value pair “type = log”, it doesn’t mind that “format = zip” since “x-match = any”. Queue C doesn’t receive any of the messages since its binding is configured to match all of the headers (“x-match = all”) with “format = zip”, “type = pdf”. No message in this example lives up to these criterias. It’s worth noting that in a header exchange, the actual order of the key-value pairs in the message is irrelevant. Dead Letter ExchangeIf no matching queue can be found for the message, the message is silently dropped. RabbitMQ provides an AMQP extension known as the “Dead Letter Exchange”, which provides the functionality to capture messages that are not deliverable. RabbitMQ concepts at a glance Concept Description Producer Application that sends the messages. Consumer Application that receives the messages. Queue Buffer that stores messages. Message Information that is sent from the producer to a consumer through RabbitMQ. Connection A TCP connection between your application and the RabbitMQ broker. Channel A virtual connection inside a connection. When publishing or consuming messages from a queue - it’s all done over a channel. Exchange Receives messages from producers and pushes them to queues depending on rules defined by the exchange type. To receive messages, a queue needs to be bound to at least one exchange. Binding A binding is a link between a queue and an exchange. Routing key A key that the exchange looks at to decide how to route the message to queues. Think of the routing key like an address for the message. AMQP Advanced Message Queuing Protocol is the protocol used by RabbitMQ for messaging. Users Users can be added from the management interface and every user can be assigned permissions such as rights to read, write and configure privileges. Users can also be assigned permissions to specific virtual hosts. Vhost, virtual host Virtual hosts provide a way to segregate applications using the same RabbitMQ instance. Different users can have different access privileges to different vhost and queues and exchanges can be created so they only exist in one vhost. Cluster A cluster consists of a set of connected computers that work together. If the RabbitMQ instance consisting of more than one node - it is called a RabbitMQ cluster. A cluster is a group of nodes i.e., a group of computers. Node A node is a single computer in the RabbitMQ cluster. RabbitMQ installation (Windows)Install Erlang/OTP RabbitMQ requires a 64-bit supported version of Erlang for Windows to be installed. Set ERLANG_HOME to where you actually put your Erlang installation, e.g. C:\\Program Files\\erl{version} (full path). The RabbitMQ batch files expect to execute %ERLANG_HOME%\\bin\\erl.exe. Go to Start &gt; Settings &gt; Control Panel &gt; System &gt; Advanced &gt; Environment Variables. Create the system environment variable ERLANG_HOME and set it to the full path of the directory which contains bin\\erl.exe. Install RabbitMQ Server After making sure a supported Erlang version is installed, download RabbitMQ server. Enable RabbitMQ Management Plugin Go to the directory where the RabbitMQ is installed. Now, enable the rabbitmq_management plugin using the rabbitmq-plugins command as shown below. 1sbin/rabbitmq-plugins enable rabbitmq_management The rabbitmq_management plugin is a combination of the following plugins. All of the following plugins will be enabled when you execute the above command: mochiweb webmachine rabbitmq_web_dispatch amqp_client rabbitmq_management_agent rabbitmq_management After enabling the rabbitmq_management plugin you should restart the RabbitMQ server as shown below. 123sbin/rabbitmqctl stopsbin/rabbitmq-server -detached And we’ll get an output like this: 1Warning: PID file not written; -detached was passed. Login to RabbitMQ Management Dashboard RabbitMQ Management is a plugin that we enabled for RabbitMQ in previous section. It gives a single static HTML page that makes background queries to the HTTP API for RabbitMQ. Information from the management interface can be useful when you are debugging your applications or when you need an overview of the whole system. If you see that the number of unacked messages starts to get high, it could mean that your consumers are getting slow. If you need to check if an exchange is working, you can try to send a test message. By default the management plugin runs on 15672 HTTP port. From your browser go to http://localhost:15672 The default username and password for RabbitMQ management plugin is: guest RabbitMQ Management DashboardThe RabbitMQ Management is a user-friendly interface that let you monitor and handle your RabbitMQ server from a web browser. Among other things queues, connections, channels, exchanges, users and user permissions can be handled - created, deleted and listed in the browser. You can monitor message rates and send/receive messages manually. Overview tabThe overview shows two charts, one for queued messages and one with the message rate. You can change the time interval shown in the chart by pressing the text (chart: last minute) above the charts. Information about all different statuses for messages can be found by pressing (?). Queued messages A chart of the total number of queued messages for all your queues. Ready show the number of messages that are available to be delivered. Unacked are the number of messages for which the server is waiting for acknowledgment. Messages rate A chart with the rate of how the messages are handled. Publish show the rate at which messages are entering the server and Confirm show a rate at which the server is confirming. Global Count The total number of connections, channels, exchanges, queues and consumers for ALL virtual hosts the current user has access to. Nodes Nodes show information about the different nodes in the RabbitMQ cluster (a cluster is a group of nodes i.e, a group of computers), or information about one single node if just one node is used. Here can information about server memory, number of erlang processes per node and other node-specific information be found. Info show i.e. further information about the node and enabled plugins. Port and contexts Listening ports for different protocols can be found here. More information about the protocols will be found in a later part of RabbitMQ for beginners. Import export definitions It is possible to import and export configuration definitions. When you download the definitions, you get a JSON representation of your broker (your RabbitMQ settings). This can be used to restore exchanges, queues, virtual hosts, policies, and users. This feature can be used as a backup. Every time you make a change in the config, you can keep the old settings just in case. Connections and Channels tabsA connection is a TCP connection between your application and the RabbitMQ broker. A channel is a virtual connection inside a connection. RabbitMQ connections and channels can be in different states; starting, tuning, opening, running, flow, blocking, blocked, closing, closed. If a connection enters flow-control this often means that the client is being rate-limited in some way. Connections The connection tab shows the connections established to the RabbitMQ server. vhost shows in which vhost the connection operates, the username the user associated with the connection. Channels tell the number of channels using the connection. SSL/TLS indicate whether the connection is secured with SSL. If you click on one of the connections, you get an overview of that specific connection. You can view channels in the connection and data rates. You can see client properties and you can close the connection. Channels The channel tab show information about all current channels. The vhost shows in which vhost the channel operates, the username the user associated with the channel. The mode tells the channel guarantee mode. It can be in confirm or transactional mode. When a channel is in confirm mode, both the broker and the client count messages. The broker then confirms messages as it handles them. Confirm mode is activated once the confirm.select method is used on a channel. If you click on one of the channels, you get a detailed overview of that specific channel. From here you can see the message rate on the number of logical consumers retrieving messages via the channel. Exchanges tabAn exchange receives messages from producers and pushes them to queues. The exchange must know exactly what to do with a message it receives. All exchanges can be listed from the exchange tab. Virtual host shows the vhost for the exchange, type is the exchange type such as direct, topic, headers, fanout. Features show the parameters for the exchange (e.g. D stand for durable, and AD for auto-delete). Features and types can be specified when the exchange is created. In this list there are some amq.* exchanges and the default (unnamed) exchange. These are created by default. By clicking on the exchange name, a detailed page about the exchange are shown. You can see and add bindings to the exchange. You can also publish a message to the exchange or delete the exchange. Queues tabThe queue tab show the queues for all or one selected vhost. Queues have different parameters and arguments depending on how they were created. The features column show the parameters that belong to the queue. It could be features like Durable queue (which ensure that RabbitMQ will never lose the queue), Message TTL (which tells how long a message published to a queue can live before it is discarded), Auto expire (which tells how long a queue can be unused for before it is automatically deleted), Max length (which tells how many (ready) messages a queue can contain before it starts to drop them) and Max length bytes (which tells the total body size for ready messages a queue can contain before it starts to drop them). You can also create a queue from this view. If you press on any chosen queue from the list of queues, all information about the queue are shown like in the pictures that follow below. The first two charts include the same information as the overview, but it just shows the number of queued messages and the message rates for that specific queue. Consumers Consumers show the consumers/channels that are connected to the queue. Bindings A binding can be created between an exchange and a queue. All active bindings to the queue are shown under bindings. You can also create a new binding to a queue from here or unbind a queue from an exchange. Publish message It is possible to manually publish a message to the queue from “publish message”. The message will be published to the default exchange with the queue name as given routing key - meaning that the message will be sent to the queue. It is also possible to publish a message to an exchange from the exchange view. Get message It is possible to manually inspect the message in the queue. “Get message” get the message to you and if you mark it as “requeue”, RabbitMQ puts it back to the queue in the same order. Delete or Purge queue A queue can be deleted by the delete button, and you can empty the queue by pressing purge. Admin tabFrom the Admin view, it is possible to add users and change user permissions. You can set up vhosts, policies, federation, and shovels. UI ExampleThis example shows how you can create a queue “example-queue” and an exchange called example.exchange. Queue view: Add queue Exchange view: Add exchange The exchange and the queue are connected by a binding called “pdfprocess”. Messages published to the exchange with the routing key “pdfprocess” will end up in the queue. Press on the exchange or on the queue go to “Add binding from this exchange” or “Add binding to this queue”. Publish a message to the exchange with the routing key “pdfprocess” Queue overview for example-queue when a message is published. A lot of things can be viewed and handled from the management interface and it will give you a good overview of your system. By looking into the management interface, you will get a good understanding about RabbitMQ and how everything is related. EasyNetQMassTransitA free, open-source distributed application framework for .NET. Install the below packages 1234567891011Install-Package MassTransit -Version 7.0.6dotnet add package MassTransit --version 7.0.6&lt;PackageReference Include=&quot;MassTransit&quot; Version=&quot;7.0.6&quot; /&gt;Install-Package MassTransit.AspNetCore -Version 7.0.6dotnet add package MassTransit.AspNetCore --version 7.0.6&lt;PackageReference Include=&quot;MassTransit.AspNetCore&quot; Version=&quot;7.0.6&quot; /&gt;Install-Package MassTransit.RabbitMQ -Version 7.0.6dotnet add package MassTransit.RabbitMQ --version 7.0.6&lt;PackageReference Include=&quot;MassTransit.RabbitMQ&quot; Version=&quot;7.0.6&quot; /&gt; Reference(s)Most of the information in this article has gathered from various references. https://www.cloudamqp.com/blog/2015-05-18-part1-rabbitmq-for-beginners-what-is-rabbitmq.html https://www.cloudamqp.com/blog/2015-05-27-part3-rabbitmq-for-beginners_the-management-interface.html https://www.cloudamqp.com/blog/2015-09-03-part4-rabbitmq-for-beginners-exchanges-routing-keys-bindings.html https://www.codewithmukesh.com/blog/rabbitmq-with-aspnet-core-microservice/ https://alvinvafana.blogspot.com/2019/10/messaging-through-service-bus-using.html https://www.rabbitmq.com/install-windows-manual.html https://www.thegeekstuff.com/2013/10/enable-rabbitmq-management-plugin/ https://www.codementor.io/@bosunbolawa/how-to-enable-rabbitmq-management-interface-owc5lzg7f https://doumer.me/micro-services-communication-rabbitmq-and-asp-net-core/ https://www.tutlane.com/tutorial/rabbitmq","link":"/a-professional-asp.net-core-api-rabbitmq/"},{"title":"A Professional ASP.NET Core API - Rate Limit","text":"AspNetCoreRateLimit is an ASP.NET Core rate limiting solution designed to control the rate of requests that clients can make to a Web API or MVC app based on IP address or client ID. The AspNetCoreRateLimit package contains an IpRateLimitMiddleware and a ClientRateLimitMiddleware, with each middleware you can set multiple limits for different scenarios like allowing an IP or Client to make a maximum number of calls in a time interval like per second, 15 minutes, etc. You can define these limits to address all requests made to an API or you can scope the limits to each API URL or HTTP verb and path. Install the below package 123Install-Package AspNetCoreRateLimit -Version 3.0.5dotnet add package AspNetCoreRateLimit --version 3.0.5&lt;PackageReference Include=&quot;AspNetCoreRateLimit&quot; Version=&quot;3.0.5&quot; /&gt; You can use two kinds of limitation: Rate limiting based on client IP Rate limiting based on client ID We examine both methods together. First, Add the following code: 12345678910111213141516171819202122232425262728293031323334353637// Startup.ConfigureServicespublic void ConfigureServices(IServiceCollection services){ // needed to load configuration from appsettings.json services.AddOptions(); // needed to store rate limit counters and ip rules services.AddMemoryCache(); //load general configuration from appsettings.json // IP services.Configure&lt;IpRateLimitOptions&gt;(Configuration.GetSection(&quot;IpRateLimiting&quot;)); // Client services.Configure&lt;ClientRateLimitOptions&gt;(Configuration.GetSection(&quot;ClientRateLimiting&quot;)); // IP //load ip rules from appsettings.json services.Configure&lt;IpRateLimitPolicies&gt;(Configuration.GetSection(&quot;IpRateLimitPolicies&quot;)); // Client //load client rules from appsettings.json services.Configure&lt;ClientRateLimitPolicies&gt;(Configuration.GetSection(&quot;ClientRateLimitPolicies&quot;)); // inject counter and rules stores services.AddSingleton&lt;IIpPolicyStore, MemoryCacheIpPolicyStore&gt;(); services.AddSingleton&lt;IRateLimitCounterStore, MemoryCacheRateLimitCounterStore&gt;(); services.AddControllers(); // https://github.com/aspnet/Hosting/issues/793 // the IHttpContextAccessor service is not registered by default. // the clientId/clientIp resolvers use it. services.AddSingleton&lt;IHttpContextAccessor, HttpContextAccessor&gt;(); // configuration (resolvers, counter key builders) services.AddSingleton&lt;IRateLimitConfiguration, RateLimitConfiguration&gt;();} Second, You should register the middleware before any other components as following: 12345678910111213141516171819202122// Startup.Configurepublic void Configure(IApplicationBuilder app, IWebHostEnvironment env){ // IP app.UseIpRateLimiting(); // Client app.UseClientRateLimiting(); if (env.IsDevelopment()) { app.UseDeveloperExceptionPage(); } app.UseHttpsRedirection(); app.UseRouting(); app.UseAuthorization(); app.UseEndpoints(endpoints =&gt; { endpoints.MapControllers(); });} If you load-balance your app, you’ll need to use IDistributedCache with Redis or SQLServer so that all kestrel instances will have the same rate limit store. Instead of the in-memory stores you should inject the distributed stores like this: 12345678// inject counter and rules distributed cache stores// IPservices.AddSingleton&lt;IIpPolicyStore, DistributedCacheIpPolicyStore&gt;();// Clientservices.AddSingleton&lt;IClientPolicyStore, DistributedCacheClientPolicyStore&gt;();services.AddSingleton&lt;IRateLimitCounterStore,DistributedCacheRateLimitCounterStore&gt;(); IP-based:General rules appsettings.json: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&quot;IpRateLimiting&quot;: { &quot;EnableEndpointRateLimiting&quot;: false, &quot;StackBlockedRequests&quot;: false, &quot;RealIpHeader&quot;: &quot;X-Real-IP&quot;, &quot;ClientIdHeader&quot;: &quot;X-ClientId&quot;, &quot;HttpStatusCode&quot;: 429, &quot;IpWhitelist&quot;: [ &quot;127.0.0.1&quot;, &quot;::1/10&quot;, &quot;192.168.0.0/24&quot; ], &quot;EndpointWhitelist&quot;: [ &quot;get:/api/license&quot;, &quot;*:/api/status&quot; ], &quot;ClientWhitelist&quot;: [ &quot;dev-id-1&quot;, &quot;dev-id-2&quot; ], &quot;GeneralRules&quot;: [ { &quot;Endpoint&quot;: &quot;*:/api/*&quot;, &quot;Period&quot;: &quot;1m&quot;, &quot;Limit&quot;: 30 }, { &quot;Endpoint&quot;: &quot;*:/api/values&quot;, &quot;Period&quot;: &quot;15m&quot;, &quot;Limit&quot;: 5 }, { &quot;Endpoint&quot;: &quot;get:/api/values&quot;, &quot;Period&quot;: &quot;1h&quot;, &quot;Limit&quot;: 5 }, { &quot;Endpoint&quot;: &quot;*&quot;, &quot;Period&quot;: &quot;1s&quot;, &quot;Limit&quot;: 2 }, { &quot;Endpoint&quot;: &quot;*&quot;, &quot;Period&quot;: &quot;15m&quot;, &quot;Limit&quot;: 100 }, { &quot;Endpoint&quot;: &quot;*&quot;, &quot;Period&quot;: &quot;12h&quot;, &quot;Limit&quot;: 1000 }, { &quot;Endpoint&quot;: &quot;*&quot;, &quot;Period&quot;: &quot;7d&quot;, &quot;Limit&quot;: 10000 } ]} EnableEndpointRateLimiting If it is set to false then the limits will apply globally and only rules that have as endpoint * will apply. For example if you set a limit of 5 calls per second, any HTTP call to any endpoint will count towards that limit. If it is set to true then the limits will apply for each endpoint as in {HTTP_Verb}:{PATH}. For example if you set a limit of 5 calls per second for *:/api/values a client can call get:/api/values 5 times per second but also 5 times put:/api/values. Endpoint *: A placeholder to anything {HTTP_Verb}:{PATH}: Endpoint format like get:/api/license Period Period format is {INT}{PERIOD_TYPE}, you can use one of the following period types: s, m, h, d. s: second m: minute h: hour d: day HttpStatusCode is set to 429, which means the HTTP status code returned to the client after the limit is triggered. ClientIdHeader It is used to extract the client id, if a client id is present in this header and matches a value specified in ClientWhitelist then no rate limits are applied. Limit Number of requests allowed. Limit format is {LONG}. Specific IPs appsettings.json: 123456789101112131415161718192021222324252627282930313233343536373839&quot;IpRateLimitPolicies&quot;: { &quot;IpRules&quot;: [ { &quot;Ip&quot;: &quot;84.247.85.224&quot;, &quot;Rules&quot;: [ { &quot;Endpoint&quot;: &quot;*&quot;, &quot;Period&quot;: &quot;1s&quot;, &quot;Limit&quot;: 10 }, { &quot;Endpoint&quot;: &quot;*&quot;, &quot;Period&quot;: &quot;15m&quot;, &quot;Limit&quot;: 200 } ] }, { &quot;Ip&quot;: &quot;192.168.3.22/25&quot;, &quot;Rules&quot;: [ { &quot;Endpoint&quot;: &quot;*&quot;, &quot;Period&quot;: &quot;1s&quot;, &quot;Limit&quot;: 5 }, { &quot;Endpoint&quot;: &quot;*&quot;, &quot;Period&quot;: &quot;15m&quot;, &quot;Limit&quot;: 150 }, { &quot;Endpoint&quot;: &quot;*&quot;, &quot;Period&quot;: &quot;12h&quot;, &quot;Limit&quot;: 500 } ] } ]} Client-basedGeneral rules appsettings.json: 123456789101112131415161718192021222324252627282930&quot;ClientRateLimiting&quot;: { &quot;EnableEndpointRateLimiting&quot;: false, &quot;StackBlockedRequests&quot;: false, &quot;ClientIdHeader&quot;: &quot;X-ClientId&quot;, &quot;HttpStatusCode&quot;: 429, &quot;EndpointWhitelist&quot;: [ &quot;get:/api/license&quot;, &quot;*:/api/status&quot; ], &quot;ClientWhitelist&quot;: [ &quot;dev-id-1&quot;, &quot;dev-id-2&quot; ], &quot;GeneralRules&quot;: [ { &quot;Endpoint&quot;: &quot;*&quot;, &quot;Period&quot;: &quot;1s&quot;, &quot;Limit&quot;: 2 }, { &quot;Endpoint&quot;: &quot;*&quot;, &quot;Period&quot;: &quot;15m&quot;, &quot;Limit&quot;: 100 }, { &quot;Endpoint&quot;: &quot;*&quot;, &quot;Period&quot;: &quot;12h&quot;, &quot;Limit&quot;: 1000 }, { &quot;Endpoint&quot;: &quot;*&quot;, &quot;Period&quot;: &quot;7d&quot;, &quot;Limit&quot;: 10000 } ]} Specific Clients appsettings.json: 123456789101112131415161718192021222324252627282930313233343536373839&quot;ClientRateLimitPolicies&quot;: { &quot;ClientRules&quot;: [ { &quot;ClientId&quot;: &quot;client-id-1&quot;, &quot;Rules&quot;: [ { &quot;Endpoint&quot;: &quot;*&quot;, &quot;Period&quot;: &quot;1s&quot;, &quot;Limit&quot;: 10 }, { &quot;Endpoint&quot;: &quot;*&quot;, &quot;Period&quot;: &quot;15m&quot;, &quot;Limit&quot;: 200 } ] }, { &quot;ClientId&quot;: &quot;client-id-2&quot;, &quot;Rules&quot;: [ { &quot;Endpoint&quot;: &quot;*&quot;, &quot;Period&quot;: &quot;1s&quot;, &quot;Limit&quot;: 5 }, { &quot;Endpoint&quot;: &quot;*&quot;, &quot;Period&quot;: &quot;15m&quot;, &quot;Limit&quot;: 150 }, { &quot;Endpoint&quot;: &quot;*&quot;, &quot;Period&quot;: &quot;12h&quot;, &quot;Limit&quot;: 500 } ] } ]} Update rate limits at runtimeAt application startup the IP/client rate limit rules defined in appsettings.json are loaded in cache by either MemoryCacheClientPolicyStore or DistributedCacheClientPolicyStore depending on what type of cache provider you are using. You can access the IP/client policy store inside a controller and modify the rules like so: IP-based 123456789101112131415161718192021222324252627282930313233343536public class IpRateLimitController : Controller{ private readonly IpRateLimitOptions _options; private readonly IIpPolicyStore _ipPolicyStore; public IpRateLimitController(IOptions&lt;IpRateLimitOptions&gt; optionsAccessor, IIpPolicyStore ipPolicyStore) { _options = optionsAccessor.Value; _ipPolicyStore = ipPolicyStore; } [HttpGet] public IpRateLimitPolicies Get() { return _ipPolicyStore.Get(_options.IpPolicyPrefix); } [HttpPost] public void Post() { var pol = _ipPolicyStore.Get(_options.IpPolicyPrefix); pol.IpRules.Add(new IpRateLimitPolicy { Ip = &quot;8.8.4.4&quot;, Rules = new List&lt;RateLimitRule&gt;(new RateLimitRule[] { new RateLimitRule { Endpoint = &quot;*:/api/testupdate&quot;, Limit = 100, Period = &quot;1d&quot; } }) }); _ipPolicyStore.Set(_options.IpPolicyPrefix, pol); }} Client-based 12345678910111213141516171819202122232425262728293031public class ClientRateLimitController : Controller{ private readonly ClientRateLimitOptions _options; private readonly IClientPolicyStore _clientPolicyStore; public ClientRateLimitController(IOptions&lt;ClientRateLimitOptions&gt; optionsAccessor, IClientPolicyStore clientPolicyStore) { _options = optionsAccessor.Value; _clientPolicyStore = clientPolicyStore; } [HttpGet] public ClientRateLimitPolicy Get() { return _clientPolicyStore.Get($&quot;{_options.ClientPolicyPrefix}_cl-key-1&quot;); } [HttpPost] public void Post() { var id = $&quot;{_options.ClientPolicyPrefix}_cl-key-1&quot;; var clPolicy = _clientPolicyStore.Get(id); clPolicy.Rules.Add(new RateLimitRule { Endpoint = &quot;*/api/testpolicyupdate&quot;, Period = &quot;1h&quot;, Limit = 100 }); _clientPolicyStore.Set(id, clPolicy); }} Quota exceeded responseYou can customize the throttled response using the QuotaExceededResponse property of the IpRateLimiting or ClientRateLimiting configuration sections: 1234567&quot;IpRateLimiting&quot;: { &quot;QuotaExceededResponse&quot;: { &quot;Content&quot;: &quot;{{ \\&quot;message\\&quot;: \\&quot;Whoa! Calm down, cowboy!\\&quot;, \\&quot;details\\&quot;: \\&quot;Quota exceeded. Maximum allowed: {0} per {1}. Please try again in {2} second(s).\\&quot; }}&quot;, &quot;ContentType&quot;: &quot;application/json&quot;, &quot;StatusCode&quot;: 429 },} {0} - rule.Limit {1} - rule.Period {2} - retryAfter How to write a custom IP rate limiter?To begin with, we need a class that inherits from ActionFilterAttribute. 123456789101112131415161718192021222324252627282930313233343536373839using System;using System.Net;using Microsoft.AspNetCore.Mvc;using Microsoft.AspNetCore.Mvc.Filters;using Microsoft.Extensions.Caching.Memory;namespace Attributes{ [AttributeUsage(AttributeTargets.Method)] public class RequestRateLimitAttribute : ActionFilterAttribute { public string Name { get; set; } public int Seconds { get; set; } private static MemoryCache Cache { get; } = new MemoryCache(new MemoryCacheOptions()); public override void OnActionExecuting(ActionExecutingContext context) { var ipAddress = context.HttpContext.Request.HttpContext.Connection.RemoteIpAddress; var memoryCacheKey = $&quot;{Name}-{ipAddress}&quot;; if (!Cache.TryGetValue(memoryCacheKey, out bool entry)) { var cacheEntryOptions = new MemoryCacheEntryOptions() .SetAbsoluteExpiration(TimeSpan.FromSeconds(Seconds)); Cache.Set(memoryCacheKey, true, cacheEntryOptions); } else { context.Result = new ContentResult { Content = $&quot;Requests are limited to 1, every {Seconds} seconds.&quot;, }; context.HttpContext.Response.StatusCode = (int)HttpStatusCode.TooManyRequests; } } }} Name: A name for uniqueness. Seconds: An integer to store the number of seconds. We need to override the virtual OnActionExecuting method from our inherited class. Within this method we are doing the following: Obtaining the users ip address. Storing the ip address in our memory cache, with a timeout based on the number of seconds we have assigned to our rate limiting action filter attribute. Returning an error message and a relevant status code (HTTP 429), in the event that the user hits our rate limit for the Api. Now to apply our action filter attribute to our desired controller action. I’ve added a simple Api endpoint for this example, and applied the attribute to the method, stating that we want to rate limit to 1 request, every 5 seconds. 12345678910111213[ApiController][Route(&quot;api&quot;)]public class ApiController : ControllerBase{ [HttpGet] // HERE [RequestRateLimit(Name = &quot;Limit Request Number&quot;, Seconds = 5)] [ProducesResponseType(StatusCodes.Status200OK)] public IActionResult Get() { return Ok(); }} Reference(s)Most of the information in this article has gathered from various references. https://github.com/stefanprodan/AspNetCoreRateLimit https://riptutorial.com/asp-net-core/example/18611/rate-limiting-based-on-client-ip https://riptutorial.com/asp-net-core/example/18612/rate-limiting-based-on-client-id https://edi.wang/post/2019/6/16/ip-rate-limit-for-aspnet-core https://github.com/sahgilbert/rate-limit-action-filter-attribute-aspnetcore","link":"/a-professional-asp.net-core-api-rate-limit/"},{"title":"A Professional ASP.NET Core API - Security Headers","text":"With the help of headers, your website could send some useful information to the browser. Let’s see how it is possible to add more protection to your website. To add a header for each request, we can use middleware. Enforce HTTPSHTTPS is pretty awesome. It not only encrypts the traffic between the client and server so others can’t see it, but also prevents others from modifying the content. So it also provides integrity. And being that you can now have HTTPS for free with services like Let’s Encrypt, most apps should start to look into using HTTPS. 1234567891011121314151617// Startup.ConfigureServicespublic void ConfigureServices(IServiceCollection services){ // Configure HTTPS redirection services.AddHttpsRedirection(options =&gt; { options.RedirectStatusCode = StatusCodes.Status301MovedPermanently; options.HttpsPort = 443; });}// Startup.Configurepublic void Configure(IApplicationBuilder app, IWebHostEnvironment env){ // Configure HTTPS redirection app.UseHttpsRedirection();} Headers via middlewareThis is my favorite. Specifying headers in middleware can be done in C# code by creating one or more pieces of middleware. Most examples in this post will use this approach. In short, you either create a new middleware class or call the Use method directly in the Configure method in Startup.cs: 12345678app.Use(async (context, next) =&gt;{ if (!context.Response.Headers.ContainsKey(&quot;Header-Name&quot;)) { context.Response.Headers.Add(&quot;Header-Name&quot;, &quot;Header-Value&quot;); } await next();}; The code adds a new header named Header-Name to all responses. It’s important to call the Use method before calling UseEndpoints, UseMvc, and similar. Types of headersThe following list examines an important part of application headers. Strict-Transport-Security (HSTS) It tells the browser: “You shall only access this URL over a secure connection.”. By submitting a Strict-Transport-Security header, the browser saves it and redirects itself to the HTTPS version without making an insecure call. 123456789101112131415161718192021222324// Startup.ConfigureServicespublic void ConfigureServices(IServiceCollection services){ // Configure HSTS // https://aka.ms/aspnetcore-hsts // https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Strict-Transport-Security services.AddHsts(options =&gt; { options.IncludeSubDomains = true; options.MaxAge = TimeSpan.FromDays(90); options.IncludeSubDomains = true; options.Preload = true; });}// Startup.Configurepublic void Configure(IApplicationBuilder app, IWebHostEnvironment env){ if (!env.IsDevelopment()) { // The default HSTS value is 30 days. You may want to change this for production scenarios, see https://aka.ms/aspnetcore-hsts. app.UseHsts(); }} X-Frame-OptionsThe X-Frame-Options HTTP response header can be used to indicate whether or not a browser should be allowed to render a page in a &lt;frame&gt;, &lt;iframe&gt;, &lt;embed&gt; or &lt;object&gt;. Sites can use this to avoid clickjacking attacks, by ensuring that their content is not embedded into other sites. 1context.Response.Headers.Add(&quot;x-frame-options&quot;, new StringValues(&quot;DENY&quot;)); Change the value to SAMEORIGIN to allow your site to iframe pages. The X-Frame-Options header is automatically added with the value SAMEORIGIN when enabling anti-forgery: 12345// Startup.ConfigureServicespublic void ConfigureServices(IServiceCollection services){ services.AddAntiforgery();} If you don’t want to add it automatically 1234services.AddAntiforgery(options =&gt;{ options.SuppressXFrameOptionsHeader = true;}); X-Permitted-Cross-Domain-PoliciesThe X-Permitted-Cross-Domain-Policies HTTP response header can be used to indicate whether or not an Adobe products such as Adobe Reader should be allowed to render a page. Sites can use this to avoid clickjacking attacks, by ensuring that their content is not embedded into other applications. 1context.Response.Headers.Add(&quot;X-Permitted-Cross-Domain-Policies&quot;, new StringValues(&quot;none&quot;)); X-XSS-ProtectionThe HTTP X-XSS-Protection response header is a feature that stops pages from loading when they detect reflected cross-site scripting (XSS) attacks. Although these protections are largely unnecessary in modern browsers when sites implement a strong Content-Security-Policy that disables the use of inline JavaScript ('unsafe-inline'), they can still provide protections for users of older web browsers that don’t yet support CSP. 1context.Response.Headers.Add(&quot;x-xss-protection&quot;, new StringValues(&quot;1; mode=block&quot;)); The value 1 means enabled and the mode of block will block the browser from rendering the page. X-Content-Type-OptionsMIME-type sniffing is an attack where a hacker tries to exploit missing metadata on served files. The header can be added in middleware: 1context.Response.Headers.Add(&quot;X-Content-Type-Options&quot;, &quot;nosniff&quot;); The value of nosniff will prevent primarily old browsers from MIME-sniffing. Referrer-PolicyWhen you click a link on a website, the calling URL is automatically transferred to the linked site. Unless this is necessary, you should disable it using the Referrer-Policy header: 1context.Response.Headers.Add(&quot;Referrer-Policy&quot;, &quot;no-referrer&quot;); There are a lot of possible values for this header, like same-origin that will set the referrer as long as the user stays on the same website. Feature-PolicyThe Feature-Policy header tells the browser which platform features your website needs. Most web apps won’t need to access the microphone or the vibrator functions available on mobile browsers. Why not be explicit about it to avoid imported scripts or framed pages to do things you don’t expect: 123456789101112131415161718192021222324context.Response.Headers.Add(&quot;Feature-Policy&quot;, new StringValues( &quot;accelerometer 'none';&quot; + &quot;ambient-light-sensor 'none';&quot; + &quot;autoplay 'none';&quot; + &quot;battery 'none';&quot; + &quot;camera 'none';&quot; + &quot;display-capture 'none';&quot; + &quot;document-domain 'none';&quot; + &quot;encrypted-media 'none';&quot; + &quot;execution-while-not-rendered 'none';&quot; + &quot;execution-while-out-of-viewport 'none';&quot; + &quot;gyroscope 'none';&quot; + &quot;magnetometer 'none';&quot; + &quot;microphone 'none';&quot; + &quot;midi 'none';&quot; + &quot;navigation-override 'none';&quot; + &quot;payment 'none';&quot; + &quot;picture-in-picture 'none';&quot; + &quot;publickey-credentials-get 'none';&quot; + &quot;sync-xhr 'none';&quot; + &quot;usb 'none';&quot; + &quot;wake-lock 'none';&quot; + &quot;xr-spatial-tracking 'none';&quot; )); X-Powered-ByLike ASP.NET, ASP.NET Core will return the X-Powered-By header. This happens when you host your website on IIS. This also means that you simply cannot remove the header in middleware, since this is out of hands for ASP.NET Core. web.config to the rescue: 12345678910&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;configuration&gt; &lt;system.webServer&gt; &lt;httpProtocol&gt; &lt;customHeaders&gt; &lt;remove name=&quot;X-Powered-By&quot; /&gt; &lt;/customHeaders&gt; &lt;/httpProtocol&gt; &lt;/system.webServer&gt;&lt;/configuration&gt; ServerLike X-Powered-By, IIS kindly identify itself in the Server header. While hackers probably quickly find out anyway, you should still make it as hard as possible by removing the header. There’s a dedicated security feature available in web.config to do that: 12345678&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;configuration&gt; &lt;system.webServer&gt; &lt;security&gt; &lt;requestFiltering removeServerHeader=&quot;true&quot; /&gt; &lt;/security&gt; &lt;/system.webServer&gt;&lt;/configuration&gt; To disable the Server header from Kestrel, you need to set AddServerHeader to false. 1234567891011121314151617// Program.CreateHostBuilderpublic class Program{ public static void Main(string[] args) { CreateHostBuilder(args).Build().Run(); } public static IHostBuilder CreateHostBuilder(string[] args) =&gt; Host.CreateDefaultBuilder(args) .ConfigureWebHostDefaults(webBuilder =&gt; { // HERE webBuilder.UseKestrel(c =&gt; c.AddServerHeader = false); webBuilder.UseStartup&lt;Startup&gt;(); });} Content-Security-Policy (CSP)The Content-Security-Policy response header allows web site administrators to control resources the user agent is allowed to load for a given page. With a few exceptions, policies mostly involve specifying server origins and script endpoints. This helps guard against cross-site scripting attacks (XSS). 12345678910111213141516171819202122232425262728293031context.Response.Headers.Add(&quot;Content-Security-Policy&quot;, new StringValues( &quot;base-uri 'none';&quot; + &quot;block-all-mixed-content;&quot; + &quot;child-src 'none';&quot; + &quot;connect-src 'none';&quot; + &quot;default-src 'none';&quot; + &quot;font-src 'none';&quot; + &quot;form-action 'none';&quot; + &quot;frame-ancestors 'none';&quot; + &quot;frame-src 'none';&quot; + &quot;img-src 'none';&quot; + &quot;manifest-src 'none';&quot; + &quot;media-src 'none';&quot; + &quot;object-src 'none';&quot; + &quot;sandbox;&quot; + &quot;script-src 'none';&quot; + &quot;script-src-attr 'none';&quot; + &quot;script-src-elem 'none';&quot; + &quot;style-src 'none';&quot; + &quot;style-src-attr 'none';&quot; + &quot;style-src-elem 'none';&quot; + &quot;upgrade-insecure-requests;&quot; + &quot;worker-src 'none';&quot; + &quot;default-src 'self';&quot; + &quot;img-src 'self'&quot; + &quot;font-src 'self';&quot; + &quot;style-src 'self';&quot; + &quot;script-src 'self'&quot; + &quot;frame-src 'self';&quot; + &quot;connect-src 'self';&quot; )); Expect-CTThe Expect-CT header lets sites opt in to reporting and/or enforcement of Certificate Transparency requirements, to prevent the use of misissued certificates for that site from going unnoticed. 1context.Response.Headers.Add(&quot;Expect-CT&quot;, new StringValues(&quot;max-age=0, enforce, report-uri=\\&quot;https://example.report-uri.com/r/d/ct/enforce\\&quot;&quot;)); All-In-One as a middleware1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798public sealed class SecurityHeadersMiddleware{ private readonly RequestDelegate _next; public SecurityHeadersMiddleware(RequestDelegate next) { _next = next; } public Task Invoke(HttpContext context) { // https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Referrer-Policy // TODO Change the value depending of your needs context.Response.Headers.Add(&quot;referrer-policy&quot;, new StringValues(&quot;strict-origin-when-cross-origin&quot;)); // https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Content-Type-Options context.Response.Headers.Add(&quot;x-content-type-options&quot;, new StringValues(&quot;nosniff&quot;)); // https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Frame-Options context.Response.Headers.Add(&quot;x-frame-options&quot;, new StringValues(&quot;DENY&quot;)); // https://security.stackexchange.com/questions/166024/does-the-x-permitted-cross-domain-policies-header-have-any-benefit-for-my-websit context.Response.Headers.Add(&quot;X-Permitted-Cross-Domain-Policies&quot;, new StringValues(&quot;none&quot;)); // https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-XSS-Protection context.Response.Headers.Add(&quot;x-xss-protection&quot;, new StringValues(&quot;1; mode=block&quot;)); // https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Expect-CT // You can use https://report-uri.com/ to get notified when a misissued certificate is detected context.Response.Headers.Add(&quot;Expect-CT&quot;, new StringValues(&quot;max-age=0, enforce, report-uri=\\&quot;https://example.report-uri.com/r/d/ct/enforce\\&quot;&quot;)); // https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Feature-Policy // https://github.com/w3c/webappsec-feature-policy/blob/master/features.md // https://developers.google.com/web/updates/2018/06/feature-policy // TODO change the value of each rule and check the documentation to see if new features are available context.Response.Headers.Add(&quot;Feature-Policy&quot;, new StringValues( &quot;accelerometer 'none';&quot; + &quot;ambient-light-sensor 'none';&quot; + &quot;autoplay 'none';&quot; + &quot;battery 'none';&quot; + &quot;camera 'none';&quot; + &quot;display-capture 'none';&quot; + &quot;document-domain 'none';&quot; + &quot;encrypted-media 'none';&quot; + &quot;execution-while-not-rendered 'none';&quot; + &quot;execution-while-out-of-viewport 'none';&quot; + &quot;gyroscope 'none';&quot; + &quot;magnetometer 'none';&quot; + &quot;microphone 'none';&quot; + &quot;midi 'none';&quot; + &quot;navigation-override 'none';&quot; + &quot;payment 'none';&quot; + &quot;picture-in-picture 'none';&quot; + &quot;publickey-credentials-get 'none';&quot; + &quot;sync-xhr 'none';&quot; + &quot;usb 'none';&quot; + &quot;wake-lock 'none';&quot; + &quot;xr-spatial-tracking 'none';&quot; )); // https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP // https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Security-Policy // TODO change the value of each rule and check the documentation to see if new rules are available context.Response.Headers.Add(&quot;Content-Security-Policy&quot;, new StringValues( &quot;base-uri 'none';&quot; + &quot;block-all-mixed-content;&quot; + &quot;child-src 'none';&quot; + &quot;connect-src 'none';&quot; + &quot;default-src 'none';&quot; + &quot;font-src 'none';&quot; + &quot;form-action 'none';&quot; + &quot;frame-ancestors 'none';&quot; + &quot;frame-src 'none';&quot; + &quot;img-src 'none';&quot; + &quot;manifest-src 'none';&quot; + &quot;media-src 'none';&quot; + &quot;object-src 'none';&quot; + &quot;sandbox;&quot; + &quot;script-src 'none';&quot; + &quot;script-src-attr 'none';&quot; + &quot;script-src-elem 'none';&quot; + &quot;style-src 'none';&quot; + &quot;style-src-attr 'none';&quot; + &quot;style-src-elem 'none';&quot; + &quot;upgrade-insecure-requests;&quot; + &quot;worker-src 'none';&quot; + &quot;default-src 'self';&quot; + &quot;img-src 'self'&quot; + &quot;font-src 'self';&quot; + &quot;style-src 'self';&quot; + &quot;script-src 'self'&quot; + &quot;frame-src 'self';&quot; + &quot;connect-src 'self';&quot; )); return _next(context); }} How to use the middleware?You should call athe above custom middleware as the following: 1234567891011121314151617181920public void Configure(IApplicationBuilder app, IWebHostEnvironment env){ if (!env.IsDevelopment()) { // HSTS should only be enabled on production, not on localhost app.UseHsts(); } // HERE // Add other security headers app.UseMiddleware&lt;SecurityHeadersMiddleware&gt;(); // Redirect http to https app.UseHttpsRedirection(); app.UseEndpoints(endpoints =&gt; { endpoints.MapControllers(); });} ValidationYou can check you have correctly set the security headers by using the following service: https://securityheaders.com Ready to use librariesNWebsec NWebsec consists of several security libraries for ASP.NET applications. Site: https://github.com/NWebsec/NWebsec Docs: https://docs.nwebsec.com/en/latest/ NetEscapades.AspNetCore.SecurityHeaders Small package to allow adding security headers to ASP.NET Core websites Site: https://github.com/andrewlock/NetEscapades.AspNetCore.SecurityHeaders Reference(s)Most of the information in this article has gathered from various references. https://blog.elmah.io/the-asp-net-core-security-headers-guide/ https://www.meziantou.net/security-headers-in-asp-net-core.htm https://improveandrepeat.com/2019/05/how-to-improve-the-security-headers-for-your-asp-net-application/ https://www.c-sharpcorner.com/article/asp-net-core-security-headers/ https://andrewlock.net/adding-default-security-headers-in-asp-net-core/ https://docs.microsoft.com/en-us/aspnet/core/security/enforcing-ssl https://joonasw.net/view/hsts-in-aspnet-core https://joonasw.net/view/enforcing-https-in-aspnet-core","link":"/a-professional-asp.net-core-api-security-headers/"},{"title":"A Professional ASP.NET Core API - Serilog","text":"Serilog is an alternative logging implementation that plugs into ASP.NET Core. It supports the same structured logging APIs, and receives log events from the ASP.NET Core framework class libraries, but adds a stack of features that make it a more appealing choice for some kinds of apps and environments. Install the below packages 123Install-Package Serilog.AspNetCore -Version 3.4.0dotnet add package Serilog.AspNetCore --version 3.4.0&lt;PackageReference Include=&quot;Serilog.AspNetCore&quot; Version=&quot;3.4.0&quot; /&gt; Serilog EnrichersTo enable Structured Logging and to unleash the full potential of Serilog, we use enrichers. These enrichers give you additional details like Machine Name, ProcessId, Thread Id when the log event had occurred for better diagnostics. It makes a developer’s life quite simpler.. Serilog SinksSerilog Sinks in simpler words relate to destinations for logging the data. In the packages that we are going to install to our ASP.NET Core application, Sinks for Console and File are included out of the box. That means we can write logs to Console and File System without adding any extra packages. Serilog supports various other destinations like MSSQL, SQLite, SEQ and more. Logger InitializationExceptions thrown during start-up are some of the most disruptive errors your application might face, and so the very first line of code in our Serilog-enabled app will set up logging and make sure any nasties are caught and recorded. 12345678910111213141516171819202122232425262728293031323334public class Program{ public static void Main(string[] args) { // HERE Log.Logger = new LoggerConfiguration() .Enrich.FromLogContext() /*Enricher*/ .WriteTo.Console() /*Sink*/ .CreateLogger(); try { Log.Information(&quot;Starting up&quot;); CreateHostBuilder(args).Build().Run(); } catch (Exception ex) { Log.Fatal(ex, &quot;Application start-up failed&quot;); } finally { Log.CloseAndFlush(); } } public static IHostBuilder CreateHostBuilder(string[] args) =&gt; Host.CreateDefaultBuilder(args) // HERE //Uses Serilog instead of default .NET Logger .UseSerilog() .ConfigureWebHostDefaults(webBuilder =&gt; { webBuilder.UseStartup&lt;Startup&gt;(); });} Cleaning the default logger The “Logging” section that you’ll find in appsettings.json isn’t used by Serilog, and can be removed: 12345678910{ &quot;Logging&quot;: { &quot;LogLevel&quot;: { &quot;Default&quot;: &quot;Information&quot;, &quot;Microsoft&quot;: &quot;Warning&quot;, &quot;Microsoft.Hosting.Lifetime&quot;: &quot;Information&quot; } }, &quot;AllowedHosts&quot;: &quot;*&quot;} After cleaning up here, the configuration looks like this: 123{ &quot;AllowedHosts&quot;: &quot;*&quot;} Writing your own log eventsYou should use ILogger&lt;T&gt; to log your own events as following 123456789101112131415public class HomeController : Controller{ private readonly ILogger&lt;HomeController&gt; _logger; public HomeController(ILogger&lt;HomeController&gt; logger) { _logger = logger; } public IActionResult Index([FromQuery] string name) { _logger.LogInformation(&quot;Hello, {Name}!&quot;, name); return View(); } } Log LevelsI also wanted you to know about the various Logging Levels. This is the fundamental concept of logging. When we wrote _logger.LogInformation(&quot;Hello, {Name}!&quot;, name);, we mentioned to the application that this is a log with the log-level set to Information. Log levels make sense because it allows you to define the type of log. Is it a critical log? just a debug message? a warning message? There are 7 log-levels included : Trace: Detailed messages with sensitive app data. Debug: Useful for the development environment. Information: General messages, like the way we mentioned earlier. Warning: For unexpected events. Error: For exceptions and errors. Critical: For failures that may need immediate attention. Streamlined request loggingOur log output will now be rather quiet. We didn’t want a dozen log events per request, but chances are, we’ll need to know what requests the app is handling in order to do most diagnostic analysis. To switch request logging back on, we’ll add Serilog to the app’s middleware pipeline over in Startup.cs. You’ll find a Configure() method in there like the following: 1234567891011121314151617181920212223242526public void Configure(IApplicationBuilder app, IWebHostEnvironment env){ if (env.IsDevelopment()) { app.UseDeveloperExceptionPage(); } else { app.UseExceptionHandler(&quot;/Home/Error&quot;); app.UseHsts(); } app.UseHttpsRedirection(); app.UseStaticFiles(); // HERE app.UseSerilogRequestLogging(); app.UseRouting(); app.UseAuthorization(); app.UseEndpoints(endpoints =&gt; { endpoints.MapControllerRoute( name: &quot;default&quot;, pattern: &quot;{controller=Home}/{action=Index}/{id?}&quot;); });} We’ll be a bit tactical about where we add Serilog into the pipeline. I tend not to want request logging for static files, so I add UseSerilogRequestLogging() later in the pipeline, as shown above. Read from configurationChange Program.Main() as following 1234567891011121314151617181920212223242526272829303132333435// Program.cspublic static void Main(string[] args){ // HERE //Read Configuration from appSettings var config = new ConfigurationBuilder() .SetBasePath(Directory.GetCurrentDirectory()) .AddJsonFile(&quot;appsettings.json&quot;) .Build(); Log.Logger = new LoggerConfiguration() .MinimumLevel.Debug() // &lt;- Set the minimum level .Enrich.FromLogContext() .Enrich.WithMachineName() .Enrich.WithProcessId() .Enrich.WithThreadId() .Enrich.WithCorrelationId() .WriteTo.Console() /*HERE*/ .ReadFrom.Configuration(config) .CreateLogger(); try { Log.Information(&quot;Starting up&quot;); CreateHostBuilder(args).Build().Run(); } catch (Exception ex) { Log.Fatal(ex, &quot;Application start-up failed&quot;); } finally { Log.CloseAndFlush(); }} Setting up Serilog Add Serilog section to appsettings.json 123456789101112131415161718192021222324252627282930313233343536373839404142{ &quot;AllowedHosts&quot;: &quot;*&quot;, &quot;Serilog&quot;: { &quot;Using&quot;: [ &quot;Serilog.Sinks.Console&quot;, &quot;Serilog.Sinks.File&quot; ], &quot;MinimumLevel&quot;: { &quot;Default&quot;: &quot;Debug&quot;, &quot;Override&quot;: { &quot;Microsoft&quot;: &quot;Warning&quot;, &quot;System&quot;: &quot;Warning&quot; } }, &quot;WriteTo&quot;: [ { &quot;Name&quot;: &quot;Console&quot; }, { &quot;Name&quot;: &quot;File&quot;, &quot;Args&quot;: { &quot;path&quot;: &quot;D:\\\\Logs\\\\log.txt&quot;, &quot;outputTemplate&quot;: &quot;{Timestamp} {Message}{NewLine:1}{Exception:1}&quot; } } ], &quot;Destructure&quot;: [ { &quot;Name&quot;: &quot;With&quot;, &quot;Args&quot;: { &quot;policy&quot;: &quot;Sample.CustomPolicy, Sample&quot; } }, { &quot;Name&quot;: &quot;ToMaximumDepth&quot;, &quot;Args&quot;: { &quot;maximumDestructuringDepth&quot;: 4 } }, { &quot;Name&quot;: &quot;ToMaximumStringLength&quot;, &quot;Args&quot;: { &quot;maximumStringLength&quot;: 100 } }, { &quot;Name&quot;: &quot;ToMaximumCollectionCount&quot;, &quot;Args&quot;: { &quot;maximumCollectionCount&quot;: 10 } } ], &quot;Enrich&quot;: [ &quot;FromLogContext&quot;, &quot;WithMachineName&quot;, &quot;WithProcessId&quot;, &quot;WithThreadId&quot; ], &quot;Properties&quot;: { &quot;ApplicationName&quot;: &quot;Serilog.WebApplication&quot; } }} Useful EnrichersHere’s how to add some of the most useful enrichers. 123456789101112131415Install-Package Serilog.Enrichers.Environment -Version 2.1.3dotnet add package Serilog.Enrichers.Environment --version 2.1.3&lt;PackageReference Include=&quot;Serilog.Enrichers.Environment&quot; Version=&quot;2.1.3&quot; /&gt;Install-Package Serilog.Enrichers.Process -Version 2.0.2-dev-00731dotnet add package Serilog.Enrichers.Process --version 2.0.2-dev-00731&lt;PackageReference Include=&quot;Serilog.Enrichers.Process&quot; Version=&quot;2.0.2-dev-00731&quot; /&gt;Install-Package Serilog.Enrichers.Thread -Version 3.2.0-dev-00747dotnet add package Serilog.Enrichers.Thread --version 3.2.0-dev-00747&lt;PackageReference Include=&quot;Serilog.Enrichers.Thread&quot; Version=&quot;3.2.0-dev-00747&quot; /&gt;Install-Package Serilog.Enrichers.CorrelationId -Version 3.0.1dotnet add package Serilog.Enrichers.CorrelationId --version 3.0.1&lt;PackageReference Include=&quot;Serilog.Enrichers.CorrelationId&quot; Version=&quot;3.0.1&quot; /&gt; Change your Program.Main() as following 123456789101112131415161718192021222324// HEREvar config = new ConfigurationBuilder() .AddJsonFile(&quot;appsettings.json&quot;) .Build();Log.Logger = new LoggerConfiguration() .MinimumLevel.Verbose() .Enrich.FromLogContext() // Serilog.Enrichers.Environment .Enrich.WithMachineName() .Enrich.WithEnvironmentUserName() // Serilog.Enrichers.Process .Enrich.WithProcessId() .Enrich.WithProcessName() // Serilog.Enrichers.Thread .Enrich.WithThreadId() .Enrich.WithThreadName() // The {ThreadName} property will only be attached when it is not null. Otherwise it will be omitted. If you want to get this property always attached you can use the following: .Enrich.WithProperty(ThreadNameEnricher.ThreadNamePropertyName, &quot;MyDefault&quot;) // Serilog.Enrichers.CorrelationId .Enrich.WithCorrelationId() // Change the output template to as following, {Properties} placeholder Collects and displays all of the above enrichers. .WriteTo.Console(outputTemplate: &quot;{Timestamp:yyyy-MM-dd HH:mm:ss.fff zzz} [{Level:u3}] {Message:lj} {Properties}{NewLine}{Exception}&quot;) .ReadFrom.Configuration(config) .CreateLogger(); For Serilog.Enrichers.CorrelationId, you need to add AddHttpContextAccessor too. 1234567// Startup.ConfigureServicespublic void ConfigureServices(IServiceCollection services){ services.AddControllers(); // HERE services.AddHttpContextAccessor();} Enrich from global propertiesYou can also specify properties globally. In some cases, we need to calculate properties on startup, which can be done using the Fluent API: 1234567Log.Logger = new LoggerConfiguration() .Enrich.FromLogContext() // HERE .Enrich.WithProperty(&quot;Version&quot;, typeof(Program).Assembly.GetName().Version) // 'Version' is accessible via {Properties} .WriteTo.Console(outputTemplate: &quot;{Timestamp:yyyy-MM-dd HH:mm:ss.fff zzz} [{Level:u3}] {Message:lj} {Properties}{NewLine}{Exception}&quot;) .CreateLogger(); TimingsSerilog’s support for structured data makes it a great way to collect timing information. It’s easy to get started with in development, because the timings are printed to the same output as other log messages (the console, files, etc.) so a metrics server doesn’t have to be available all the time. Serilog Timings is built with some specific requirements in mind: One operation produces exactly one log event (events are raised at the completion of an operation)Natural and fully-templated messagesEvents for a single operation have a single event type, across both success and failure cases (only the logging level and Outcome properties change)This keeps noise in the log to a minimum, and makes it easy to extract and manipulate timing information on a per-operation basis. Install below packages 123Install-Package SerilogTimings -Version 2.3.0dotnet add package SerilogTimings --version 2.3.0&lt;PackageReference Include=&quot;SerilogTimings&quot; Version=&quot;2.3.0&quot; /&gt; The simplest use case is to time an operation, without explicitly recording success/failure: 1234using (Operation.Time(&quot;Submitting payment for {OrderId}&quot;, order.Id)){ // Timed block of code goes here} At the completion of the using block, a message will be written to the log like: 1[INF] Submitting payment for order-12345 completed in 456.7 ms Operations that can either succeed or fail, or that produce a result, can be created with Operation.Begin(): 123456using (var op = Operation.Begin(&quot;Retrieving orders for {CustomerId}&quot;, customer.Id)){ // Timed block of code goes here op.Complete();} Using op.Complete() will produce the same kind of result as in the first example: 1[INF] Retrieving orders for customer-67890 completed in 7.8 ms If the operation is not completed by calling Complete(), it is assumed to have failed and a warning-level event will be written to the log instead: 1[WRN] Retrieving orders for customer-67890 abandoned in 1234.5 ms In this case the Outcome property will be “abandoned”.To suppress this message, for example when an operation turns out to be inapplicable, use op.Cancel(). Once Cancel() has been called, no event will be written by the operation on either completion or abandonment. Levelling Timings are most useful in production, so timing events are recorded at the Information level and higher, which should generally be collected all the time. If you truly need Verbose - or Debug-level timings, you can trigger them with Operation.At() or the OperationAt() extension method on ILogger: 1234using (Operation.At(LogEventLevel.Debug).Time(&quot;Preparing zip archive&quot;)){ // ...} When a level is specified, both completion and abandonment events will use it. To configure a different abandonment level, pass the second optional parameter to the At() method. Serilog &amp; KibanaKibana is an open source data visualization user interface for ElasticSearch. Think of ElasticSearch as the database and Kibana as the web user interface which you can use to build graphs and query data in ElasticSearch. Installation Get Elasticsearch Get Kibana Start Elasticsearch: bin/elasticsearch Start Kibana: bin/kibana Open Kibana: http://localhost:5601 ElasticSearch Sink Install below package 123Install-Package Serilog.Sinks.ElasticSearch -Version 8.4.1dotnet add package Serilog.Sinks.ElasticSearch --version 8.4.1&lt;PackageReference Include=&quot;Serilog.Sinks.ElasticSearch&quot; Version=&quot;8.4.1&quot; /&gt; After installation, add the following code: 12345678910111213141516171819202122232425262728293031323334353637383940414243// Program.csusing Serilog.Formatting.Elasticsearch;using Serilog.Sinks.Elasticsearch;public static void Main(string[] args){ var environment = Environment.GetEnvironmentVariable(&quot;ASPNETCORE_ENVIRONMENT&quot;); var config = BuildConfigurationRoot(); Log.Logger = new LoggerConfiguration() // HERE .WriteTo.Elasticsearch(ConfigureElasticSink(config, environment)) .CreateLogger(); try { Log.Information(&quot;Starting up&quot;); CreateHostBuilder(args).Build().Run(); } catch (Exception ex) { Log.Fatal(ex, &quot;Application start-up failed&quot;); } finally { Log.CloseAndFlush(); }}// HEREprivate static ElasticsearchSinkOptions ConfigureElasticSink(IConfigurationRoot configuration, string environment){ return new ElasticsearchSinkOptions(new Uri(configuration[&quot;ElasticConfiguration:Uri&quot;])) { AutoRegisterTemplate = true, AutoRegisterTemplateVersion = AutoRegisterTemplateVersion.ESv7, CustomFormatter = new ExceptionAsObjectJsonFormatter(renderMessage: true), // Our ElasticSearch index: ASSEMBLYNAME-ENVIROMENT-YEAR-MONTH // This index must introduce to ElasticSearch/Kibana IndexFormat = $&quot;{Assembly.GetExecutingAssembly().GetName().Name.ToLower().Replace(&quot;.&quot;, &quot;-&quot;)}-{environment?.ToLower().Replace(&quot;.&quot;, &quot;-&quot;)}-{DateTime.UtcNow:yyyy-MM}&quot; };} And also in appsettings.json 123&quot;ElasticConfiguration&quot;: { &quot;Uri&quot;: &quot;http://localhost:9200&quot;}, Define index to Kibana If this is your first run you will see Create index pattern page so go to step 3 but if you had any index before, start form beggining: Run your application, Then browse the Kibana via http://localhost:5601/app/home/. Find Connect to your Elasticsearch index link and click on it. After that, Click on Create index pattern and introduce our index format like below1ASSEMBLYNAME-ENVIROMENT-* =&gt; myapp-development-* Click on Next step Choose @timestamp, then click on Create index pattern Now, You can go to Discover page and find your logs! Reference(s)Most of the information in this article has gathered from various references. https://nblumhardt.com/2019/10/serilog-in-aspnetcore-3/ https://www.codewithmukesh.com/blog/serilog-in-aspnet-core-3-1/ https://dejanstojanovic.net/aspnet/2018/october/extending-serilog-with-additional-values-to-log/ https://github.com/nblumhardt/serilog-timings https://benfoster.io/blog/serilog-best-practices/ https://esg.dev/posts/serilog-dos-and-donts/ https://www.humankode.com/asp-net-core/logging-with-elasticsearch-kibana-asp-net-core-and-docker","link":"/a-professional-asp.net-core-api-serilog/"},{"title":"A Professional ASP.NET Core API - Swagger","text":"When consuming a web API, understanding its various methods can be challenging for a developer. Swagger, also known as OpenAPI, solves the problem of generating useful documentation and help pages for web APIs. It provides benefits such as interactive documentation, client SDK generation, and API discoverability. Swashbuckle can be added with the following approaches: Install the below package 123Install-Package Swashbuckle.AspNetCore -Version 5.6.1dotnet add package Swashbuckle.AspNetCore --version 5.6.1&lt;PackageReference Include=&quot;Swashbuckle.AspNetCore&quot; Version=&quot;5.6.1&quot; /&gt; Add the following code 123456789// Startup.ConfigureServicespublic void ConfigureServices(IServiceCollection services){ services.AddControllers(); // Register the Swagger generator, defining 1 or more Swagger documents services.AddSwaggerGen();} Enable the middleware for serving the generated JSON document and the Swagger UI 1234567891011121314151617181920// Startup.Configurepublic void Configure(IApplicationBuilder app){ // Enable middleware to serve generated Swagger as a JSON endpoint. app.UseSwagger(); // Enable middleware to serve swagger-ui (HTML, JS, CSS, etc.), // specifying the Swagger JSON endpoint. app.UseSwaggerUI(c =&gt; { c.SwaggerEndpoint(&quot;/swagger/v1/swagger.json&quot;, &quot;My API V1&quot;); }); app.UseRouting(); app.UseEndpoints(endpoints =&gt; { endpoints.MapControllers(); });} Browse Swagger doc via below URL http[s]://localhost:port/swagger How to use Newtonsoft.Json?Install the below package 123Install-Package Swashbuckle.AspNetCore.Newtonsoft -Version 5.6.1dotnet add package Swashbuckle.AspNetCore.Newtonsoft --version 5.6.1&lt;PackageReference Include=&quot;Swashbuckle.AspNetCore.Newtonsoft&quot; Version=&quot;5.6.1&quot; /&gt; Then 123// explicit opt-in - needs to be placed after AddSwaggerGen()services.AddSwaggerGenNewtonsoftSupport(); How to set swagger on default URL?Update the above code with the following change 12345app.UseSwaggerUI(c =&gt;{ c.SwaggerEndpoint(&quot;swagger/v1/swagger.json&quot;, &quot;My API V1&quot;); c.RoutePrefix = string.Empty; // HERE}); Now you can browse the swagger doc url via http[s]://localhost:port How to integrate it with ReDoc?ReDoc is just another implementation of Swagger UI. Install the below package 123Install-Package Swashbuckle.AspNetCore.ReDoc -Version 5.6.1dotnet add package Swashbuckle.AspNetCore.ReDoc --version 5.6.1&lt;PackageReference Include=&quot;Swashbuckle.AspNetCore.ReDoc&quot; Version=&quot;5.6.1&quot; /&gt; Update your codes 123456789101112131415161718192021222324252627public void ConfigureServices(IServiceCollection services){ services.AddControllers(); services.AddSwaggerGen();} public void Configure(IApplicationBuilder app, IWebHostEnvironment env){ app.UseSwagger(); app.UseReDoc(c =&gt; { c.SpecUrl(&quot;../swagger/v1/swagger.json&quot;); }); app.UseSwaggerUI(c =&gt; { c.SwaggerEndpoint(&quot;v1/swagger.json&quot;, &quot;My API V1&quot;); }); app.UseRouting(); app.UseEndpoints(endpoints =&gt; { endpoints.MapControllers(); });} Now you are able to browse them via below urls Swagger: http[s]://localhost:port/swagger ReDoc: http[s]://localhost:port/api-docs How to use XML comments with Swagger?Right-click the project in Solution Explorer and select Edit &lt;project_name&gt;.csproj. Manually add the following lines to the .csproj file: 1234&lt;PropertyGroup&gt; &lt;GenerateDocumentationFile&gt;true&lt;/GenerateDocumentationFile&gt; &lt;NoWarn&gt;$(NoWarn);1591&lt;/NoWarn&gt;&lt;/PropertyGroup&gt; Then add the below code too 123456789101112public void ConfigureServices(IServiceCollection services){ services.AddControllers(); services.AddSwaggerGen(c =&gt; { // HERE // Set the comments path for the Swagger JSON and UI. var xmlFile = $&quot;{Assembly.GetExecutingAssembly().GetName().Name}.xml&quot;; var xmlPath = Path.Combine(AppContext.BaseDirectory, xmlFile); c.IncludeXmlComments(xmlPath); });} Now you can use it like the following 12345678910111213141516171819202122232425262728/// &lt;summary&gt;/// Creates a TodoItem./// &lt;/summary&gt;/// &lt;remarks&gt;/// Sample request:////// POST /Todo/// {/// &quot;id&quot;: 1,/// &quot;name&quot;: &quot;Item1&quot;,/// &quot;isComplete&quot;: true/// }////// &lt;/remarks&gt;/// &lt;param name=&quot;item&quot;&gt;&lt;/param&gt;/// &lt;returns&gt;A newly created TodoItem&lt;/returns&gt;/// &lt;response code=&quot;201&quot;&gt;Returns the newly created item&lt;/response&gt;/// &lt;response code=&quot;400&quot;&gt;If the item is null&lt;/response&gt; [HttpPost][ProducesResponseType(StatusCodes.Status201Created)][ProducesResponseType(StatusCodes.Status400BadRequest)]public ActionResult&lt;TodoItem&gt; Create(TodoItem item){ _context.TodoItems.Add(item); _context.SaveChanges(); return CreatedAtRoute(&quot;GetTodo&quot;, new { id = item.Id }, item);} AnnotationsInstall the below package 123Install-Package Swashbuckle.AspNetCore.Annotations -Version 5.6.1dotnet add package Swashbuckle.AspNetCore.Annotations --version 5.6.1&lt;PackageReference Include=&quot;Swashbuckle.AspNetCore.Annotations&quot; Version=&quot;5.6.1&quot; /&gt; Enable it 12345// Startup.ConfigureServicesservices.AddSwaggerGen(config =&gt;{ config.EnableAnnotations();}); Enrich Operation Metadata 12345678[HttpPost][SwaggerOperation( Summary = &quot;Creates a new product&quot;, Description = &quot;Requires admin privileges&quot;, OperationId = &quot;CreateProduct&quot;, Tags = new[] { &quot;Purchase&quot;, &quot;Products&quot; })]public IActionResult Create([FromBody]Product product) Enrich Response Metadata 1234[HttpPost][SwaggerResponse(201, &quot;The product was created&quot;, typeof(Product))][SwaggerResponse(400, &quot;The product data is invalid&quot;)]public IActionResult Create([FromBody]Product product) Enrich Parameter Metadata You can annotate “path”, “query” or “header” bound parameters or properties (i.e. decorated with [FromRoute], [FromQuery] or [FromHeader]) with a SwaggerParameterAttribute to enrich the corresponding Parameter metadata that’s generated by Swashbuckle: 123[HttpGet]public IActionResult GetProducts( [FromQuery, SwaggerParameter(&quot;Search keywords&quot;, Required = true)]string keywords) Enrich RequestBody Metadata You can annotate “body” bound parameters or properties (i.e. decorated with [FromBody]) with a SwaggerRequestBodyAttribute to enrich the corresponding RequestBody metadata that’s generated by Swashbuckle: 123[HttpPost]public IActionResult CreateProduct( [FromBody, SwaggerRequestBody(&quot;The product payload&quot;, Required = true)]Product product) Enrich Schema Metadata 123456789101112[SwaggerSchema(Required = new[] { &quot;Description&quot; })]public class Product{ [SwaggerSchema(&quot;The product identifier&quot;, ReadOnly = true)] public int Id { get; set; } [SwaggerSchema(&quot;The product description&quot;)] public string Description { get; set; } [SwaggerSchema(&quot;The date it was created&quot;, Format = &quot;date&quot;)] public DateTime DateCreated { get; set; }} Add Tag Metadata 1234[SwaggerTag(&quot;Create, read, update and delete Products&quot;)]public class ProductsController{} List Known Subtypes for Inheritance and Polymorphism 12345678910111213// Startup.ConfigureServicesservices.AddSwaggerGen(config =&gt;{ config.EnableAnnotations(enableAnnotationsForInheritance: true, enableAnnotationsForPolymorphism: true);});// Shape.cs[SwaggerSubType(typeof(Rectangle))][SwaggerSubType(typeof(Circle))]public abstract class Shape{} Enrich Polymorphic Base Classes with Discriminator Metadata 1234567891011121314// Startup.ConfigureServicesservices.AddSwaggerGen(config =&gt;{ config.EnableAnnotations(enableAnnotationsForInheritance: true, enableAnnotationsForPolymorphism: true);});// Shape.cs[SwaggerDiscriminator(&quot;shapeType&quot;)][SwaggerSubType(typeof(Rectangle), DiscriminatorValue = &quot;rectangle&quot;)][SwaggerSubType(typeof(Circle), DiscriminatorValue = &quot;circle&quot;)]public abstract class Shape{ public ShapeType { get; set; }} Ready to use pluginsSwashbuckle.AspNetCore.Filters Some useful Swashbuckle filters which add additional documentation, e.g. request and response examples, a file upload button, etc. See its Readme for more details 123Install-Package Swashbuckle.AspNetCore.Filters -Version 5.1.2dotnet add package Swashbuckle.AspNetCore.Filters --version 5.1.2&lt;PackageReference Include=&quot;Swashbuckle.AspNetCore.Filters&quot; Version=&quot;5.1.2&quot; /&gt; Unchase.Swashbuckle.AspNetCore.Extensions Some useful extensions (filters), which add additional documentation, e.g. hide PathItems for unaccepted roles, fix enums for client code generation, etc. See its Readme for more details 123Install-Package Unchase.Swashbuckle.AspNetCore.Extensions -Version 2.3.12dotnet add package Unchase.Swashbuckle.AspNetCore.Extensions --version 2.3.12&lt;PackageReference Include=&quot;Unchase.Swashbuckle.AspNetCore.Extensions&quot; Version=&quot;2.3.12&quot; /&gt; MicroElements.Swashbuckle.FluentValidation Use FluentValidation rules instead of ComponentModel attributes to augment generated Swagger Schemas 123Install-Package MicroElements.Swashbuckle.FluentValidation -Version 4.0.0dotnet add package MicroElements.Swashbuckle.FluentValidation --version 4.0.0&lt;PackageReference Include=&quot;MicroElements.Swashbuckle.FluentValidation&quot; Version=&quot;4.0.0&quot; /&gt; Swagger &amp; Authorization1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586// SwaggerBasicAuthMiddleware.cspublic class SwaggerBasicAuthMiddleware{ private readonly RequestDelegate _next; private readonly SwaggerAuthorizationOptions _options; public SwaggerBasicAuthMiddleware(RequestDelegate next, IOptions&lt;SwaggerAuthorizationOptions&gt; options) { _next = next; _options = options.Value; } public async Task Invoke(HttpContext context) { var segment = string.IsNullOrEmpty(_options.UrlSegment) ? &quot;/swagger&quot; : _options.UrlSegment; var redirect = string.IsNullOrEmpty(_options.RedirectUrl) ? &quot;/Login&quot; : _options.RedirectUrl; if (context.Request.Path.StartsWithSegments(segment) &amp;&amp; !context.User.Identity.IsAuthenticated) { context.Response.StatusCode = StatusCodes.Status401Unauthorized; context.Response.Redirect(redirect); return; } await _next.Invoke(context); }}// SwaggerAuthorizationOptions.cspublic class SwaggerAuthorizationOptions{ public string RedirectUrl { get; set; } public string UrlSegment { get; set; }}// SwaggerAuthorizeExtensions.cspublic static class SwaggerAuthorizeExtensions{ public static IServiceCollection AddSwaggerAuthorization(this IServiceCollection service, Action&lt;SwaggerAuthorizationOptions&gt; options = default) { options = options ?? (opts =&gt; { }); service.Configure(options); return service; } public static IApplicationBuilder UseSwaggerAuthorization(this IApplicationBuilder builder) { return builder.UseMiddleware&lt;SwaggerBasicAuthMiddleware&gt;(); }}// Startup.ConfigureServicespublic void ConfigureServices(IServiceCollection services){ services.AddControllers(); services.AddSwaggerGen(); services.AddSwaggerAuthorization(option =&gt; { option.RedirectUrl = &quot;/Login&quot;; option.UrlSegment = &quot;/swagger&quot;; });}// Startup.Configurepublic void Configure(IApplicationBuilder app){ app.UseRouting(); app.UseAuthorization(); app.UseAuthentication(); // HERE // Becarful, It should be after UseAuthorization &amp; UseAuthentication middlewares. app.UseSwaggerAuthorization(); // Enable middleware to serve generated Swagger as a JSON endpoint. app.UseSwagger(); // Enable middleware to serve swagger-ui (HTML, JS, CSS, etc.), // specifying the Swagger JSON endpoint. app.UseSwaggerUI(c =&gt; { c.SwaggerEndpoint(&quot;/swagger/v1/swagger.json&quot;, &quot;My API V1&quot;); }); app.UseEndpoints(endpoints =&gt; { endpoints.MapControllers(); });} Reference(s)Most of the information in this article has gathered from various references. https://docs.microsoft.com/en-us/aspnet/core/tutorials/getting-started-with-swashbuckle http://stevenmaglio.blogspot.com/2019/12/using-swagger-ui-and-redoc-in-aspnet.html https://github.com/domaindrivendev/Swashbuckle.AspNetCore https://github.com/mattfrear/Swashbuckle.AspNetCore.Filters","link":"/a-professional-asp.net-core-api-swagger/"},{"title":"A Professional ASP.NET Core API - Versioning","text":"When developing APIs, you should keep one thing in mind: Change is inevitable. When your API has reached a point where you need to add more responsibilities, you should consider versioning your API. Hence you will need a versioning strategy. Install the below package 123Install-Package Microsoft.AspNetCore.Mvc.Versioning -Version 4.1.1dotnet add package Microsoft.AspNetCore.Mvc.Versioning --version 4.1.1&lt;PackageReference Include=&quot;Microsoft.AspNetCore.Mvc.Versioning&quot; Version=&quot;4.1.1&quot; /&gt; Configure API versioning1234567891011121314151617// Startup.ConfigureServicesusing Microsoft.AspNetCore.Mvc.Versioning;public void ConfigureServices(IServiceCollection services){ services.AddApiVersioning(config =&gt; { // You can specify the default version as 1.0. config.DefaultApiVersion = new ApiVersion(1, 0); // Set defaul version if you dont specify it. config.AssumeDefaultVersionWhenUnspecified = true; // Let the clients of the API know all supported versions. // The consumers could read the 'api-supported-versions' header. config.ReportApiVersions = true; config.ApiVersionReader = new HeaderApiVersionReader(&quot;x-api-version&quot;); });} if you don’t set these two configurations 12config.DefaultApiVersion = new ApiVersion(1, 0);config.AssumeDefaultVersionWhenUnspecified = true; And don’t set any version for your Controller/Action, You will get the following error when you send a request. 12345678{ &quot;error&quot;: { &quot;code&quot;: &quot;ApiVersionUnspecified&quot;, &quot;message&quot;: &quot;An API version is required, but was not specified.&quot;, &quot;innerError&quot;: null }} API Version ReaderAPI Version Reader defines how an API version is read from the HTTP request. If not explicitly configured, the default setting is that our API version will be a query string parameter named v (example: ../users?v=2.0). Another, probably more popular option is to store the API version in the HTTP header. We have also the possibility of having an API version both in a query string as well as in an HTTP header. Query string parameter 12// /api/home?v=2.0config.ApiVersionReader = new QueryStringApiVersionReader(&quot;v&quot;); HTTP header 12// x-api-version: 2.0config.ApiVersionReader = new HeaderApiVersionReader(&quot;x-api-version&quot;); Media type 1234567// Content-Type: text/plain; charset=utf-8; v=2// Content-Type: application/json; charset=utf-8; v=2config.ApiVersionReader = new MediaTypeApiVersionReader();// Content-Type: text/plain; charset=utf-8; version=2// Content-Type: application/json; charset=utf-8; version=2config.ApiVersionReader = new MediaTypeApiVersionReader(&quot;version&quot;)); API Version Reader Composition 12345config.ApiVersionReader = ApiVersionReader.Combine( new QueryStringApiVersionReader(&quot;v&quot;), new HeaderApiVersionReader(&quot;x-api-version&quot;), new MediaTypeApiVersionReader(&quot;version&quot;)); The URL Path 12// [Route(&quot;api/v{version:apiVersion}/[controller]&quot;)] config.ApiVersionReader = new UrlSegmentApiVersionReader(); Set version(s) to Controllers and ActionsConsider the following example: 1234567891011121314151617181920212223242526272829303132333435363738[ApiController]// api-supported-versions: 1.1, 2.0// api-deprecated-versions: 1.0[ApiVersion(&quot;1.0&quot;, Deprecated = true)][ApiVersion(&quot;1.1&quot;)][ApiVersion(&quot;2.0&quot;)]// api/v2/values/4// api/v2.0/values/4[Route(&quot;api/v{version:apiVersion}/[controller]&quot;)]public class ValuesController : ControllerBase{ // GET api/v1/values [HttpGet] public ActionResult&lt;IEnumerable&lt;string&gt;&gt; Get() { return new string[] { &quot;value1&quot;, &quot;value2&quot; }; } // GET api/v2/values/5 // GET api/v2.0/values/5 [HttpGet(&quot;{id}&quot;)] [MapToApiVersion(&quot;2.0&quot;)] public ActionResult&lt;string&gt; Get(int id) { return &quot;value&quot;; } // POST api/v1/values/5 // POST api/v1.0/values/5 // POST api/v1.1/values/5 // POST api/v2/values/5 // POST api/v2.0/values/5 [HttpPost(&quot;{id}&quot;)] public ActionResult&lt;string&gt; Post(int id) { return &quot;value&quot;; }} Tip: Since no version number is specified to the actions in ValuesController, all the endpoints are assumed to have the default version of 1.0. [ApiVersion(“1.0”, Deprecated = true)] Annotating our controller with, for example, [ApiVersion(“1.0”)] attribute, means that this controller supports API version 1.0. To deprecate some version in our API controller, we need to set Deprecated flag to true: [ApiVersion(“1.0”, Deprecated = true)]. In such cases a api-deprecated-versions header will be added to identify deprecated versions. [ApiVersion(“1.1”)] [ApiVersion(“2.0”)] Controllers can support multiple API versions. [Route(“api/v{version:apiVersion}/[controller]”)] To implement URL path versioning, You can modify the Route attribute of the controllers to accept API versioning info in the path param. [MapToApiVersion(“2.0”)] From the several versions introduced for the controller, you can specify a specific version (eg. version 2.0) for the action. The action is only available with this version. If you try to access it with other versions, you will encounter an UnsupportedApiVersion error. 1234567{ &quot;error&quot;: { &quot;code&quot;: &quot;UnsupportedApiVersion&quot;, &quot;message&quot;: &quot;The HTTP resource that matches the request URI 'http://localhost:5000/api/v1.0/values/4' does not support the API version '1.0'.&quot;, &quot;innerError&quot;: null }} [ApiVersionNeutral] If we have a service that is version-neutral, we will mark that controller with [ApiVersionNeutral] attribute. How to get the API version inside a controller? 1var apiVersion = HttpContext.GetRequestedApiVersion(); And also 1public IActionResult Get( int id, ApiVersion apiVersion ) {} API Version ConventionsBesides attributing our controllers and methods, another way to configure service versioning is with API versioning conventions. There are several reasons why would we use API versioning conventions instead of attributes: Centralized management and application of all service API versions Apply API versions to services defined by controllers in external .NET assemblies Dynamically apply API versions from external sources; for example, from the configuration 1234services.AddApiVersioning(config =&gt;{ config.Conventions.Controller&lt;MyController&gt;().HasApiVersion(1, 0);}); Here’s an example of setting deprecated API version as well as versioning controller actions: 12345678910services.AddApiVersioning(config =&gt;{ config.Conventions.Controller&lt;MyController&gt;() .HasDeprecatedApiVersion(1, 0) .HasApiVersion(1, 1) .HasApiVersion(2, 0) .Action(c =&gt; c.Get1_0()).MapToApiVersion(1, 0) .Action(c =&gt; c.Get1_1()).MapToApiVersion(1, 1) .Action(c =&gt; c.Get2_0()).MapToApiVersion(2, 0);}); There is also an option to define custom conventions.There is a IControllerConvention interface for this purpose. Custom conventions are added to the convention builder through the API versioning options: 1234services.AddApiVersioning(config =&gt;{ config.Conventions.Add(new MyCustomConvention());}); How to prevent an unavailable or deprecated api version from loading?Consider the following example 123456789101112131415161718192021[ApiController][ApiVersion(&quot;1.1&quot;)][ApiVersion(&quot;2.0&quot;)][Route(&quot;api/v{version:apiVersion}/[controller]&quot;)]public class ValuesController : ControllerBase{ // GET api/v1/values [HttpGet] [MapToApiVersion(&quot;1.0&quot;)] public ActionResult&lt;IEnumerable&lt;string&gt;&gt; Get() { return new string[] { &quot;value1&quot;, &quot;value2&quot; }; } [HttpGet(&quot;{id}&quot;)] [MapToApiVersion(&quot;2.0&quot;)] public ActionResult&lt;string&gt; Get(int id) { return &quot;value&quot;; }} In this example, we have two valid versions (1.1, 2.0) for all actions but the Get() has mapped to version 1.0 which is invalid for us. We want to prevent this method from loading. To do this, you should write an ActionFilterAttribute as following 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677// UnavailableApiVersion.cspublic class UnavailableApiVersion{ public string Code { get; set; } public string Message { get; set; } public IEnumerable&lt;string&gt; AvailableVersions { get; set; } public IEnumerable&lt;string&gt; DeprecatedVersions { get; set; } public UnavailableApiVersion() { AvailableVersions = new List&lt;string&gt;(); DeprecatedVersions = new List&lt;string&gt;(); }} // PreventUnavailableApiVersionsAttribute.cs[AttributeUsage(AttributeTargets.Class)]public class PreventUnavailableApiVersionsAttribute : ActionFilterAttribute{ public string Header { get; set; } = &quot;x-api-version&quot;; public string QueryString { get; set; } = &quot;v&quot;; public string UrlSegment { get; set; } = &quot;version&quot;; public bool IsADeprecatedVersionValid { get; set; } = true; private string GetUrl(HttpRequest request) { return $&quot;{request.Scheme}://{request.Host}{request.Path}{request.QueryString}&quot;; } public override void OnActionExecuting(ActionExecutingContext context) { var props = context.ActionDescriptor.Properties; var url = GetUrl(context.HttpContext.Request); var headerVersion = context.HttpContext.Request.Headers.Count(x =&gt; string.Equals(x.Key, Header.Trim(), StringComparison.InvariantCultureIgnoreCase)); var routeVersion = context.RouteData.Values[UrlSegment.Trim()]; var queryVersion = context.HttpContext.Request.QueryString.Value.Trim(); var matchedQuery = queryVersion.Replace(&quot;?&quot;, &quot;&quot;).Split('&amp;').FirstOrDefault(x =&gt; x.StartsWith($&quot;{QueryString}=&quot;)); var isSkippable = routeVersion == null &amp;&amp; headerVersion == 0 &amp;&amp; string.IsNullOrEmpty(matchedQuery); if (isSkippable) return; var version = &quot;&quot;; if (routeVersion != null) { version = routeVersion.ToString(); } if (headerVersion &gt; 0) { version = context.HttpContext.Request.Headers[&quot;x-api-version&quot;].ToString(); } if (!string.IsNullOrEmpty(matchedQuery)) { version = matchedQuery.Replace($&quot;{QueryString}=&quot;, &quot;&quot;); } version = version.Contains('.') ? version : $&quot;{version}.0&quot;; foreach (var prop in props) { var apiVersionModel = prop.Value as ApiVersionModel; if (apiVersionModel != null) { if (apiVersionModel.IsApiVersionNeutral) return; var deprecated = apiVersionModel.DeprecatedApiVersions.Select(x =&gt; x.ToString()); var impl = apiVersionModel.ImplementedApiVersions.Select(x =&gt; x.ToString()); var supported = apiVersionModel.SupportedApiVersions.Select(x =&gt; x.ToString()); var isSupported = IsADeprecatedVersionValid ? impl.Contains(version) : supported.Contains(version); if (!isSupported) { context.Result = new JsonResult(new UnavailableApiVersion { Code = &quot;UnavailableApiVersion&quot;, AvailableVersions = supported, DeprecatedVersions = deprecated, Message = $&quot;The HTTP resource that matches the request URI '{url}' does not available via the API version '{version}'.&quot; }); context.HttpContext.Response.StatusCode = (int)HttpStatusCode.BadRequest; } } } }} And consume it on top of your controller 12345678910111213141516171819202122[PreventUnavailableApiVersions][ApiController][ApiVersion(&quot;1.1&quot;)][ApiVersion(&quot;2.0&quot;)][Route(&quot;api/v{version:apiVersion}/[controller]&quot;)]public class ValuesController : ControllerBase{ // GET api/v1/values [HttpGet] [MapToApiVersion(&quot;1.0&quot;)] public ActionResult&lt;IEnumerable&lt;string&gt;&gt; Get() { return new string[] { &quot;value1&quot;, &quot;value2&quot; }; } [HttpGet(&quot;{id}&quot;)] [MapToApiVersion(&quot;2.0&quot;)] public ActionResult&lt;string&gt; Get(int id) { return &quot;value&quot;; }} Now, whenever you call the Get() action, the PreventUnavailableApiVersions checks the version you requested (1.0) with versions of your controller (1.1, 2.0), If the requested version is not in the list, it returns the same error as below. 123456789101112// Status code: 400 Bad Request{ &quot;code&quot;: &quot;UnavailableApiVersion&quot;, &quot;message&quot;: &quot;The HTTP resource that matches the request URI 'http://localhost:5000/api/v1/WeatherForecast?v=1.0' does not available by the API version '1.0'.&quot;, &quot;availableVersions&quot;: [ &quot;1.1&quot;, &quot;2.0&quot; ], &quot;deprecatedVersions&quot;: [ &quot;1.0&quot; ]} Deprecated versions As a default behaviour deprecated versions are in valid list it means if you write like the below code 1234567891011121314151617181920212223[PreventUnavailableApiVersions][ApiController][ApiVersion(&quot;1.0&quot;, Deprecated = true)][ApiVersion(&quot;1.1&quot;)][ApiVersion(&quot;2.0&quot;)][Route(&quot;api/v{version:apiVersion}/[controller]&quot;)]public class ValuesController : ControllerBase{ // GET api/v1/values [HttpGet] [MapToApiVersion(&quot;1.0&quot;)] public ActionResult&lt;IEnumerable&lt;string&gt;&gt; Get() { return new string[] { &quot;value1&quot;, &quot;value2&quot; }; } [HttpGet(&quot;{id}&quot;)] [MapToApiVersion(&quot;2.0&quot;)] public ActionResult&lt;string&gt; Get(int id) { return &quot;value&quot;; }} You will see the result of action method without any unavailable error but you can config to remove deprecated versions from list of valid versions.You just need to write 12// IsADeprecatedVersionValid: default is true[PreventUnavailableApiVersions(IsADeprecatedVersionValid = false)] Now, the action filter consider the version 1.0 as an unavailable and you will get an UnavailableApiVersion response. Configuration PreventUnavailableApiVersions action filter supports header, query string and url segment mode so you can configure any of these just like what you did in ApiVersionReader. 123456789101112// Default is 'v'// QueryStringApiVersionReader(&quot;ver&quot;)[PreventUnavailableApiVersions(QueryString = &quot;ver&quot;)] // Default is 'x-api-version'// HeaderApiVersionReader(&quot;api-version-header&quot;)[PreventUnavailableApiVersions(Header = &quot;api-version-header&quot;)]// UrlSegmentApiVersionReader// Default is 'version', [Route(&quot;api/v{version:apiVersion}/[controller]&quot;)]// [Route(&quot;api/v{myversion:apiVersion}/[controller]&quot;)][PreventUnavailableApiVersions(UrlSegment = &quot;myversion&quot;)] A Second way! Always you can find an easier way so you can rewrite the above action filter as following 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677[AttributeUsage(AttributeTargets.Class | AttributeTargets.Method)]public class UnavailableApiVersionsAttribute : ActionFilterAttribute{ private string GetUrl(HttpRequest request) { return $&quot;{request.Scheme}://{request.Host}{request.Path}{request.QueryString}&quot;; } private string FixVersion(string version) { var v = version.Contains('.') ? version : $&quot;{version}.0&quot;; return v.Trim(); } private readonly string _commaSeparatedVersions; public UnavailableApiVersionsAttribute(string commaSeparatedVersions) { _commaSeparatedVersions = commaSeparatedVersions; } public string Header { get; set; } = &quot;x-api-version&quot;; public string QueryString { get; set; } = &quot;v&quot;; public string UrlSegment { get; set; } = &quot;version&quot;; public bool IsADeprecatedVersionValid { get; set; } = true; public override void OnActionExecuting(ActionExecutingContext context) { if (string.IsNullOrEmpty(_commaSeparatedVersions)) return; var props = context.ActionDescriptor.Properties; var url = GetUrl(context.HttpContext.Request); var headerVersion = context.HttpContext.Request.Headers.Count(x =&gt; string.Equals(x.Key, Header.Trim(), StringComparison.InvariantCultureIgnoreCase)); var routeVersion = context.RouteData.Values[UrlSegment.Trim()]; var queryVersion = context.HttpContext.Request.QueryString.Value.Trim(); var matchedQuery = queryVersion.Replace(&quot;?&quot;, &quot;&quot;).Split('&amp;').FirstOrDefault(x =&gt; x.StartsWith($&quot;{QueryString}=&quot;)); var isSkippable = routeVersion == null &amp;&amp; headerVersion == 0 &amp;&amp; string.IsNullOrEmpty(matchedQuery); if (isSkippable) return; var version = &quot;&quot;; if (routeVersion != null) { version = routeVersion.ToString(); } if (headerVersion &gt; 0) { version = context.HttpContext.Request.Headers[&quot;x-api-version&quot;].ToString(); } if (!string.IsNullOrEmpty(matchedQuery)) { version = matchedQuery.Replace($&quot;{QueryString}=&quot;, &quot;&quot;); } version = FixVersion(version); var unavailableVersions = _commaSeparatedVersions.Split(',').Select(x =&gt; FixVersion(x.Trim())); var isUnavailableVersion = unavailableVersions.Contains(version); foreach (var prop in props) { var apiVersionModel = prop.Value as ApiVersionModel; if (apiVersionModel != null) { if (apiVersionModel.IsApiVersionNeutral) return; var deprecated = apiVersionModel.DeprecatedApiVersions.Select(x =&gt; x.ToString()); var supported = IsADeprecatedVersionValid ? apiVersionModel.SupportedApiVersions.Select(x =&gt; x.ToString()).Concat(deprecated).Except(unavailableVersions) : apiVersionModel.SupportedApiVersions.Select(x =&gt; x.ToString()).Except(unavailableVersions); if(!isUnavailableVersion &amp;&amp; !IsADeprecatedVersionValid) { isUnavailableVersion = deprecated.Contains(version); } if (isUnavailableVersion) { context.Result = new JsonResult(new UnavailableApiVersion { Code = &quot;UnavailableApiVersion&quot;, AvailableVersions = supported, DeprecatedVersions = deprecated, Message = $&quot;The HTTP resource that matches the request URI '{url}' does not available via the API version '{version}'.&quot; }); context.HttpContext.Response.StatusCode = (int)HttpStatusCode.BadRequest; } } } }} UnavailableApiVersions attribute get a comma-separated versions via constructor just on action methods. When you use this action filter you cannot access to the api via these forbidden versions. So you should consume it like below code 1234567891011121314151617181920212223[ApiController][ApiVersion(&quot;1.0&quot;, Deprecated = true)][ApiVersion(&quot;1.1&quot;)][ApiVersion(&quot;2.0&quot;)][Route(&quot;api/v{version:apiVersion}/[controller]&quot;)]public class ValuesController : ControllerBase{ // GET api/v1/values [HttpGet] [MapToApiVersion(&quot;1.0&quot;)] [UnavailableApiVersions(&quot;1.0,1.1&quot;)] public ActionResult&lt;IEnumerable&lt;string&gt;&gt; Get() { return new string[] { &quot;value1&quot;, &quot;value2&quot; }; } [HttpGet(&quot;{id}&quot;)] [MapToApiVersion(&quot;2.0&quot;)] public ActionResult&lt;string&gt; Get(int id) { return &quot;value&quot;; }} You can use UnavailableApiVersionsAttribute on any controller or action method. Global registration Also, You are able to register the UnavailableApiVersionsAttribute filter globally. 123456789// Startup.ConfigureServicespublic void ConfigureServices(IServiceCollection services){ services.AddControllers(options =&gt; { // HERE options.Filters.Add(new UnavailableApiVersionsAttribute(&quot;1.0,1.1&quot;) { IsADeprecatedVersionValid = false }); });} Swagger integrationInstall the below packages 123Install-Package Microsoft.AspNetCore.Mvc.Versioning.ApiExplorer -Version 4.1.1dotnet add package Microsoft.AspNetCore.Mvc.Versioning.ApiExplorer --version 4.1.1&lt;PackageReference Include=&quot;Microsoft.AspNetCore.Mvc.Versioning.ApiExplorer&quot; Version=&quot;4.1.1&quot; /&gt; Add ConfigureSwaggerOptions to make some custom options. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152// ConfigureSwaggerOptions.cs/// &lt;summary&gt;/// Configures the Swagger generation options./// &lt;/summary&gt;/// &lt;remarks&gt;/// This allows API versioning to define aSwagger document per API version after the/// &lt;see cref=&quot;IApiVersionDescriptionProvider&quot; /&gt;service has been resolved from the service container./// &lt;/remarks&gt;public sealed class ConfigureSwaggerOptions :IConfigureOptions&lt;SwaggerGenOptions&gt;{ private readonly IApiVersionDescriptionProvider _provider; /// &lt;summary&gt; /// Initializes a new instance of the &lt;see cref=&quot;ConfigureSwaggerOptions&quot; /&gt; class. /// &lt;/summary&gt; /// &lt;param name=&quot;provider&quot;&gt; /// The &lt;see cref=&quot;IApiVersionDescriptionProvider&quot;&gt;provider&lt;/see&gt; used to generate Swagger /// documents. /// &lt;/param&gt; public ConfigureSwaggerOptions(IApiVersionDescriptionProvider provider) =&gt; _provider = provider; /// &lt;inheritdoc /&gt; public void Configure(SwaggerGenOptions options) { // add a swagger document for each discovered API version // note: you might choose to skip or document deprecated API versions differently foreach (ApiVersionDescription description in _provider.ApiVersionDescriptions) { options.SwaggerDoc(description.GroupName, CreateInfoForApiVersion(description)); } } private static OpenApiInfo CreateInfoForApiVersion(ApiVersionDescription description) { var info = new OpenApiInfo { Title = &quot;A Web API&quot;, Version = description.ApiVersion.ToString(), Description = &quot;An API sample.&quot;, Contact = new OpenApiContact { Name = &quot;hamedfathi&quot;, Email = &quot;hamedfathi@outlook.com&quot; }, TermsOfService = new Uri(&quot;https://hamedfathi.me&quot;), License = new OpenApiLicense { Name = &quot;MIT License&quot;, Url = new Uri(&quot;https://opensource.org/licenses/MIT&quot;) } }; if (description.IsDeprecated) { info.Description += &quot; This API version has been deprecated.&quot;; } return info; }} Modify your Startup.cs as following 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566// Startup.ConfigureServicespublic void ConfigureServices(IServiceCollection services){ services.AddControllers(); services.AddTransient&lt;IConfigureOptions&lt;SwaggerGenOptions&gt;, ConfigureSwaggerOptions&gt;(); services.AddSwaggerGen(c =&gt; { var xmlFile = $&quot;{Assembly.GetExecutingAssembly().GetName().Name}.xml&quot;; var xmlPath = Path.Combine(AppContext.BaseDirectory, xmlFile); c.IncludeXmlComments(xmlPath); }); services.AddApiVersioning(config =&gt; { config.DefaultApiVersion = new ApiVersion(1, 0); config.AssumeDefaultVersionWhenUnspecified = true; config.ReportApiVersions = true; config.ApiVersionReader = new UrlSegmentApiVersionReader(); }); services.AddVersionedApiExplorer( options =&gt; { // add the versioned api explorer, which also adds IApiVersionDescriptionProvider service // note: the specified format code will format the version as &quot;'v'major[.minor][-status]&quot; options.GroupNameFormat = &quot;'v'VVV&quot;; // note: this option is only necessary when versioning by url segment. the SubstitutionFormat // can also be used to control the format of the API version in route templates options.SubstituteApiVersionInUrl = true; });}// Startup.Configurepublic void Configure(IApplicationBuilder app, IWebHostEnvironment env, IApiVersionDescriptionProvider provider){ app.UseSwagger(); app.UseSwaggerUI( options =&gt; { foreach (ApiVersionDescription description in provider.ApiVersionDescriptions) { string swaggerEndpoint; string basePath = Configuration[&quot;ASPNETCORE_BASEPATH&quot;]; Console.WriteLine(&quot;PATH: &quot; + basePath); if (!string.IsNullOrEmpty(basePath)) { swaggerEndpoint = $&quot;{basePath}/swagger/{description.GroupName}/swagger.json&quot;; } else { swaggerEndpoint = $&quot;/swagger/{description.GroupName}/swagger.json&quot;; } options.SwaggerEndpoint(swaggerEndpoint, description.GroupName.ToUpperInvariant()); } }); app.UseRouting(); app.UseAuthorization(); app.UseEndpoints(endpoints =&gt; { endpoints.MapControllers(); });} Reference(s)Most of the information in this article has gathered from various references. https://www.infoworld.com/article/3562355/how-to-use-api-versioning-in-aspnet-core.html https://dev.to/99darshan/restful-web-api-versioning-with-asp-net-core-1e8g https://dotnetcoretutorials.com/2017/01/17/api-versioning-asp-net-core/ https://exceptionnotfound.net/overview-of-api-versioning-in-asp-net-core-3-0/ https://github.com/microsoft/aspnet-api-versioning/wiki/API-Version-Reader","link":"/a-professional-asp.net-core-api-versioning/"},{"title":"A Professional ASP.NET Core - File Upload","text":"ASP.NET Core supports uploading one or more files using buffered model binding for smaller files and unbuffered streaming for larger files. File ModelCreate a new class, Models/FileModel.cs. This will be the base class. 12345678910public abstract class FileModel{ public int Id { get; set; } public string Name { get; set; } public string FileType { get; set; } public string Extension { get; set; } public string Description { get; set; } public string UploadedBy { get; set; } public DateTime? CreatedOn { get; set; }} Now, let’s create a model for the file on the file system. Name it Models/FileOnFileSystem.cs and inherit the FileModel class. 1234public class FileOnFileSystemModel : FileModel{ public string FilePath { get; set; }} Similarly add another class for the file on database, Models/FileOnDatabaseModel.cs 1234public class FileOnDatabaseModel : FileModel{ public byte[] Data { get; set; }} Setting up Entity Framework CoreInstall the below packages 123456789101112131415161718192021Install-Package Microsoft.EntityFrameworkCore -Version 3.1.9dotnet add package Microsoft.EntityFrameworkCore --version 3.1.9&lt;PackageReference Include=&quot;Microsoft.EntityFrameworkCore&quot; Version=&quot;3.1.9&quot; /&gt;Install-Package Microsoft.EntityFrameworkCore.Design -Version 3.1.9dotnet add package Microsoft.EntityFrameworkCore.Design --version 3.1.9&lt;PackageReference Include=&quot;Microsoft.EntityFrameworkCore.Design&quot; Version=&quot;3.1.9&quot;&gt; &lt;PrivateAssets&gt;all&lt;/PrivateAssets&gt; &lt;IncludeAssets&gt;runtime; build; native; contentfiles; analyzers&lt;/IncludeAssets&gt;&lt;/PackageReference&gt;Install-Package Microsoft.EntityFrameworkCore.Tools -Version 3.1.9dotnet add package Microsoft.EntityFrameworkCore.Tools --version 3.1.9&lt;PackageReference Include=&quot;Microsoft.EntityFrameworkCore.Tools&quot; Version=&quot;3.1.9&quot;&gt; &lt;PrivateAssets&gt;all&lt;/PrivateAssets&gt; &lt;IncludeAssets&gt;runtime; build; native; contentfiles; analyzers&lt;/IncludeAssets&gt;&lt;/PackageReference&gt;Install-Package Microsoft.EntityFrameworkCore.SqlServer -Version 3.1.9dotnet add package Microsoft.EntityFrameworkCore.SqlServer --version 3.1.9&lt;PackageReference Include=&quot;Microsoft.EntityFrameworkCore.SqlServer&quot; Version=&quot;3.1.9&quot; /&gt; Next, add a connection string to your appsetting.json file. 123&quot;ConnectionStrings&quot;: { &quot;DefaultConnection&quot;: &quot;Server=.;Database=FileDb;Trusted_Connection=True;&quot;} Create ApplicationDbContext 12345678910using Microsoft.EntityFrameworkCore;public class ApplicationDbContext : DbContext{ public ApplicationDbContext(DbContextOptions&lt;ApplicationDbContext&gt; options) : base(options) { } public DbSet&lt;FileOnDatabaseModel&gt; FilesOnDatabase { get; set; } public DbSet&lt;FileOnFileSystemModel&gt; FilesOnFileSystem { get; set; }} Let’s now configure the services. Modify the Startup.cs/ConfigureServices. 123456789101112131415using Microsoft.EntityFrameworkCore;public class Startup{ public void ConfigureServices(IServiceCollection services) { // ... services.AddDbContext&lt;ApplicationDbContext&gt;(options =&gt; options.UseSqlServer( Configuration.GetConnectionString(&quot;DefaultConnection&quot;), b =&gt; b.MigrationsAssembly(typeof(ApplicationDbContext).Assembly.FullName)) ); // ... }} Finally, let’s do the required migrations and update our database. Just run the following commands on the Package Manager Console or other terminals. 1234567Add-Migration initialUpdate-Database// dotnet tool install --global dotnet-ef// dotnet tool update --global dotnet-efdotnet ef migrations add initialdotnet ef database update You will get a done message on console. Open up SQL Server Object Explorer to check if the database and tables have been created. Setting up the View and ViewModelMake a new class, a ViewModel class, Models/FileUploadViewModel.cs as below. 12345public class FileUploadViewModel{ public List&lt;FileOnFileSystemModel&gt; FilesOnFileSystem { get; set; } public List&lt;FileOnDatabaseModel&gt; FilesOnDatabase { get; set; }} After that, Let’s start modifying the View Page, Views/File/Index.cshtml. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596@model FileUploadViewModel@{ ViewData[&quot;Title&quot;] = &quot;Index&quot;; Layout = &quot;~/Views/Shared/_Layout.cshtml&quot;;}&lt;h4&gt;Start Uploading Files Here&lt;/h4&gt;&lt;hr /&gt;@if (ViewBag.Message != null){ &lt;div class=&quot;alert alert-success alert-dismissible&quot; style=&quot;margin-top:20px&quot;&gt; @ViewBag.Message &lt;/div&gt;}&lt;form method=&quot;post&quot; enctype=&quot;multipart/form-data&quot;&gt; &lt;input type=&quot;file&quot; name=&quot;files&quot; multiple required /&gt; &lt;input type=&quot;text&quot; autocomplete=&quot;off&quot; placeholder=&quot;Enter File Description&quot; name=&quot;description&quot; required /&gt; &lt;button type=&quot;submit&quot; class=&quot;btn btn-primary&quot; asp-controller=&quot;File&quot; asp-action=&quot;UploadToFileSystem&quot;&gt;Upload to File System&lt;/button&gt; &lt;button class=&quot;btn btn-success&quot; type=&quot;submit&quot; asp-controller=&quot;File&quot; asp-action=&quot;UploadToDatabase&quot;&gt;Upload to Database&lt;/button&gt;&lt;/form&gt;&lt;hr /&gt;&lt;h4&gt;Files on File System&lt;/h4&gt;@if (Model.FilesOnFileSystem.Count == 0){ &lt;caption&gt;No Records Found&lt;/caption&gt;}else{ &lt;caption&gt;List of Files on File System&lt;/caption&gt; &lt;table class=&quot;table table-striped&quot;&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;#&lt;/th&gt; &lt;th&gt;Name&lt;/th&gt; &lt;th&gt;Description&lt;/th&gt; &lt;th&gt;File Type&lt;/th&gt; &lt;th&gt;Created On&lt;/th&gt; &lt;th&gt;Actions&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; @foreach (var file in Model.FilesOnFileSystem) { &lt;tr&gt; &lt;th&gt;@file.Id&lt;/th&gt; &lt;td&gt;@file.Name&lt;/td&gt; &lt;td&gt;@file.Description&lt;/td&gt; &lt;td&gt;@file.FileType&lt;/td&gt; &lt;td&gt;@file.CreatedOn&lt;/td&gt; &lt;td&gt; &lt;a type=&quot;button&quot; class=&quot;btn btn-primary&quot; asp-controller=&quot;File&quot; asp-action=&quot;DownloadFileFromFileSystem&quot; asp-route-id=&quot;@file.Id&quot;&gt;Download&lt;/a&gt; &lt;a type=&quot;button&quot; class=&quot;btn btn-danger&quot; asp-controller=&quot;File&quot; asp-action=&quot;DeleteFileFromFileSystem&quot; asp-route-id=&quot;@file.Id&quot;&gt;Delete&lt;/a&gt; &lt;/td&gt; &lt;/tr&gt; } &lt;/tbody&gt; &lt;/table&gt;}&lt;hr /&gt;&lt;h4&gt;Files on Database&lt;/h4&gt;@if (Model.FilesOnDatabase.Count == 0){ &lt;caption&gt;No Records Found&lt;/caption&gt;}else{ &lt;caption&gt;List of Files on Database&lt;/caption&gt; &lt;table class=&quot;table table-striped&quot;&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;#&lt;/th&gt; &lt;th&gt;Name&lt;/th&gt; &lt;th&gt;Description&lt;/th&gt; &lt;th&gt;File Type&lt;/th&gt; &lt;th&gt;Created On&lt;/th&gt; &lt;th&gt;Actions&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; @foreach (var file in Model.FilesOnDatabase) { &lt;tr&gt; &lt;th&gt;@file.Id&lt;/th&gt; &lt;td&gt;@file.Name&lt;/td&gt; &lt;td&gt;@file.Description&lt;/td&gt; &lt;td&gt;@file.FileType&lt;/td&gt; &lt;td&gt;@file.CreatedOn&lt;/td&gt; &lt;td&gt; &lt;a type=&quot;button&quot; class=&quot;btn btn-primary&quot; asp-controller=&quot;File&quot; asp-action=&quot;DownloadFileFromDatabase&quot; asp-route-id=&quot;@file.Id&quot;&gt;Download&lt;/a&gt; &lt;a type=&quot;button&quot; class=&quot;btn btn-danger&quot; asp-controller=&quot;File&quot; asp-action=&quot;DeleteFileFromDatabase&quot; asp-route-id=&quot;@file.Id&quot;&gt;Delete&lt;/a&gt; &lt;/td&gt; &lt;/tr&gt; } &lt;/tbody&gt; &lt;/table&gt;} Now, Create FileController 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121// Controllers/FileController.cspublic class FileController : Controller{ private readonly ApplicationDbContext context; public FileController(ApplicationDbContext context) { this.context = context; } public async Task&lt;IActionResult&gt; Index() { var fileuploadViewModel = await LoadAllFiles(); ViewBag.Message = TempData[&quot;Message&quot;]; return View(fileuploadViewModel); } [HttpPost] public async Task&lt;IActionResult&gt; UploadToFileSystem(List&lt;IFormFile&gt; files, string description) { foreach (var file in files) { var basePath = Path.Combine(Directory.GetCurrentDirectory() + &quot;\\\\Files\\\\&quot;); bool basePathExists = System.IO.Directory.Exists(basePath); if (!basePathExists) Directory.CreateDirectory(basePath); var fileName = Path.GetFileNameWithoutExtension(file.FileName); var filePath = Path.Combine(basePath, file.FileName); var extension = Path.GetExtension(file.FileName); if (!System.IO.File.Exists(filePath)) { using (var stream = new FileStream(filePath, FileMode.Create)) { await file.CopyToAsync(stream); } var fileModel = new FileOnFileSystemModel { CreatedOn = DateTime.UtcNow, FileType = file.ContentType, Extension = extension, Name = fileName, Description = description, FilePath = filePath }; await context.FilesOnFileSystem.AddAsync(fileModel); await context.SaveChangesAsync(); } } TempData[&quot;Message&quot;] = &quot;File successfully uploaded to File System.&quot;; return RedirectToAction(&quot;Index&quot;); } [HttpPost] public async Task&lt;IActionResult&gt; UploadToDatabase(List&lt;IFormFile&gt; files, string description) { foreach (var file in files) { var fileName = Path.GetFileNameWithoutExtension(file.FileName); var extension = Path.GetExtension(file.FileName); var fileModel = new FileOnDatabaseModel { CreatedOn = DateTime.UtcNow, FileType = file.ContentType, Extension = extension, Name = fileName, Description = description }; using (var dataStream = new MemoryStream()) { await file.CopyToAsync(dataStream); fileModel.Data = dataStream.ToArray(); } await context.FilesOnDatabase.AddAsync(fileModel); await context.SaveChangesAsync(); } TempData[&quot;Message&quot;] = &quot;File successfully uploaded to Database&quot;; return RedirectToAction(&quot;Index&quot;); } private async Task&lt;FileUploadViewModel&gt; LoadAllFiles() { var viewModel = new FileUploadViewModel(); viewModel.FilesOnDatabase = await context.FilesOnDatabase.ToListAsync(); viewModel.FilesOnFileSystem = await context.FilesOnFileSystem.ToListAsync(); return viewModel; } public async Task&lt;IActionResult&gt; DownloadFileFromDatabase(int id) { var file = await context.FilesOnDatabase.Where(x =&gt; x.Id == id).FirstOrDefaultAsync(); if (file == null) return null; return File(file.Data, file.FileType, file.Name + file.Extension); } public async Task&lt;IActionResult&gt; DownloadFileFromFileSystem(int id) { var file = await context.FilesOnFileSystem.Where(x =&gt; x.Id == id).FirstOrDefaultAsync(); if (file == null) return null; var memory = new MemoryStream(); using (var stream = new FileStream(file.FilePath, FileMode.Open)) { await stream.CopyToAsync(memory); } memory.Position = 0; return File(memory, file.FileType, file.Name + file.Extension); } public async Task&lt;IActionResult&gt; DeleteFileFromFileSystem(int id) { var file = await context.FilesOnFileSystem.Where(x =&gt; x.Id == id).FirstOrDefaultAsync(); if (file == null) return null; if (System.IO.File.Exists(file.FilePath)) { System.IO.File.Delete(file.FilePath); } context.FilesOnFileSystem.Remove(file); await context.SaveChangesAsync(); TempData[&quot;Message&quot;] = $&quot;Removed {file.Name + file.Extension} successfully from File System.&quot;; return RedirectToAction(&quot;Index&quot;); } public async Task&lt;IActionResult&gt; DeleteFileFromDatabase(int id) { var file = await context.FilesOnDatabase.Where(x =&gt; x.Id == id).FirstOrDefaultAsync(); context.FilesOnDatabase.Remove(file); await context.SaveChangesAsync(); TempData[&quot;Message&quot;] = $&quot;Removed {file.Name + file.Extension} successfully from Database.&quot;; return RedirectToAction(&quot;Index&quot;); }} Reference(s)Most of the information in this article has gathered from various references. https://code-maze.com/file-upload-aspnetcore-mvc/ https://khalidabuhakmeh.com/upload-a-file-using-aspdotnet-core https://www.c-sharpcorner.com/article/upload-download-files-in-asp-net-core-2-0 https://gunnarpeipman.com/aspnet-core-file-uploads/ https://www.codewithmukesh.com/blog/file-upload-in-aspnet-core-mvc/","link":"/a-professional-asp.net-core-file-upload/"},{"title":"A Professional ASP.NET Core - Middleware","text":"Middleware is software that’s assembled into an app pipeline to handle requests and responses. Each component: Chooses whether to pass the request to the next component in the pipeline. Can perform work before and after the next component in the pipeline. Request delegates are used to build the request pipeline. The request delegates handle each HTTP request. Request delegates are configured using Run, Map, and Use extension methods. An individual request delegate can be specified in-line as an anonymous method (called in-line middleware), or it can be defined in a reusable class. These reusable classes and in-line anonymous methods are middleware, also called middleware components. Each middleware component in the request pipeline is responsible for invoking the next component in the pipeline or short-circuiting the pipeline. When a middleware short-circuits, it’s called a terminal middleware because it prevents further middleware from processing the request. Create a middleware pipeline with IApplicationBuilderThe ASP.NET Core request pipeline consists of a sequence of request delegates, called one after the other. The following diagram demonstrates the concept. The thread of execution follows the black arrows. Each delegate can perform operations before and after the next delegate. Exception-handling delegates should be called early in the pipeline, so they can catch exceptions that occur in later stages of the pipeline. The simplest possible ASP.NET Core app sets up a single request delegate that handles all requests. This case doesn’t include an actual request pipeline. Instead, a single anonymous function is called in response to every HTTP request. 1234567891011public class Startup{ public void Configure(IApplicationBuilder app) { // HERE app.Run(async context =&gt; { await context.Response.WriteAsync(&quot;Hello, World!&quot;); }); }} Chain multiple request delegates together with Use. The next parameter represents the next delegate in the pipeline. You can short-circuit the pipeline by not calling the next parameter. You can typically perform actions both before and after the next delegate, as the following example demonstrates: 123456789101112131415161718public class Startup{ public void Configure(IApplicationBuilder app) { // HERE app.Use(async (context, next) =&gt; { // Do work that doesn't write to the Response. await next.Invoke(); // Do logging or other work that doesn't write to the Response. }); app.Run(async context =&gt; { await context.Response.WriteAsync(&quot;Hello from 2nd delegate.&quot;); }); }} When a delegate doesn’t pass a request to the next delegate, it’s called short-circuiting the request pipeline. Short-circuiting is often desirable because it avoids unnecessary work. For example, Static File Middleware can act as a terminal middleware by processing a request for a static file and short-circuiting the rest of the pipeline. Middleware added to the pipeline before the middleware that terminates further processing still processes code after their next.Invoke statements. However, see the following warning about attempting to write to a response that has already been sent. Run delegates don’t receive a next parameter. The first Run delegate is always terminal and terminates the pipeline. Run is a convention. Some middleware components may expose Run[Middleware] methods that run at the end of the pipeline: Middleware orderThe following diagram shows the complete request processing pipeline for ASP.NET Core MVC and Razor Pages apps. You can see how, in a typical app, existing middlewares are ordered and where custom middlewares are added. You have full control over how to reorder existing middlewares or inject new custom middlewares as necessary for your scenarios. The Endpoint middleware in the preceding diagram executes the filter pipeline for the corresponding app type—MVC or Razor Pages. Methods at a glanceRequest delegates are configured using various extension methods as following: Run Terminates chain. No other middleware method will run after this. Should be placed at the end of any pipeline. 1234app.Run(async context =&gt;{ await context.Response.WriteAsync(&quot;Hello from &quot; + _environment);}); UseWhen Performs action before and after next delegate if condition is met. 1234567891011121314private static void HandleBranch(IApplicationBuilder app){ app.Run(async context =&gt; { await context.Response.WriteAsync(&quot;Condition is fulfilled&quot;); });}public void ConfigureUseWhen(IApplicationBuilder app){ app.UseWhen(context =&gt; { return context.Request.Query.ContainsKey(&quot;somekey&quot;); }, HandleBranch);} Use Performs action before and after next delegate. 123456app.Use(async (context, next) =&gt;{ //action before next delegate await next.Invoke(); //call next middleware //action after called middleware}); MapWhen Enables branching pipeline. Runs specified middleware if condition is met. 1234567891011121314private static void HandleBranch(IApplicationBuilder app){ app.Run(async context =&gt; { await context.Response.WriteAsync(&quot;Condition is fulfilled&quot;); });}public void ConfigureMapWhen(IApplicationBuilder app){ app.MapWhen(context =&gt; { return context.Request.Query.ContainsKey(&quot;somekey&quot;); }, HandleBranch);} Map Similar to MapWhen. Runs middleware if path requested by user equals path provided in parameter. 12345678910111213private static void HandleMapTest(IApplicationBuilder app){ app.Run(async context =&gt; { await context.Response.WriteAsync(&quot;Map Test Successful&quot;); });}public void ConfigureMapping(IApplicationBuilder app){ app.Map(&quot;/maptest&quot;, HandleMapTest);} Common middlewares (in order)The following is a list of common middlewares in order: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public void Configure(IApplicationBuilder app, IWebHostEnvironment env){ if (env.IsDevelopment()) { // Displays detailed information about request exceptions. app.UseDeveloperExceptionPage(); } else { // Provide a path to the custom error page that will be displayed to the user. app.UseExceptionHandler(&quot;/Home/Error&quot;); // Send HTTP Strict Transport Security Protocol (HSTS) headers to clients. app.UseHsts(); } // Redirect HTTP requests to HTTPS. app.UseHttpsRedirection(); // Enables static file serving for the current request path. app.UseStaticFiles(); // Enables cookie policy capabilities. app.UseCookiePolicy(); // Enables dynamically compressing HTTP Responses. app.UseResponseCompression(); // Matches request to an endpoint. app.UseRouting(); // Set culture information for requests based on information provided by the client. app.UseRequestLocalization(); // Applies a CORS policy to all the app's endpoints with the specified origins. app.UseCors(); // Authentication is concerned with determining 'who' made a request. app.UseAuthentication(); // Authorization is concerned with 'what' a user is allowed to access. app.UseAuthorization(); // Enable session state for the application. app.UseSession(); // Determines when responses are cacheable, stores responses, and serves responses from cache. app.UseResponseCaching(); // Execute the matched endpoint. app.UseEndpoints(endpoints =&gt; { endpoints.MapControllerRoute( name: &quot;default&quot;, pattern: &quot;{controller=Home}/{action=Index}/{id?}&quot;); });} Componentising custom middlewareIn some scenarios you might want to write a custom middleware. Write below classes: 123456789101112131415161718192021222324252627public class CustomMiddleware{ // A function that can process an HTTP request. private readonly RequestDelegate _next; public CustomMiddleware(RequestDelegate next) { _next = next; } public Task Invoke(HttpContext httpContext) { await context.Response.WriteAsync(&quot;------- Before ------ \\n\\r&quot;); // Call the next delegate/middleware in the pipeline. return _next(httpContext); await context.Response.WriteAsync(&quot;\\n\\r------- After ------&quot;); }}public static class CustomMiddlewareExtensions{ public static IApplicationBuilder UseCustomMiddleware(this IApplicationBuilder builder) { return builder.UseMiddleware&lt;CustomMiddleware&gt;(); }} The middleware class must include: A public constructor with a parameter of type RequestDelegate. A public method named Invoke or InvokeAsync. This method must: Return a Task. Accept a first parameter of type HttpContext. Additional parameters for the constructor and Invoke or InvokeAsync are populated by dependency injection (DI). Now, use it as following: 123456789101112131415// Startup.cspublic class Startup{ public void Configure(IApplicationBuilder app) { // HERE app.UseCustomMiddleware(); app.Run(async (context) =&gt; { await context.Response.WriteAsync(&quot;Hello World!&quot;); }); }} Adding custom options to middlewareWriting a custom middleware is great but you will come to a point where it needs to be made configurable. Let’s define a configuration options class which defines some options which the middleware can use. 12345public class CustomMiddlewareOptions{ public bool DisplayBefore { get; set; } = true; public bool DisplayAfter { get; set; } = true;} Write extension methods to get options with Action&lt;CustomMiddlewareOptions&gt; as following: 123456789101112131415public static class CustomMiddlewareWithOptionsExtensions{ public static IServiceCollection AddCustomMiddlewareWithOptions(this IServiceCollection service, Action&lt;CustomMiddlewareOptions&gt; options = default /* HERE */) { options = options ?? (opts =&gt; { }); service.Configure(options); return service; } public static IApplicationBuilder UseCustomMiddlewareWithOptions(this IApplicationBuilder builder) { return builder.UseMiddleware&lt;CustomMiddlewareWithOptions&gt;(); }} The middleware now can be added into the pipeline and be setup using a lambda expression. It can take the Options in through constructor through the DI mechanism. It comes from the IOptions&lt;T&gt; functionality. 12345678910111213141516171819202122232425262728using Microsoft.Extensions.Options;public class CustomMiddlewareWithOptions{ private readonly RequestDelegate _next; private readonly CustomMiddlewareOptions _options; public CustomMiddlewareWithOptions(RequestDelegate next, IOptions&lt;CustomMiddlewareOptions&gt; options /* HERE */) { _next = next; _options = options.Value; } public async Task InvokeAsync(HttpContext context) { if (_options.DisplayBefore) { await context.Response.WriteAsync(&quot;------- Before ------ \\n\\r&quot;); } await _next(context); if (_options.DisplayAfter) { await context.Response.WriteAsync(&quot;\\n\\r------- After ------&quot;); } }} Register and config it as below: 1234567891011121314151617public class Startup{ public void ConfigureServices(IServiceCollection services) { services.AddCustomMiddlewareWithOptions(options =&gt; options.DisplayAfter = false); } public void Configure(IApplicationBuilder app) { app.UseCustomMiddlewareWithOptions(); app.Run(async (context) =&gt; { await context.Response.WriteAsync(&quot;Hello World!&quot;); }); }} Multiple configuration setupThe other option is the multiple configuration setup option where you want to be able to use the same type of middleware more than once in your application pipeline but want to specify configuration per usage. For this option you specify that you require a configuration option instance directly and it’s not hidden behind IOptions&lt;&gt;. 1234567891011121314151617181920212223242526public class CustomMiddlewareWithOptionsMultiUse{ private readonly RequestDelegate _next; private readonly CustomMiddlewareOptions _options; public CustomMiddlewareWithOptionsMultiUse(RequestDelegate next, CustomMiddlewareOptions options) { _next = next; _options = options; } public async Task InvokeAsync(HttpContext context) { if (_options.DisplayBefore) { await context.Response.WriteAsync(&quot;------- Before ------ \\n\\r&quot;); } await _next(context); if (_options.DisplayAfter) { await context.Response.WriteAsync(&quot;\\n\\r------- After ------&quot;); } }} Adding this version into the middleware pipeline is much straight forward however using an extension method makes it cleaner from a consumers point of view. 12345678public static class CustomMiddlewareWithOptionsMultiUseExtensions{ public static IApplicationBuilder UseCustomMiddlewareWithOptionsMultiUse(this IApplicationBuilder builder, CustomMiddlewareOptions options = default) { options = options ?? new CustomMiddlewareOptions(); return builder.UseMiddleware&lt;CustomMiddlewareWithOptionsMultiUse&gt;(options); }} Passing in the options instance into the UseMiddleware method call allows for the DI system inject it into the middleware constructor directly. Using this extension method we can then add in multiple instances into the pipeline with different configuration options specified. 12345678910111213public class Startup{ public void Configure(IApplicationBuilder app, IHostingEnvironment env) { app.UseCustomMiddlewareWithOptionsMultiUse(new CustomMiddlewareOptions { DisplayBefore = true }); app.UseCustomMiddlewareWithOptionsMultiUse(new CustomMiddlewareOptions { DisplayAfter = false }); app.Run(async (context) =&gt; { await context.Response.WriteAsync(&quot;Hello World!&quot;); }); }} Reference(s)Most of the information in this article has gathered from various references. https://docs.microsoft.com/en-us/aspnet/core/fundamentals/middleware https://adamstorr.azurewebsites.net/blog/aspnetcore-exploring-custom-middleware https://docs.microsoft.com/en-us/aspnet/core/fundamentals/middleware/write https://www.devtrends.co.uk/blog/conditional-middleware-based-on-request-in-asp.net-core https://riptutorial.com/asp-net-core/example/20718/run--map--use","link":"/a-professional-asp.net-core-middleware/"},{"title":"A Professional ASP.NET Core - Model Binding","text":"Controllers and Razor pages work with data that comes from HTTP requests. For example, route data may provide a record key, and posted form fields may provide values for the properties of the model. Writing code to retrieve each of these values and convert them from strings to .NET types would be tedious and error-prone. Model binding automates this process. The model binding system: Retrieves data from various sources such as route data, form fields, and query strings. Provides the data to controllers and Razor pages in method parameters and public properties. Converts string data to .NET types. Updates properties of complex types. HTTP RequestHTTP is one of the many protocols (strategies of communication) used to transfer data from one machine to another across the internet. It is the protocol that browsers primarily use to communicate with websites. For instance, when you go to www.wikipedia.org, an HTTP request is created and transmitted to Wikipedia’s servers, which in turn render and transmit an HTTP response back to the browser.The HTTP protocol is a “text-based protocol”, which means that this strategy uses human-readable characters as its means of communication. An HTTP request defines the following: Method (required) — (Example: GET) Host (required) — (Example: www.hamedfathi.me) Path (required) —(Example: /search) HTTP version (required) — (Example: HTTP/2) Headers (optional) — (Example: Content-Type: application/json) Query String (optional) — (Example: ?q=test) Body (optional) — (Example: {“q”: “test”}) Model Binding SourcesBy default, model binding gets data in the form of key-value pairs from the following sources in an HTTP request (in order): Order Approach 1 Form fields 2 The request body (For controllers that have the [ApiController] attribute.) 3 Route data 4 Query string parameters 5 Uploaded files Therefore, model binding engine will try to use any of the above sources that are available in order, unless you refer to a specific source For each target parameter or property, the sources are scanned in the order indicated in the preceding list. There are a few exceptions: Route data and query string values are used only for simple types. Uploaded files are bound only to target types that implement IFormFile or IEnumerable&lt;IFormFile&gt;. If the default source is not sufficient or is not what you want, use one of the following attributes to specify the source: Override binding source Attribute Description [FromQuery] Gets values from the URL query string. [FromRoute] Gets values from route data. [FromForm] Gets values from posted form fields. (via HTTP POST) [FromBody] Gets values from the request body, based on configured formatter (e.g. JSON, XML). Only one action parameter can have this attribute. [FromHeader] Gets values from HTTP headers. [FromServices] Gets values from DI. Override binding behavior Attribute Description [Bind] Specifies which properties of a model should be included in model binding. [BindRequired] Add model state error if binding fails. [BindNever] Ignore the binding of parameter. Supply custom binding Attribute Description [ModelBinder] provide custom model binder. Model Binding for Simple TypesWhen Binding Simple Types the framework convert the values into the types of action method’s arguments. The Simple Types are: Boolean, Byte, SByte, Char, DateTime, DateTimeOffset, Decimal, Double, Enum, Guid, Int16, Int32, Int64, Single, TimeSpan, UInt16, UInt32, UInt64, Uri, Version. Model Binding for Complex TypesWhen the argument of the action method is a complex type like a class object then Model Binding process gets all the public properties of the complex type and performs the binding for each of them. Default Binding ValuesYou may wonder what will happen if ASP.NET Core framework does not find the values of the action method’s argument in any of the three locations – Form data values, Routing variables &amp; Query strings. In that case it will provide the default values based on the type of the action method’s argument. These are: For value types, the value will be default(T) 0 for int, float, decimal, double, byte. 01-01-0001 00:00:00 for DateTime. Nullable simple types are set to null. Nullable types are null. null for string. For complex Types (reference types), model binding creates an instance by using the default constructor, without setting properties. Arrays are set to Array.Empty&lt;T&gt;(), except that byte[] arrays are set to null. Form fieldsA ProductEditModel object, which contains the details of the product that needs to be created or edited. View model 123456789// ProductEditModel.cspublic class ProductEditModel{ public int Id { get; set; } public string Name { get; set; } public decimal Rate { get; set; } public int Rating { get; set; }} A form is created to which contains three form fields. Name, Rate and Rating. There are three ways front of us: Standard HTML 1234567891011121314151617181920@model ProductEditModel@{ Layout = &quot;_Layout&quot;; ViewData[&quot;Title&quot;] = &quot;Index&quot;;}&lt;h2&gt;Product&lt;/h2&gt;&lt;form action=&quot;/Home/Create&quot; method=&quot;post&quot;&gt; &lt;label for=&quot;Name&quot;&gt;Name&lt;/label&gt; &lt;input type=&quot;text&quot; name=&quot;Name&quot; /&gt; &lt;label for=&quot;Rate&quot;&gt;Rate&lt;/label&gt; &lt;input type=&quot;text&quot; name=&quot;Rate&quot; /&gt; &lt;label for=&quot;Rating&quot;&gt;Rating&lt;/label&gt; &lt;input type=&quot;text&quot; name=&quot;Rating&quot; /&gt; &lt;input type=&quot;submit&quot; name=&quot;submit&quot; /&gt;&lt;/form&gt; HTML Helper 123456789101112131415161718192021@model ProductEditModel@{ Layout = &quot;_Layout&quot;; ViewData[&quot;Title&quot;] = &quot;Index&quot;;}&lt;h2&gt;Product&lt;/h2&gt;@using (Html.BeginForm(&quot;Create&quot;, &quot;Home&quot;, FormMethod.Post)){ &lt;label for=&quot;Name&quot;&gt;Name&lt;/label&gt; &lt;input type=&quot;text&quot; name=&quot;Name&quot; /&gt; &lt;label for=&quot;Rate&quot;&gt;Rate&lt;/label&gt; &lt;input type=&quot;text&quot; name=&quot;Rate&quot; /&gt; &lt;label for=&quot;Rating&quot;&gt;Rating&lt;/label&gt; &lt;input type=&quot;text&quot; name=&quot;Rating&quot; /&gt; &lt;input type=&quot;submit&quot; name=&quot;submit&quot; /&gt;} Tag Helper 1234567891011121314151617181920@model ProductEditModel@{ Layout = &quot;_Layout&quot;; ViewData[&quot;Title&quot;] = &quot;Index&quot;;}&lt;h2&gt;Product&lt;/h2&gt;&lt;form asp-controller=&quot;Home&quot; asp-action=&quot;Create&quot; method=&quot;post&quot;&gt; &lt;label for=&quot;Name&quot;&gt;Name&lt;/label&gt; &lt;input type=&quot;text&quot; name=&quot;Name&quot; /&gt; &lt;label for=&quot;Rate&quot;&gt;Rate&lt;/label&gt; &lt;input type=&quot;text&quot; name=&quot;Rate&quot; /&gt; &lt;label for=&quot;Rating&quot;&gt;Rating&lt;/label&gt; &lt;input type=&quot;text&quot; name=&quot;Rating&quot; /&gt; &lt;input type=&quot;submit&quot; name=&quot;submit&quot; /&gt;&lt;/form&gt; Route Tag Helper 1234567891011121314151617181920@model ProductEditModel@{ Layout = &quot;_Layout&quot;; ViewData[&quot;Title&quot;] = &quot;Index&quot;;}&lt;h2&gt;Product&lt;/h2&gt;&lt;form asp-route=&quot;MyCreateRoute&quot; method=&quot;post&quot;&gt; &lt;label for=&quot;Name&quot;&gt;Name&lt;/label&gt; &lt;input type=&quot;text&quot; name=&quot;Name&quot; /&gt; &lt;label for=&quot;Rate&quot;&gt;Rate&lt;/label&gt; &lt;input type=&quot;text&quot; name=&quot;Rate&quot; /&gt; &lt;label for=&quot;Rating&quot;&gt;Rating&lt;/label&gt; &lt;input type=&quot;text&quot; name=&quot;Rating&quot; /&gt; &lt;input type=&quot;submit&quot; name=&quot;submit&quot; /&gt;&lt;/form&gt; If you use above approach, you must set below attribute to your action: 1[Route(&quot;/Home/Create&quot;, Name = &quot;MyCreateRoute&quot;)] Action The Create action method in the HomeController. 1234567891011121314151617[HttpPost]// Just for 'Route Tag Helper' approach// [Route(&quot;/Home/Create&quot;, Name = &quot;MyCreateRoute&quot;)]public IActionResult Create(ProductEditModel model){ string message = &quot;&quot;; if (ModelState.IsValid) { message = &quot;product &quot; + model.Name + &quot; created successfully&quot; ; } else { message = &quot;Failed to create the product. Please try again&quot;; } return Content(message);} Now, When you click on the submit button your form information will be sent to the Create action and binds to the ProductEditModel model based on its public properties and corresponding HTML name tags. Request bodyRequest Body is the part of the HTTP Request where additional content can be sent to the server. You can use Postman to test this approach easily. Request body message Our ProductEditModel model to create: 12345678// POST http://localhost:PORT/Home/Create// Body &gt; raw{ &quot;name&quot;: &quot;hamed&quot;, &quot;rate&quot;: 20.0, &quot;rating&quot;: 100} MVC If you are using a MVC application, you must add [FromBody] on your model. 123456789101112131415[HttpPost]public IActionResult Create([FromBody] ProductEditModel model){ string message = &quot;&quot;; if (ModelState.IsValid) { message = &quot;product &quot; + model.Name + &quot; created successfully&quot;; } else { message = &quot;Failed to create the product. Please try again&quot;; } return Content(message);} API If you are using an API application, you must add [ApiController] on your controller. 12345678910111213141516171819[ApiController]public class HomeController : ControllerBase{ [HttpPost] public IActionResult Create(ProductEditModel model) { string message = &quot;&quot;; if (ModelState.IsValid) { message = &quot;product &quot; + model.Name + &quot; created successfully&quot;; } else { message = &quot;Failed to create the product. Please try again&quot;; } return Content(message); }} Route dataRoute values obtain from URL segments or through default values aftermatching a route. Using optional and default values 1api/{controller}/{action=index}/{id?} api: A literal segment. {controller}: A requierd route parameter. {action=index} An optional route parameter with default value if not provided. {id?}: An optional route parameter. Note: A segment is a small contiguous section of a URL. It’s separated from other URL segments by at least one character, often by the / character. e.g. {id} and {dogsOnly} in below example. Suppose you have the following action method: 12[HttpGet(&quot;{id}/{dogsOnly}&quot;)] // Routepublic ActionResult&lt;Pet&gt; GetById(int id, bool dogsOnly) {} And the app receives a request with this URL: 1http://example.com/api/pets/2/true Model binding goes through the following steps after the routing system selects the action method: Finds the first parameter of GetByID, an integer named id. Looks through the available sources in the HTTP request and finds id = &quot;2&quot; in route data. Converts the string “2” into integer 2. Finds the second parameter of GetByID, an boolean named dogsOnly. Looks through the available sources in the HTTP request and finds dogsOnly = &quot;true&quot; in route data. Converts the string “true” into boolean true. Complex types You are able to write route binding for complex type as following: Create a model binding class 1234567891011public class DetailsQuery{ [Required] public int? ClockNumber { get; set; } [Required] public int? YearFrom { get; set; } [Required] public int? YearTo { get; set; } [FromQuery] // From query string public bool CheckHistoricalFlag { get; set; } = false;} The action is 1234567// http://localhost:PORT/api/employees/10/calendar/1966/2009?checkhistoricalflag=true[HttpGet(&quot;/api/employees/{clockNumber:int}/calendar/{yearFrom:int}/{yearTo:int}&quot;)]public ActionResult Get([FromRoute] DetailsQuery query){ return Ok();} As you can see the binding engine can map each of DetailsQuery properties from URL segments. Constraints You can apply a large number of route constraints to route templates to ensure that route values are convertible to appropriate types. Constraint Example Match examples Description int {count:int} 678, -890, 0 Matches any integer decimal {rate:decimal} 12.3, 88, -5.005 Matches any decimal value Guid {id:guid} 48ac5fbd-fd24-43b5-a742-6aab7fad67f9 Matches any Guid min(value) {age:min(22)} 18, 20, 21 Matches integer values of 22 or greater length(value) {name:length(7)} hamed, fathi, 12345 Matches string values with a length of 7 optional int {count:int?} 456, -222, 0, null Optionally matches any integer optional int max(value) {count:int:max(15)?} 7, -660, 0, null Optionally matches any integer of 15 or less Query stringsURL’s are made up of several parts, like protocol, hostname, path and so on. The query string is the part of the URL that comes after a question-mark character. So, in a URL like this: 1https://www.google.com/search?q=test&amp;oq=hello Everything after the ? character is considered the query string. The query strings are separated by &amp;. In this case, there are two parameters: One called q and one called oq. They have the values “test” and “hello”. These would be relevant to the page displayed by the URL. So, Query string values pass at the end of the URL, not used during routing. Simple type Write an action 123456789// HomeController.cspublic class HomeController : Controller{ public IActionResult QueryS1(float a, string b, bool c) { // ... }} You can send your values to model binding engine via query string as following 1GET: http://localhost:PORT/Home/QueryS1?a=1.1&amp;b=hamed&amp;c=true Complex type Create a view model 123456public class User{ public long Id { get; set; } public string Name { get; set; } public DateTime BirthDate { get; set; }} Pass it to your action 123456789// HomeController.cspublic class HomeController : Controller{ public IActionResult QueryS2(User user) { // ... }} Call it by query strings 1GET: http://localhost:PORT/Home/QueryS2?id=1&amp;name=hamed&amp;birthdate=1980-09-10 Collections Suppose the parameter to be bound is an array named selectedCourses: 1public IActionResult OnPost(int? id, int[] selectedCourses) Query string data can be in one of the following formats: 123456789selectedCourses=1050&amp;selectedCourses=2000 selectedCourses[0]=1050&amp;selectedCourses[1]=2000[0]=1050&amp;[1]=2000selectedCourses[a]=1050&amp;selectedCourses[b]=2000&amp;selectedCourses.index=a&amp;selectedCourses.index=b[a]=1050&amp;[b]=2000&amp;index=a&amp;index=b Dictionaries Suppose the target parameter is a Dictionary&lt;int, string&gt; named selectedCourses: 1public IActionResult OnPost(int? id, Dictionary&lt;int, string&gt; selectedCourses) Query string data can look like one of the following examples: 12345678selectedCourses[1050]=Chemistry&amp;selectedCourses[2000]=Economics[1050]=Chemistry&amp;selectedCourses[2000]=EconomicsselectedCourses[0].Key=1050&amp;selectedCourses[0].Value=Chemistry&amp;selectedCourses[1].Key=2000&amp;selectedCourses[1].Value=Economics[0].Key=1050&amp;[0].Value=Chemistry&amp;[1].Key=2000&amp;[1].Value=Economics Uploaded filesASP.NET Core supports uploading files by exposing the IFormFile interface. You can use this interface as a method parameter to your action method and it will be populated with the details of the file upload: 1public IActionResult UploadFile(IFormFile file) {} You can also use an IEnumerable&lt;IFormFile&gt; if your action method accepts multiple files: 1public IActionResult UploadFiles(IEnumerable&lt;IFormFile&gt; files) {} The IFormFile object exposes several properties and utility methods for reading the contents of the uploaded file: 123456789101112public interface IFormFile{ string ContentType { get; } string ContentDisposition { get; } IHeaderDictionary Headers { get; } long Length { get; } string Name { get; } string FileName { get; } Stream OpenReadStream(); void CopyTo(Stream target); Task CopyToAsync(Stream target, CancellationToken cancellationToken = null);} Now, Create a file input control 12345678910111213&lt;form method=&quot;post&quot; enctype=&quot;multipart/form-data&quot; asp-controller=&quot;FileUpload&quot; asp-action=&quot;Index&quot;&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;div class=&quot;col-md-10&quot;&gt; &lt;p&gt;Upload one or more files using this form:&lt;/p&gt; &lt;input type=&quot;file&quot; name=&quot;files&quot; multiple /&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;div class=&quot;col-md-10&quot;&gt; &lt;input type=&quot;submit&quot; value=&quot;Upload&quot; /&gt; &lt;/div&gt; &lt;/div&gt;&lt;/form&gt; When uploading files using model binding and the IFormFile interface, the action method can accept either a single IFormFile or an IEnumerable&lt;IFormFile&gt; representing multiple files. We can loop through one or more uploaded files, save them to the local file system and then use the files as per our application’s logic: 12345678910111213141516171819202122232425262728public class FileUploadController : Controller{ [HttpPost(&quot;FileUpload&quot;)] public async Task&lt;IActionResult&gt; Index(List&lt;IFormFile&gt; files) { long size = files.Sum(f =&gt; f.Length); var filePaths = new List&lt;string&gt;(); foreach (var formFile in files) { if (formFile.Length &gt; 0) { // full path to file in temp location var filePath = Path.GetTempFileName(); //we are using Temp file name just for the example. Add your own file path. filePaths.Add(filePath); using (var stream = new FileStream(filePath, FileMode.Create)) { await formFile.CopyToAsync(stream); } } } // process uploaded files // Don't rely on or trust the FileName property without validation. return Ok(new { count = files.Count, size, filePaths }); }} A Specific binding sourceBy default the ASP.NET Core model binder will attempt to bind all action method parameters from different binding sources. Occasionally, you may find it necessary to specifically declare which binding source to bind to, but in other cases, these sources won’t be sufficient. The most common scenarios are when you want to bind a method parameter to a request header value, or when the body of a request contains JSON-formatted data that you want to bind to a parameter. In these cases, you can decorate your action method parameters (or binding model class properties) with attributes that say where to bind from, as shown here 123456789101112131415161718192021222324252627// GET: http://localhost:PORT/User/GetUserInfo/hamed?age=32public class UserController{ [Route(&quot;{controller}/{action}/{name}&quot;)] public IActionResult GetUserInfo( // This will be bound from an HTTP header in the request. [FromHeader] string userId, // This will be bound from the route. '{name}' [FromRoute] string name, // This will be bound from the query string. 'age=32' [FromQuery] age, // The list of photos will be bound to the body of the request, typically in JSON format. [FromBody] List&lt;Photo&gt; photos, // This will be bound from the DI container. [FromServices] ILogger&lt;UserController&gt; logger ) { /* method implementation */ }} PrefixConsider the following model 123456public class Instructor{ public int Id { get; set; } public string FirstName { get; set; } public string LastName { get; set; }} Parameter name If the model to be bound is a parameter named instructorToUpdate: 1public IActionResult OnPost(int? id, Instructor instructorToUpdate) Model binding starts by looking through the sources for the key instructorToUpdate.Id. If that isn’t found, it looks for Id without a prefix. Property name If the model to be bound is a property named Instructor of the controller or PageModel class: 12[BindProperty]public Instructor Instructor { get; set; } Model binding starts by looking through the sources for the key Instructor.Id. If that isn’t found, it looks for Id without a prefix. Custom prefix If the model to be bound is a parameter named instructorToUpdate and a Bind attribute specifies Instructor as the prefix: 123// http://localhost:PORT/Home/Query?id=1&amp;instructor.id=2&amp;instructor.firstname=hamed&amp;instructor.lastname=fathipublic IActionResult OnPost(int? id, [Bind(Prefix = &quot;Instructor&quot;)] Instructor instructorToUpdate) TargetsModel binding tries to find values for the following kinds of targets: Parameters of the controller action method that a request is routed to. Parameters of the Razor Pages handler method that a request is routed to. Public properties of a controller or PageModel class, if specified by attributes. [BindProperty] attribute Can be applied to a public property of a controller or PageModel class to cause model binding to target that property: 1234public class EditModel : InstructorsPageModel{ [BindProperty] public Instructor Instructor { get; set; } [BindProperties] attribute Can be applied to a controller or PageModel class to tell model binding to target all public properties of the class: 1234[BindProperties(SupportsGet = true)]public class CreateModel : InstructorsPageModel{ public Instructor Instructor { get; set; } Attributes for complex type targetsSeveral built-in attributes are available for controlling model binding of complex types: [Bind] attribute Can be applied to a class or a method parameter. Specifies which properties of a model should be included in model binding. [Bind] does not affect input formatters. In the following example, only the specified properties of the Instructor model are bound when any handler or action method is called: 12[Bind(&quot;LastName,FirstMidName,HireDate&quot;)]public class Instructor In the following example, only the specified properties of the Instructor model are bound when the OnPost method is called: 12[HttpPost]public IActionResult OnPost([Bind(&quot;LastName,FirstMidName,HireDate&quot;)] Instructor instructor) [BindRequired] attribute Can only be applied to model properties, not to method parameters. Causes model binding to add a model state error if binding cannot occur for a model’s property. Here’s an example: 123456789public class InstructorWithCollection{ public int ID { get; set; } [DataType(DataType.Date)] [DisplayFormat(DataFormatString = &quot;{0:yyyy-MM-dd}&quot;, ApplyFormatInEditMode = true)] [Display(Name = &quot;Hire Date&quot;)] [BindRequired] // HERE public DateTime HireDate { get; set; } [BindNever] attribute Can only be applied to model properties, not to method parameters. Prevents model binding from setting a model’s property. Here’s an example: 1234public class InstructorWithDictionary{ [BindNever] // HERE public int ID { get; set; } Custom Model BindingModel binding allows controller actions to work directly with model types (passed in as method arguments), rather than HTTP requests. Mapping between incoming request data and application models is handled by model binders. Developers can extend the built-in model binding functionality by implementing custom model binders (though typically, you don’t need to write your own provider). [ModelBinder] In this section we’ll implement a custom model binder that: Converts incoming request data into strongly typed key arguments. Uses Entity Framework Core to fetch the associated entity. Passes the associated entity as an argument to the action method. The following sample uses the ModelBinder attribute on the Author model: 12345678910111213141516using CustomModelBindingSample.Binders;using Microsoft.AspNetCore.Mvc;namespace CustomModelBindingSample.Data{ // Applying ModelBinder Attribute on Model [ModelBinder(BinderType = typeof(AuthorEntityBinder))] public class Author { public int Id { get; set; } public string Name { get; set; } public string GitHub { get; set; } public string Twitter { get; set; } public string BlogUrl { get; set; } }} In the preceding code, the ModelBinder attribute specifies the type of IModelBinder that should be used to bind Author action parameters. The following AuthorEntityBinder class binds an Author parameter by fetching the entity from a data source using Entity Framework Core and an authorId: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class AuthorEntityBinder : IModelBinder{ private readonly AuthorContext _context; public AuthorEntityBinder(AuthorContext context) { _context = context; } public Task BindModelAsync(ModelBindingContext bindingContext) { if (bindingContext == null) { throw new ArgumentNullException(nameof(bindingContext)); } var modelName = bindingContext.ModelName; // Try to fetch the value of the argument by name var valueProviderResult = bindingContext.ValueProvider.GetValue(modelName); if (valueProviderResult == ValueProviderResult.None) { return Task.CompletedTask; } bindingContext.ModelState.SetModelValue(modelName, valueProviderResult); var value = valueProviderResult.FirstValue; // Check if the argument value is null or empty if (string.IsNullOrEmpty(value)) { return Task.CompletedTask; } if (!int.TryParse(value, out var id)) { // Non-integer arguments result in model state errors bindingContext.ModelState.TryAddModelError( modelName, &quot;Author Id must be an integer.&quot;); return Task.CompletedTask; } // Model will be null if not found, including for // out of range id values (0, -3, etc.) var model = _context.Authors.Find(id); bindingContext.Result = ModelBindingResult.Success(model); return Task.CompletedTask; }} The following code shows how to use the AuthorEntityBinder in an action method: 12345678910[HttpGet(&quot;get/{authorId}&quot;)]public IActionResult Get(Author author){ if (author == null) { return NotFound(); } return Ok(author);} The ModelBinder attribute can be used to apply the AuthorEntityBinder to parameters that don’t use default conventions: 1234567891011// Applying ModelBinding Attribute on Action method[HttpGet(&quot;{id}&quot;)]public IActionResult GetById([ModelBinder(Name = &quot;id&quot;)] Author author){ if (author == null) { return NotFound(); } return Ok(author);} In this example, since the name of the argument isn’t the default authorId, it’s specified on the parameter using the ModelBinder attribute. Both the controller and action method are simplified compared to looking up the entity in the action method. The logic to fetch the author using Entity Framework Core is moved to the model binder. This can be a considerable simplification when you have several methods that bind to the Author model. You can apply the ModelBinder attribute to individual model properties (such as on a viewmodel) or to action method parameters to specify a certain model binder or model name for just that type or action. Implementing a ModelBinderProvider Instead of applying an attribute, you can implement IModelBinderProvider. This is how the built-in framework binders are implemented. When you specify the type your binder operates on, you specify the type of argument it produces, not the input your binder accepts. The following binder provider works with the AuthorEntityBinder. When it’s added to MVC’s collection of providers, you don’t need to use the ModelBinder attribute on Author or Author-typed parameters. 12345678910111213141516171819202122232425using CustomModelBindingSample.Data;using Microsoft.AspNetCore.Mvc.ModelBinding;using Microsoft.AspNetCore.Mvc.ModelBinding.Binders;using System;namespace CustomModelBindingSample.Binders{ public class AuthorEntityBinderProvider : IModelBinderProvider { public IModelBinder GetBinder(ModelBinderProviderContext context) { if (context == null) { throw new ArgumentNullException(nameof(context)); } if (context.Metadata.ModelType == typeof(Author)) { return new BinderTypeModelBinder(typeof(AuthorEntityBinder)); } return null; } }} To use a custom model binder provider, add it in ConfigureServices: 123456789public void ConfigureServices(IServiceCollection services){ services.AddDbContext&lt;AuthorContext&gt;(options =&gt; options.UseInMemoryDatabase(&quot;Authors&quot;)); services.AddControllers(options =&gt; { options.ModelBinderProviders.Insert(0, new AuthorEntityBinderProvider()); });} When evaluating model binders, the collection of providers is examined in order. The first provider that returns a binder that matches the input model is used. Adding your provider to the end of the collection may thus result in a built-in model binder being called before your custom binder has a chance. In this example, the custom provider is added to the beginning of the collection to ensure it’s always used for Author action arguments. ValidationData can come from many different sources in your web application—you could load it from files, read it from a database, or you could accept values that a user typed into a form in requests. Although you might be inclined to trust that the data already on your server is valid (though this is sometimes a dangerous assumption!), you definitely shouldn’t trust the data sent as part of a request. DataAnnotations Validation attributes, or more precisely DataAnnotations attributes, allow you to specify rules that the properties in your model should conform to. They provide metadata about your model by describing the sort of data the model should contain, as opposed to the data itself. 1234567891011121314151617181920Public class UserBindingModel{ [Required] [StringLength(100)] [Display(Name = &quot;Your name&quot;)] public string FirstName { get; set; } [Required] [StringLength(100)] [Display(Name = &quot;Last name&quot;)] public string LastName { get; set; } [Required] [EmailAddress] public string Email { get; set; } [Phone] [Display(Name = &quot;Phone number&quot;)] public string PhoneNumber { get; set; }} Some of these attributes are: Attribute Description [CreditCard] Validates that a property has a valid credit card format. [EmailAddress] Validates that a property has a valid email address format. [StringLength(max)] Validates that a string has at most the max amount of characters. [MinLength(min)] Validates that a collection has at least the min amount of items. [Phone] Validates that a property has a valid phone number format. [Range(min, max)] Validates that a property has a value between min and max. [RegularExpression(regex)] Validates that a property conforms to the regex regular expression pattern [Url] Validates that a property has a valid URL format [Required] Indicates the property that must be provided [Compare] Allows you to confirm that two properties have the same value (for example, Email and ConfirmEmail) [DataType(enum)] This attribute is used to specify the datatype of the model - CreditCard, Currency, Custom, Date, DateTime, Duration, EmailAddress, Html, ImageUrl, MultilineText, Password, PhoneNumber, PostalCode, Text, Time, Upload, Url Custom DataAnnotations Imagine we want to restrict the address field value of a student to limited number of words. For example we might say 50 words is more than enough for an address field. You might also think that this type of validation (limiting a string to a maximum number of words) 12345678910111213141516171819using System.ComponentModel.DataAnnotations;public class MaxWordAttributes : ValidationAttribute{ private readonly int _maxWords; public MaxWordAttributes(int maxWords) : base(&quot;{0} has to many words.&quot;) { _maxWords = maxWords; } protected override ValidationResult IsValid(object value, ValidationContext validationContext) { if (value == null) return ValidationResult.Success; var textValue = value.ToString(); if (textValue.Split(' ').Length &lt;= _maxWords) return ValidationResult.Success; var errorMessage = FormatErrorMessage((validationContext.DisplayName)); return new ValidationResult(errorMessage); }} And use it 123[DataType(DataType.MultilineText)] [MaxWordAttributes(50, ErrorMessage=&quot;There are too many words in {0}.&quot;)] public string Address { get; set; } Validating on the server Validation of the binding model occurs before the action executes, but note that the action always executes, whether the validation failed or succeeded. It’s the responsibility of the action method to handle the result of the validation The ModelState is a property of a Controller and represents a collection of name and value pairs that were submitted to the server during a POST. It also contains a collection of error messages for each value submitted, this object is a ModelStateDictionary. Despite its name, it doesn’t actually know anything about any model classes, it only has names, values, and errors. ModelState has two purposes: to store the value submitted to the server, and to store the validation errors associated with those values. 123456if (!ModelState.IsValid){ // Do something about it! // Usually return the user to the same page // while showing the errors.} We have the AddUserVM view model: 123456public class AddUserVM{ public string FirstName { get; set; } public string LastName { get; set; } public string EmailAddress { get; set; }} Also, we have the actions: 1234567891011// Controllers/HomeController.cs[HttpPost]public ActionResult Add(AddUserVM model){ if(!ModelState.IsValid) { return View(model); } return RedirectToAction(&quot;Index&quot;);} Custom Validation But what if we needed to perform more complex validation than what is provided by attributes? Say we needed to validate that the first and last names are not identical, and display a particular error message when this happens. We can actually add errors to the model state via the AddModelError method on ModelStateDictionary: 1234567891011121314[HttpPost]public ActionResult Add(AddUserVM model){ if(model.FirstName == model.LastName) { // HERE ModelState.AddModelError(&quot;LastName&quot;, &quot;The last name cannot be the same as the first name.&quot;); } if(!ModelState.IsValid) { return View(model); } return RedirectToAction(&quot;Index&quot;);} Reference(s)Most of the information in this article has gathered from various references. https://docs.microsoft.com/en-us/aspnet/core/mvc/models/model-binding https://docs.microsoft.com/en-us/aspnet/core/mvc/advanced/custom-model-binding https://www.tektutorialshub.com/asp-net-core/asp-net-core-model-binding/ https://wakeupandcode.com/forms-and-fields-in-asp-net-core/ https://www.manning.com/books/asp-net-core-in-action https://code-maze.com/file-upload-aspnetcore-mvc/ https://medium.com/better-programming/the-anatomy-of-an-http-request-728a469ecba9 https://blog.zhaytam.com/2019/04/13/asp-net-core-checking-modelstate-isvalid-is-boring/ https://exceptionnotfound.net/asp-net-mvc-demystified-modelstate https://www.c-sharpcorner.com/article/custom-data-annotation-validation-in-mvc/","link":"/a-professional-asp.net-core-model-binding/"},{"title":"A Professional ASP.NET Core - RSS","text":"RSS feeds provide an excellent mechanism for websites to publish their content for consumption by others. Install the below package 123Install-Package System.ServiceModel.Syndication -Version 4.7.0dotnet add package System.ServiceModel.Syndication --version 4.7.0&lt;PackageReference Include=&quot;System.ServiceModel.Syndication&quot; Version=&quot;4.7.0&quot; /&gt; Create the model1234567public class Post{ public string Title { get; set; } public string UrlSlug { get; set; } public string Description { get; set; } public DateTime CreatedDate { get; set; }} Create the actionCreate the action that will respond to the request for our RSS Feed. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768using System.ServiceModel.Syndication;using System.Xml;using System.IO;using System.Text;// Customize this method with your real data.private IEnumerable&lt;Post&gt; GetBlogPosts(){ var posts = new List&lt;Post&gt;(); posts.Add(new Post() { Title = &quot;A Professional ASP.NET Core - RSS&quot;, UrlSlug = &quot;a-professional-asp.net-core-rss&quot;, Description = &quot;RSS feeds provide an excellent mechanism for websites to publish their content for consumption by others.&quot;, CreatedDate = new DateTime(2020, 10, 9) }); posts.Add(new Post() { Title = &quot;A Professional ASP.NET Core API - Caching&quot;, UrlSlug = &quot;a-professional-asp.net-core-api-caching&quot;, Description = &quot;Caching is a technique of storing the frequently accessed/used data so that the future requests for those sets of data can be served much faster to the client..&quot;, CreatedDate = new DateTime(2020, 10, 5) }); posts.Add(new Post() { Title = &quot;Using Tailwind CSS with Aurelia 2 and Webpack&quot;, UrlSlug = &quot;aurelia-2-with-tailwindcss-and-webpack&quot;, Description = &quot;Tailwind CSS is a highly customizable, low-level CSS framework that gives you all of the building blocks you need to build bespoke designs without any annoying opinionated styles you have to fight to override.&quot;, CreatedDate = new DateTime(2020, 7, 23) }); return posts;}// http://localhost:PORT/rss.xml[ResponseCache(Duration = 1200)][HttpGet(&quot;/rss.xml&quot;)]public IActionResult Rss(){ var feed = new SyndicationFeed(&quot;Title&quot;, &quot;Description&quot;, new Uri(&quot;https://hamedfathi.me&quot;), &quot;RSSUrl&quot;, DateTime.Now); feed.Copyright = new TextSyndicationContent($&quot;{DateTime.Now.Year} Hamed Fathi&quot;); var items = new List&lt;SyndicationItem&gt;(); var postings = GetBlogPosts(); foreach (var item in postings) { var postUrl = Url.Action(&quot;Article&quot;, &quot;Blog&quot;, new { id = item.UrlSlug }, HttpContext.Request.Scheme); var title = item.Title; var description = item.Description; items.Add(new SyndicationItem(title, description, new Uri(postUrl), item.UrlSlug, item.CreatedDate)); } feed.Items = items; var settings = new XmlWriterSettings { Encoding = Encoding.UTF8, NewLineHandling = NewLineHandling.Entitize, NewLineOnAttributes = true, Indent = true }; using (var stream = new MemoryStream()) { using (var xmlWriter = XmlWriter.Create(stream, settings)) { var rssFormatter = new Rss20FeedFormatter(feed, false); rssFormatter.WriteTo(xmlWriter); xmlWriter.Flush(); } return File(stream.ToArray(), &quot;application/rss+xml; charset=utf-8&quot;); }} The only important note here is that I am setting a ResponeCache attribute on this method. I strongly recommend this as your RSS Feed generation is often something that will be going to the database etc. and feed-readers are notorious for multiple refreshes etc. By enabling ResponseCaching for your RSS action, you can reduce the load on your server. Fetch RSS feedYou are able to loading and processing the feed. 12345678910using System.ServiceModel.Syndication;using System.Xml;public IEnumerable&lt;SyndicationItem&gt; GetFeedItems(string rssUrl){ var reader = XmlReader.Create(rssUrl); var feed = SyndicationFeed.Load(reader); var posts = feed.Items; return posts;} RSS MiddlewareSnickler.RSSCore was created in order to provide a way to easily generate RSS feeds on the fly via an ASP.NET Core Middleware. Install the below package 123Install-Package Snickler.RSSCore -Version 2.0.0dotnet add package Snickler.RSSCore --version 2.0.0&lt;PackageReference Include=&quot;Snickler.RSSCore&quot; Version=&quot;2.0.0&quot; /&gt; Create an RSS Provider Create a provider class that implements IRSSProvider and returns a list of RSSItem objects via the RetrieveSyndicationItems method. 1234567891011121314151617181920public class SomeRSSProvider: IRSSProvider{ public Task&lt;IList&lt;RSSItem&gt;&gt; RetrieveSyndicationItems() { IList&lt;RSSItem&gt; syndicationList = new List&lt;RSSItem&gt;(); var synd1 = new RSSItem(&quot;Sample Title 1&quot;, &quot;Sample Content 1&quot;) { PermaLink = new Uri(&quot;http://www.sampleaddress.com/sample-content-1&quot;), LinkUri = new Uri(&quot;http://www.sampleaddress.com/sample-content-1&quot;), LastUpdated = DateTime.Now, PublishDate = DateTime.Now, Categories = new List&lt;string&gt; { &quot;.NET&quot; }, Authors = new List&lt;string&gt; { &quot;someuser@sampleaddress.com&quot; } }; syndicationList.Add(synd1); return Task.FromResult(syndicationList); }} RSS Feed Configuration Add your provider to the service registration in ConfigureServices with the AddRSSFeed extension 12345public void ConfigureServices(IServiceCollection services){ services.AddRSSFeed&lt;SomeRSSProvider&gt;(); services.AddMvc();} Set the options for your RSS Feed in Configure with UseRSSFeed 123456789101112public void Configure(IApplicationBuilder app, IHostingEnvironment env){ app.UseRssFeed(&quot;/feed&quot;, new RSSFeedOptions { Title = &quot;Snickler's Super Awesome RSS Feed&quot;, Copyright = &quot;2018&quot;, Description = &quot;The Best and Most Awesome RSS Feed Content&quot;, ManagingEditor = &quot;managingeditor@someaddress.com&quot;, Webmaster = &quot;webmaster@someaddress.com&quot;, Url = new Uri(&quot;http://someaddress.com&quot;) });} Optional RSS Caching Configuration By default, MemoryCache is used to cache the feed for 1 day. To be able to update the cache duration or cache key, add a new instance of the MemoryCacheProvider to the Caching property within the RSSFeedOptions class. 1234567891011121314app.UseRssFeed(&quot;/feed&quot;, new RSSFeedOptions{ Title = &quot;Snickler's Super Awesome RSS Feed&quot;, Copyright = &quot;2018&quot;, Description = &quot;The Best and Most Awesome RSS Feed Content&quot;, ManagingEditor = &quot;managingeditor@someaddress.com&quot;, Webmaster = &quot;webmaster@someaddress.com&quot;, Url = new Uri(&quot;http://someaddress.com&quot;), Caching = new MemoryCacheProvider { CacheDuration = TimeSpan.FromDays(5), CacheKey = &quot;SomeSuperAwesomeCacheKey&quot; }}); Reference(s)Most of the information in this article has gathered from various references. https://mitchelsellers.com/blog/article/creating-an-rss-feed-in-asp-net-core-3-0 https://khalidabuhakmeh.com/reading-rss-feeds-with-dotnet-core http://www.binaryintellect.net/articles/05fc3052-bf5c-4ab9-b8ab-a7fd6974b977.aspx https://github.com/snickler/RSSCore","link":"/a-professional-asp.net-core-rss/"},{"title":"Using Tailwind CSS with Aurelia 2 and Webpack","text":"What is Tailwind CSS?Tailwind CSS is a highly customizable, low-level CSS framework that gives you all of the building blocks you need to build bespoke designs without any annoying opinionated styles you have to fight to override. for more information take a look at Tailwind CSS How to configure an Aurelia 2 project with Tailwind CSS?1- Run the following command in your terminal 1npx makes aurelia 2- Use your type of project, I am using Default Typescript with Webpack and CSS. 3- Install Tailwind CSS in your project via this command 123npm i tailwindcss -Doryarn add tailwindcss -D 4- After installation go to the root folder and run the below command too 1./node_modules/.bin/tailwind init This command will create a tailwind.config.js file in the root folder beside the webpack.config.js file with the following content 12345678module.exports = { purge: [], theme: { extend: {}, }, variants: {}, plugins: [],} 5- Open your webpack.config.js file and add the below line into the postcssLoader literal object as a first item in plugins array. (Just like the picture) 1require('tailwindcss')('tailwind.config.js'), 6- Add these lines to the top of your main CSS file (for example my-app.css) 123@tailwind base;@tailwind components;@tailwind utilities; How to test it?In an easy way you can add the following Tailwind CSS snippet code to your project. 123456789&lt;div class=&quot;p-6&quot;&gt; &lt;div class=&quot;bg-red-100 border border-red-400 text-red-700 px-4 py-3 rounded relative&quot; role=&quot;alert&quot;&gt; &lt;strong class=&quot;font-bold&quot;&gt;Holy smokes!&lt;/strong&gt; &lt;span class=&quot;block sm:inline&quot;&gt;Something seriously bad happened.&lt;/span&gt; &lt;span class=&quot;absolute top-0 bottom-0 right-0 px-4 py-3&quot;&gt; &lt;svg class=&quot;fill-current h-6 w-6 text-red-500&quot; role=&quot;button&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot; viewBox=&quot;0 0 20 20&quot;&gt;&lt;title&gt;Close&lt;/title&gt;&lt;path d=&quot;M14.348 14.849a1.2 1.2 0 0 1-1.697 0L10 11.819l-2.651 3.029a1.2 1.2 0 1 1-1.697-1.697l2.758-3.15-2.759-3.152a1.2 1.2 0 1 1 1.697-1.697L10 8.183l2.651-3.031a1.2 1.2 0 1 1 1.697 1.697l-2.758 3.152 2.758 3.15a1.2 1.2 0 0 1 0 1.698z&quot;/&gt;&lt;/svg&gt; &lt;/span&gt; &lt;/div&gt;&lt;/div&gt; I have added this to my-app.html now you can run the project by 123npm run startoryarn run Seems everything works What is PurgeCSS?Purgecss is a tool to remove unused CSS. It can be used as part of your development workflow. Purgecss comes with a JavaScript API, a CLI, and plugins for popular build tools. Why do we need PurgeCSS with Tailwind CSS?Purgecss is particularly effective with Tailwind because Tailwind generates thousands of utility classes for you, most of which you probably won’t actually use. For more information, you can read Controlling File Size. If you run the build command, you will see the final bundle side is huge (even in production mode) 123npm run buildoryarn build How can we enable PurgeCSS?Open the tailwind.config.js file and replace 1purge: [], with 1234purge: { enabled: true, content: ['./src/**/*.html'],}, Now, execute the build command again and see the result. Congrats!","link":"/aurelia-2-with-tailwindcss-and-webpack/"},{"title":"Awesome .NET!","text":"A collection of awesome .NET libraries, tools, frameworks, and software that I suggest you try! Logging Simple .NET logging with fully-structured events. Serilog Serilog.Extensions.Logging Serilog.Exceptions Serilog.Sinks.RollingFile Serilog.Sinks.File Serilog.Sinks.Console Serilog.Sinks.ColoredConsole Serilog.Sinks.LiteDB Inversion of Control (IoC) Grace is a feature rich dependency injection container library Grace Grace.AspNetCore.Hosting Grace.AspNetCore.MVC Grace.Dynamic Grace.Factory DryIoc is fast, small, full-featured IoC Container for .NET DryIoc DryIoc.Microsoft.DependencyInjection Serialization Popular high-performance JSON framework for .NET Newtonsoft.Json JSON Schema draft v4 reader, generator and validator for .NET. NJsonSchema NJsonSchema.CodeGeneration NJsonSchema.CodeGeneration.CSharp NJsonSchema.CodeGeneration.TypeScript Classes to serialize, deserialize and validate OData JSON payloads. Supports OData v4 only. Enables construction of OData services and clients. Microsoft.OData.Core Microsoft.AspNetCore.OData A library for reading and writing CSV files. Extremely fast, flexible, and easy to use. Supports reading and writing of custom class objects. CsvHelper protobuf-net is a contract based serializer for .NET code, that happens to write data in the “protocol buffers” serialization format engineered by Google. The API, however, is very different to Google’s, and follows typical .NET patterns (it is broadly comparable, in usage, to XmlSerializer, DataContractSerializer, etc). It should work for most .NET languages that write standard types and can use attributes. protobuf-net Extended Xml Serializer for .NET ExtendedXmlSerializer ExtendedXmlSerializer.AspCore ExtendedXmlSerializer.Autofac A YAML portable .NET library. providing parsing and serialization of object graphs, compatible with CoreCLR. SharpYaml Fastest C# Serializer and Infinitely Fast Deserializer for .NET, .NET Core and Unity. ZeroFormatter Definitely Fastest and Zero Allocation JSON Serializer for C#(NET, .NET Core, Unity, Xamarin). Utf8Json Utf8Json.ImmutableCollection Utf8Json.AspNetCoreMvcFormatter Test-driven development (TDD) - Behavior-driven development (BDD) xUnit.net is a developer testing framework, built to support Test Driven Development, with a design goal of extreme simplicity and alignment with framework features. xunit NSubstitute is a friendly substitute for .NET mocking frameworks. It has a simple, succinct syntax to help developers write clearer tests. NSubstitute is designed for Arrange-Act-Assert (AAA) testing and with Test Driven Development (TDD) in mind. NSubstitute Moq is the most popular and friendly mocking framework for .NET Moq A BDD style testing framework, heavily relying on (auto mocking) containers. Chill xBehave.net is xUnit.net extension for describing your tests using natural language. Ideally suited to a variety of testing styles (e.g. BDD, TDD, ATDD, etc.), xBehave.net can be used for acceptance tests, integration tests, unit tests or any other ad-hoc testing scenarios. xBehave LightBDD is a behaviour-driven development test framework offering ability to write tests that are easy to read, easy to track during execution and summarize in user friendly report, while allowing developers to use all of the standard development tools to maintain them. LightBDD.XUnit2 Fluent Assertions is a set of .NET extension methods that allow you to more naturally specify the expected outcome of a TDD or BDD-style test. We currently use it in all our internal and client projects, and it is used in many open-source projects. It runs on .NET 4.0, 4.5, 4.6, CoreClr, .NET Native, Windows 8.1, Silverlight 5, Windows Phone 8.0… FluentAssertions FluentAssertions.Json FluentAssertions.Autofac The Tynamix ObjectFiller.NET fills the properties of your objects with random data. Use it for unittest, prototyping and whereever you need some random testdata. It has a fluent API and is highly customizable. It supports also IEnumerables and Dictionaries and constructors WITH parameters. It is also possible to fill instances and to write private properties. ObjectFiller A simple and sane data generator for populating objects that supports different locales. A delightful port of the famed faker.js and inspired by FluentValidation. Use it to create and load databases and UIs with mock up data. Get started by using Faker class or a DataSet directly. Bogus Easy integration testing helper for ASP.Net Core applications. Alba Coverlet is a cross platform code coverage library for .NET Core, with support for line, branch and method coverage. Coverlet Message Brokers RawRabbit is a modern .NET client for communication over RabbitMq. It is written for .NET Core and uses Microsoft’s new frameworks for logging, configuration and dependecy injection. RawRabbit RawRabbit.Extensions RawRabbit.Attributes RawRabbit.DependencyInjection.Autofac RawRabbit.Logging.Serilog RawRabbit.Operations.StateMachine RawRabbit.Enrichers.Polly An easy to use .NET API for RabbitMQ EasyNetQ EasyNetQ.Management.Client Rebus is a lean service bus implementation for .NET. Rebus Rebus.RabbitMQ Rebus.Serilog Rebus.SqlServer Rebus.PostgreSql Rebus.MongoDb Rebus.Async Object-relational mapping (ORM) A high performance Micro-ORM supporting SQL Server, MySQL, Sqlite, SqlCE, Firebird etc.. Dapper Moq.Dapper Entity Framework Core is a lightweight and extensible version of the popular Entity Framework data access technology. Microsoft.EntityFrameworkCore Microsoft.EntityFrameworkCore.Design Microsoft.EntityFrameworkCore.Relational Microsoft.EntityFrameworkCore.Relational.Design Microsoft.EntityFrameworkCore.InMemory Microsoft.EntityFrameworkCore.Tools Microsoft.EntityFrameworkCore.Tools.DotNet Microsoft.EntityFrameworkCore.Specification.Tests Microsoft.EntityFrameworkCore.Relational.Specification.Tests Microsoft.EntityFrameworkCore.Relational.Design.Specification.Tests EFSecondLevelCache.Core EntityFrameworkCore.Triggers EntityFrameworkCore.Rx Woodman.EntityFrameworkCore.Bulk Microsoft.EntityFrameworkCore.AutoHistory EfCore.InMemoryHelpers EntityFrameworkCore.PrimaryKey EntityFrameworkCore.TypedOriginalValues Microsoft SQL Server is a relational database management system developed by Microsoft. As a database server, it is a software product with the primary function of storing and retrieving data as requested by other software applications. Microsoft.EntityFrameworkCore.SqlServer Microsoft.EntityFrameworkCore.SqlServer.Design SQLite is a self-contained, high-reliability, embedded, full-featured, public-domain, SQL database engine. SQLite is the most used database engine in the world. Microsoft.Data.Sqlite Microsoft.EntityFrameworkCore.Sqlite Microsoft.EntityFrameworkCore.Sqlite.Design PostgreSQL, often simply Postgres, is an object-relational database management system (ORDBMS) with an emphasis on extensibility and standards compliance. As a database server, its primary functions are to store data securely and return that data in response to requests from other software applications. Npgsql Npgsql.EntityFrameworkCore.PostgreSQL Npgsql.EntityFrameworkCore.PostgreSQL.Design Library to create and use COMB (timestamped sequential) GUID variants for Microsoft SQL Server and PostgreSQL. RT.Comb Aspect-oriented programming (AOP) Cecil is a library written by Jb Evain to generate and inspect programs and libraries in the ECMA CIL format. It has full support for generics, and support some debugging symbol format. In simple English, with Cecil, you can load existing managed assemblies, browse all the contained types, modify them on the fly and save back to the disk the modified assembly. Mono.Cecil Castle Core provides common Castle Project abstractions including logging services. It also features Castle DynamicProxy a lightweight runtime proxy generator, and Castle DictionaryAdapter. Castle.Core Extensible tool for weaving .net assemblies Fody Validation A validation library for .NET that uses a fluent interface to construct strongly-typed validation rules. FluentValidation FluentValidation.AspNetCore Distributed Systems Build powerful concurrent &amp; distributed applications more easily. Akka Akka.Logger.Serilog Akka.DI.AutoFac Akka.TestKit.Xunit2 Akka.Persistence.SqlServer Orleans is a framework that provides a straight-forward approach to building distributed high-scale computing applications, without the need to learn and apply complex concurrency or other scaling patterns. Microsoft.Orleans.Core Microsoft.Orleans.Client Microsoft.Orleans.Server Scheduling Quartz Scheduling Framework for .NET Quartz.NET NoSQL Embedded .NET NoSQL Document Store in a single data file LiteDB High performance Redis client, incorporating both synchronous and asynchronous usage. StackExchange.Redis Official .NET driver for MongoDB. MongoDB.Driver Postgresql as a Document Database and Event Store for .Net Applications. Marten A C#/.NET RethinkDB database driver with 100% ReQL API coverage. Architecturally, this driver is a port of the official Java driver. RethinkDb.Driver Object Mapper A convention-based object-object mapper. AutoMapper uses a fluent configuration API to define an object-object mapping strategy. AutoMapper uses a convention-based matching algorithm to match up source to destination values. Currently, AutoMapper is designed for model projection scenarios to flatten complex object models to DTOs and other simple objects, whose design is better suited for serialization, communication, messaging, or simply an anti-corruption layer between the domain and application layer. AutoMapper AutoMapper.Data AutoMapper.Extensions.Microsoft.DependencyInjection Html Manipulation This is an agile HTML parser that builds a read/write DOM and supports plain XPATH or XSLT (you actually don’t HAVE to understand XPATH nor XSLT to use it, don’t worry…). It is a .NET code library that allows you to parse “out of the web” HTML files. The parser is very tolerant with “real world” malformed HTML. The object model is very similar to what proposes System.Xml, but for HTML documents (or streams). HtmlAgilityPack Caching CacheManager is an open source caching abstraction layer for .NET written in C#. It supports various cache providers and implements many advanced features. The main goal of the CacheManager package is to make developer’s life easier to handle even very complex caching scenarios.With CacheManager it is possible to implement multiple layers of caching, e.g. in-process caching in front of a distributed cache, in just a few lines of code. CacheManager is not just an interface to unify the programming model for various cache providers, which will make it very easy to change the caching strategy later on in a project. It also offers additional features, like cache synchronization, concurrent updates, serialization, events, performance counters… The developer can opt-in to those features only if needed. CacheManager.Core CacheManager.Microsoft.Extensions.Logging CacheManager.Microsoft.Extensions.Configuration CacheManager.Microsoft.Extensions.Caching.Memory CacheManager.SystemRuntimeCaching CacheManager.Serialization.Json CacheManager.StackExchange.Redis CacheManager.Serialization.ProtoBuf Lazy cache is a simple,thread safe in-memory caching service LazyCache Lexer/Parser Frameworks Tiny C# Monadic Parser Framework Sprache A parser combinator library for C# Superpower ANTLR (ANother Tool for Language Recognition) is a powerful parser generator for reading, processing, executing, or translating structured text or binary files. Antlr4.Runtime.Standard Command Line Parsers The ultimate command line application framework PowerArgs Bot Framework Microsoft Bot Builder is a powerful framework for constructing bots that can handle both freeform interactions and more guided ones where the possibilities are explicitly shown to the user. It is easy to use and leverages C# to provide a natural way to write bots. Microsoft.Bot.Builder Microsoft.Bot.Builder.Integration.AspNet.Core Bot Framework Emulator Build Systems The Microsoft Build Engine (MSBuild) is the build platform for .NET and Visual Studio. Microsoft.Build Microsoft.Build.Runtime Microsoft.Build.Engine Microsoft.Build.Utilities.Core Microsoft.Build.Tasks.Core Microsoft.Build.Conversion.Core Microsoft.Build.Localization NuGet is a free and open-source package manager designed for the Microsoft development platform. NuGet.Frameworks A cross-platform build automation system with C# DSL. Nuke.Core Cake (C# Make) is a cross platform build automation system with a C# DSL to do things like compiling code, copy files/folders, running unit tests, compress files and build NuGet packages. Cake Report Engines PdfReport.Core is a code first reporting engine, which is built on top of the iTextSharp.LGPLv2.Core and EPPlus.Core libraries. PdfRpt.Core Cryptography The Bouncy Castle Crypto package is a C# implementation of cryptographic algorithms and protocols, it was developed by the Legion of the Bouncy Castle, a registered Australian Charity, with a little help! The Legion, and the latest goings on with this package, can be found at http://www.bouncycastle.org. In addition to providing basic cryptography algorithms, the package also provides support for CMS, TSP, X.509 certificate generation and a variety of other standards such as OpenPGP. Portable.BouncyCastle FNV-1a hash algorithm in C# Aesop.Fnv1a bcrypt is a password hashing function designed by Niels Provos and David Mazières, based on the Blowfish cipher, and presented at USENIX in 1999.[1] Besides incorporating a salt to protect against rainbow table attacks, bcrypt is an adaptive function: over time, the iteration count can be increased to make it slower, so it remains resistant to brute-force search attacks even with increasing computation power. BCrypt.Net-Core Rijndael256 makes encrypting data and files a breeze with the AES symmetric-key cipher Rijndael. Rijndael256.Core Fast version of Crc32 &amp; Crc32C algorithms for .NET and .NET Core. It is up to 3x-5x times better than other “fast” implemenations. Code based on Crc32C.NET library. Crc32.NET Jwt.Net, a JWT (JSON Web Token) implementation for .NET JWT Managed .NET wrapper for unmanaged PKCS#11 libraries Pkcs11Interop Benchmarks BenchmarkDotNet is a powerful .NET library for benchmarking. Benchmarking is really hard (especially microbenchmarking), you can easily make a mistake during performance measurements. BenchmarkDotNet will protect you from the common pitfalls (even for experienced developers) because it does all the dirty work for you: it generates an isolated project per each benchmark method, does several launches of this project, run multiple iterations of the method (include warm-up), and so on. Usually, you even shouldn’t care about a number of iterations because BenchmarkDotNet chooses it automatically to achieve the requested level of precision. BenchmarkDotNet App Metrics is an open-source .NET Standard library used to record application metrics. App.Metrics Template Engines DotLiquid is a templating system ported to the .NET framework from Ruby’s Liquid Markup. DotLiquid A fast, powerful, safe and lightweight text templating language and engine for .NET Scriban A fast, powerful, CommonMark compliant, extensible Markdown processor for .NET Markdig.NET Reactive Extensions (Rx) In computing, reactive programming is an asynchronous programming paradigm concerned with data streams and the propagation of change. This means that it becomes possible to express static (e.g. arrays) or dynamic (e.g. event emitters) data streams with ease via the employed programming language(s), and that an inferred dependency within the associated execution model exists, which facilitates the automatic propagation of the change involved with data flow. System.Reactive System.Reactive.Linq System.Interactive Reactive collections based on Rx.Net DynamicData Command Query Responsibility Segregation (CQRS) Simple, unambitious mediator implementation in .NET. MediatR MediatR.Extensions.Microsoft.DependencyInjection Docker Docker is an open platform for developers and sysadmins to build, ship, and run distributed applications, whether on laptops, data center VMs, or the cloud. Docker.DotNet Docker.DotNet.BasicAuth Docker.DotNet.X509 Exception Handling Polly is a .NET 4.5 / .NET Standard 1.1 library that allows developers to express resilience and transient fault handling policies such as Retry, Circuit Breaker, Timeout, Bulkhead Isolation and Fallback in a fluent and thread-safe manner. Polly Workflow Engines Create state machines and lightweight state machine-based workflows directly in .NET code Stateless Reflection/Expression In .NET reflection is slow… well, kinda slow. If you need access to the members of an arbitrary type, with the type and member-names known only at runtime - then it is frankly hard (especially for DLR types). This library makes such access easy and fast. FastMember Tired of slow .NET Reflection API? This package will let you get rid of this overhead by replacing Reflection calls with much faster delegates. DelegatesFactory Expression tree compilation is used by wide range of tools, e.g. IoC/DI containers, Serializers, OO Mappers. But the performance of compilation with Expression.Compile() is just slow. Moreover, the compiled delegate may be slower than manually created delegate. FastExpressionCompiler DateTime Noda Time is a date and time API acting as an alternative to the built-in DateTime/DateTimeOffset etc types built into the .NET framework. NodaTime NodaTime.Serialization.JsonNet Extensive time period calculations and individual calendar periods. TimePeriodLibrary.NET This project is a merge of several common DateTime operations on the form of extensions to System.DateTime, including natural date difference text (precise and human rounded), holidays and working days calculations on several culture locales. Feedback will be much appreciated. DateTimeExtensions Search Engines Strongly typed interface to Elasticsearch. Fluent and classic object initializer mappings of requests and responses. Uses and exposes Elasticsearch.Net NEST Lucene.Net is a full-text search engine library capable of advanced text analysis, indexing, and searching. It can be used to easily add search capabilities to applications. Lucene.Net Lucene.Net.Queries Object Tracking Generate tracking information about an operation being executed. Audit.NET Audit.NET.SqlServer Audit.NET.Redis Audit.NET.MongoDB Identity Managers ASP.NET Core Identity is the membership system for building ASP.NET Core web applications, including membership, login, and user data. ASP.NET Core Identity allows you to add login features to your application and makes it easy to customize data about the logged in user. Microsoft.AspNetCore.Identity Microsoft.AspNetCore.Identity.EntityFrameworkCore Microsoft.AspNetCore.Identity.Service Microsoft.AspNetCore.Identity.Service.EntityFrameworkCore Microsoft.AspNetCore.Identity.Specification.Tests OpenID Connect and OAuth 2.0 Framework for ASP.NET Core IdentityServer4 IdentityServer4.AccessTokenValidation Easy-to-use OpenID Connect server for ASP.NET Core OpenIddict OpenIddict.Mvc OpenIddict.EntityFrameworkCore Email MailKit is an Open Source cross-platform .NET mail-client library that is based on MimeKit and optimized for mobile devices. MailKit A .NET Fake SMTP Server netDumbster Language Integrated Query (LINQ) re-linq Frontend: A foundation for parsing LINQ expression trees and generating queries in SQL or other languages. Remotion.Linq LINQ to Regex library provides language integrated access to the .NET regular expressions. LinqToRegex Dynamic LINQ lets you express queries as text. System.Linq.Dynamic.Core This project enhances LINQ to Objects with extra methods, in a manner which keeps to the spirit of LINQ. morelinq A collection of extension methods to IQueryable and IEnumerable that enable easy searching and ranking. Searches can be performed against multiple properties and support a wide range of types NinjaNye.SearchExtensions MathExtensions is a library for .NET that aims to extend the basic but yet incomplete System.Math, with simple and useful extensions methods regarding various mathematical domains, like methods for combinatorics, sequence analysis, generation and manipulation, random extractions, etc. TommasoScalici.MathExtensions AspNetCore A service API versioning library for Microsoft ASP.NET Core. Microsoft.AspNetCore.Mvc.Versioning Microsoft.AspNetCore.Mvc.Versioning.ApiExplorer The automatic type-safe REST library for Xamarin and .NET Refit SignalR, Incredibly simple real-time web for ASP.NET Core Microsoft.AspNetCore.SignalR Microsoft.AspNetCore.SignalR.Core Microsoft.AspNetCore.SignalR.Client Microsoft.AspNetCore.SignalR.Redis signalr-client Free, open source and cross-platform framework for creating modular and extendable web applications based on ASP.NET Core. ExtCore.Infrastructure ExtCore.WebApplication ExtCore.Data.EntityFramework ExtCore.Data.EntityFramework.SqlServer ExtCore.Data.EntityFramework.Sqlite ExtCore.Data.EntityFramework.PostgreSql Nancy is a lightweight web framework for the .Net platform, inspired by Sinatra. Nancy aim at delivering a low ceremony approach to building light, fast web applications. Nancy Botwin is a library that allows Nancy-esque routing for use with ASP.NET Core. Botwin AspNetCore.Health enables load balancers to monitor the status of deployed Web applications. AspNetCore.Health Warden is an open source library built to solve the problem of monitoring the resources. Warden Warden.Watchers.Process Warden.Watchers.Web Warden.Integrations.HttpApi Warden.Watchers.Server Warden.Watchers.MsSql Warden.Integrations.MsSql Warden.Watchers.Redis Warden.Watchers.MongoDb Warden.Watchers.Disk A lightweight ASP.Net Core library for runtime CSS and JavaScript file management, minification, combination &amp; compression Smidge Smidge.Nuglify A runtime bundler and minifier for ASP.NET Core LigerShark.WebOptimizer.Core AspNetCoreRateLimit is an ASP.NET Core rate limiting solution designed to control the rate of requests that clients can make to a Web API or MVC app based on IP address or client ID. The AspNetCoreRateLimit package contains an IpRateLimitMiddleware and a ClientRateLimitMiddleware, with each middleware you can set multiple limits for different scenarios like allowing an IP or Client to make a maximum number of calls in a time interval like per second, 15 minutes, etc. You can define these limits to address all requests made to an API or you can scope the limits to each API URL or HTTP verb and path. AspNetCoreRateLimit R4MVC is a Roslyn code generator for ASP.NET Core MVC apps that creates strongly typed helpers that eliminate the use of literal strings in many places R4Mvc ASP.NET Core client web browser detection extension to resolve devices, platforms, engine of the client. Wangkanai.Detection Lightweight mini-profiler, designed for ASP.NET Core MVC (not System.Web) websites MiniProfiler.AspNetCore.Mvc SaasKit is a .NET toolkit for building SaaS (Software As A Service) applications.The goal of the project is to help developers build SaaS products without getting in the way. It aims to be platform agnostic and as simple to use as possible. SaasKit.Multitenancy Sieve is a simple, clean, and extensible framework for .NET Core that adds sorting, filtering, and pagination functionality out of the box. Most common use case would be for serving ASP.NET Core GET queries. Sieve JSON Localization Resources My.Extensions.Localization.Json Swagger NSwag: The Swagger API toolchain for .NET and TypeScript NSwag.Core NSwag.Annotations NSwag.Commands NSwag.ConsoleCore NSwag.AssemblyLoaderCore NSwag.AspNetCore NSwag.SwaggerGeneration NSwag.CodeGeneration NSwag.CodeGeneration.CSharp NSwag.CodeGeneration.TypeScript NSwag.SwaggerGeneration.WebApi Swagger tooling for API’s built with ASP.NET Core. Generate beautiful API documentation, including a UI to explore and test operations, directly from your routes, controllers and models. Swashbuckle.AspNetCore .NET models with JSON and YAML writers for OpenAPI specification Microsoft.OpenApi Microsoft.OpenApi.Readers Bot Engine Microsoft Bot Builder is a powerful framework for constructing bots that can handle both freeform interactions and more guided ones where the possibilities are explicitly shown to the user. It is easy to use and leverages C# to provide a natural way to write bots. Microsoft.Bot.Builder Machine Learning ML.NET is a cross-platform open-source machine learning framework which makes machine learning accessible to .NET developers. Microsoft.ML .NET Bindings for TensorFlow TensorFlowSharp Miscellaneous Humanizer meets all your .NET needs for manipulating and displaying strings, enums, dates, times, timespans, numbers and quantities Humanizer (pronounced dyna-mighty) flexes DLR muscle to do meta-mazing things in .net Dynamitey Enums.NET is a high-performance type-safe .NET enum utility library Enums.NET A fluent, portable URL builder. To make HTTP calls off the fluent chain, check out Flurl.Http. Flurl Flurl.Http Flurl.Http.Xml Simple, reliable feature toggles in .NET FeatureToggle A fast globbing library for .NET / .NETStandard applications. Outperforms Regex. DotNet.Glob UnitConversion is designed to be expansible through factories or through concrete converter implementations. UnitConversion Provides easy-to-use and robust fully distributed locks (using SQLServer) as well as wrappers for named system-wide locks (using WaitHandles) DistributedLock What you have been waiting for. Perform a deep compare of any two .NET objects using reflection. Shows the differences between the two objects. CompareNETObjects C# implementation of ua-parser UAParser A library implementing different string similarity and distance measures. StringSimilarity.NET Functional Extensions for C# CSharpFunctionalExtensions A powerful Dynamic Sql Query Builder supporting Sql Server, MySql, PostgreSql and Firebird SqlKata Tiny.RestClient facilitates the dialog between your API and your application. It hides all the complexity of communication, deserialisation … Tiny.RestClient An async-based GitHub API client library for .NET and .NET Core Octokit Crontab for .NET NCrontab Extensions to LINQ to Objects MoreLINQ Utility libraries to interact with discs, filesystem formats and more DiscUtils The client API for Event Store. Get the open source or commercial versions of Event Store server from https://eventstore.org/ EventStore.Client Tools Request/response Inspector middleware for ASP.NET Core. like Glimpse. Rin MiniProfiler ReferenceTrimmer","link":"/awesome-dotnet/"},{"title":"CSS-in-JS in Aurelia 2","text":"What is CSS-in-JS?CSS-in-JS is a styling technique where JavaScript is used to style components. When this JavaScript is parsed, CSS is generated (usually as an &lt;style&gt; element) and attached to the DOM. It allows you to abstract CSS to the component level itself, using JavaScript to describe styles in a declarative and maintainable way.In the ecosystem of some client-side libraries, such as React, this method is very common. So we decided to discuss how to use CSS-in-JS in Aurelia. Why EmotionJS?There are multiple implementations of CSS-in-JS concept in the form of libraries but few of them are framework-agnostic so we chose EmotionJSThis is how they define EmotionJS: Emotion is a performant and flexible CSS-in-JS library. Building on many other CSS-in-JS libraries, it allows you to style apps quickly with string or object styles. It has a predictable composition to avoid specificity issues with CSS. With source maps and labels, Emotion has a great developer experience and great performance with heavy caching in production. EmotionJS &amp; Aurelia 2 integrationTo integrate EmotionJS and Aurelia, Follow the steps below:Add EmotionJS framework-agnostic version to your project with the following command 1npm i emotion --save Define a custom attribute and name it Emotion just like the following code 1234567891011121314151617import { inject } from &quot;aurelia&quot;;import { css, cache } from 'emotion'@inject(Element)export class EmotionCustomAttribute { constructor(private element: Element) { } afterAttach() { if (this.isInShadow(this.element)) cache.sheet.container = this.element.getRootNode() as HTMLElement; else cache.sheet.container = document.head; this.element.classList.add(css(this.value)); } private isInShadow(element: Element): boolean { return element.getRootNode() instanceof ShadowRoot; }} Surely there are questions about the above code let me answer them one by one. What is isInShadow?This method helps us to find out our HTMLElement is inside a shadow-root or not. Why shadow-root matter?Because Aurelia 2 supports ShadowDOM and we need to style those HTMLElements that are inside a shadow via the emotion library. What is cache.sheet.container?The emotion library uses container configuration to inject styles into specific DOM. To support shadow-root we should inject our styles into the shadow block but for global styles document.head is good. Why afterAttach?Detecting ShadowDOM mode for an HTMLElement is possible via this life-cycle method. Now, Register the new Emotion custom attribute in your main.ts file. 1234567import Aurelia from 'aurelia';import { MyApp } from './my-app';import { EmotionCustomAttribute } from './emotion-attr';Aurelia .register(EmotionCustomAttribute) .app(MyApp) .start(); Add an object in your view-model and call it cssObject. 12345678910export class MyApp { public message = 'Hello World!'; private color = 'white' public cssObject = { backgroundColor: 'hotpink !important', '&amp;:hover': { color: this.color } };} Go to your view and add emotion custom attribute to an HTML tag. 1&lt;div class=&quot;message&quot; emotion.bind=&quot;cssObject&quot;&gt;${message}&lt;/div&gt; Congrats. You did this. Run the project and enjoy it.You can find the source code here.","link":"/css-in-js-in-aurelia-2/"},{"title":"The .NET World - C# Source Generator","text":"I want to talk about one of the most exciting new features in C# 9. A way to generate the source code you want and access it instantly in your editor. Stay tuned. What is a source generator?A Source Generator is a new kind of component that C# developers can write that lets you do two major things: Retrieve a Compilation object that represents all user code that is being compiled. This object can be inspected and you can write code that works with the syntax and semantic models for the code being compiled, just like with analyzers today. Generate C# source files that can be added to a Compilation object during the course of compilation. In other words, you can provide additional source code as input to a compilation while the code is being compiled.When combined, these two things are what make Source Generators so useful. You can inspect user code with all of the rich metadata that the compiler builds up during compilation, then emit C# code back into the same compilation that is based on the data you’ve analyzed! If you’re familiar with Roslyn Analyzers, you can think of Source Generators as analyzers that can emit C# source code. Source generators run as a phase of compilation visualized below: A Source Generator is a .NET Standard 2.0 assembly that is loaded by the compiler along with any analyzers. It is usable in environments where .NET Standard components can be loaded and run. What are its prerequisites? C# 9.0+ (SDK 5.0.100+) Microsoft Visual Studio 16.8.0+ or JetBrains Rider 2020.3.0+ What are its limitations? Source Generators do not allow you to rewrite user source code. You can only augment a compilation by adding C# source files to it. Run un-ordered, each generator will see the same input compilation, with no access to files created by other source generators. What is the scenario?The need to mock static methods in order to add a unit test is a very common problem. It’s often the case that these static methods are in third-party libraries. There are many utility libraries that are completely made up of static methods. While this makes them very easy to use, it makes them really difficult to test. The way to mock a static method is by creating a class that wraps the call, extracting an interface, and passing in the interface. Then from your unit tests you can create a mock of the interface and pass it in. In the following, we describe this method and choose Dapper as a real-world example to show you how a wrapper class and interface helps us to test its static (extension) methods. What is Dapper? A simple object mapper for .Net. 123456789public class Student{ public int Id { get; set; } public string Name { get; set; } public string Family { get; set; } public DateTime BirthDate { get; set; }}var student = connection.Query&lt;Student&gt;(&quot;SELECT * FROM STUDENT); Dapper contains a lot of extension (static) methods so I’m going to look at how to mock its methods with the instruction above. Solution structure Make MockableStaticGenerator solution with these projects: Name Template Target MockableStaticGenerator class library netstandard2.0 DapperSample class library netstandard2.0 DapperSampleTest xUnit test project net5.0 MockableStaticGenerator Open MockableStaticGenerator project and add the following configuration to csproj file. 12345678910111213141516171819202122232425&lt;Project Sdk=&quot;Microsoft.NET.Sdk&quot;&gt; &lt;PropertyGroup&gt; &lt;TargetFramework&gt;netstandard2.0&lt;/TargetFramework&gt; &lt;Version&gt;0.0.1&lt;/Version&gt; &lt;PackageId&gt;MockableStaticGenerator&lt;/PackageId&gt; &lt;LangVersion&gt;latest&lt;/LangVersion&gt; &lt;GeneratePackageOnBuild&gt;true&lt;/GeneratePackageOnBuild&gt; &lt;IncludeBuildOutput&gt;false&lt;/IncludeBuildOutput&gt; &lt;EmitCompilerGeneratedFiles&gt;true&lt;/EmitCompilerGeneratedFiles&gt; &lt;CompilerGeneratedFilesOutputPath&gt;$(BaseIntermediateOutputPath)Generated&lt;/CompilerGeneratedFilesOutputPath&gt; &lt;/PropertyGroup&gt; &lt;PropertyGroup&gt; &lt;RestoreAdditionalProjectSources&gt;https://pkgs.dev.azure.com/dnceng/public/_packaging/dotnet5/nuget/v3/index.json ;$(RestoreAdditionalProjectSources)&lt;/RestoreAdditionalProjectSources&gt; &lt;/PropertyGroup&gt; &lt;ItemGroup&gt; &lt;None Include=&quot;$(OutputPath)\\$(AssemblyName).dll&quot; Pack=&quot;true&quot; PackagePath=&quot;analyzers/dotnet/cs&quot; Visible=&quot;false&quot; /&gt; &lt;/ItemGroup&gt; &lt;ItemGroup&gt; &lt;PackageReference Include=&quot;Microsoft.CodeAnalysis.CSharp.Workspaces&quot; Version=&quot;3.8.0&quot; PrivateAssets=&quot;all&quot; /&gt; &lt;PackageReference Include=&quot;Microsoft.CodeAnalysis.Analyzers&quot; Version=&quot;3.3.2&quot;&gt; &lt;PrivateAssets&gt;all&lt;/PrivateAssets&gt; &lt;IncludeAssets&gt;runtime; build; native; contentfiles; analyzers; buildtransitive&lt;/IncludeAssets&gt; &lt;/PackageReference&gt; &lt;/ItemGroup&gt;&lt;/Project&gt; Make sure both below packages are installed. 12345678910Install-Package Microsoft.CodeAnalysis.Analyzers -Version 3.3.2dotnet add package Microsoft.CodeAnalysis.Analyzers --version 3.3.2&lt;PackageReference Include=&quot;Microsoft.CodeAnalysis.Analyzers&quot; Version=&quot;3.3.2&quot;&gt; &lt;PrivateAssets&gt;all&lt;/PrivateAssets&gt; &lt;IncludeAssets&gt;runtime; build; native; contentfiles; analyzers&lt;/IncludeAssets&gt;&lt;/PackageReference&gt;Install-Package Microsoft.CodeAnalysis.CSharp.Workspaces -Version 3.8.0dotnet add package Microsoft.CodeAnalysis.CSharp.Workspaces --version 3.8.0&lt;PackageReference Include=&quot;Microsoft.CodeAnalysis.CSharp.Workspaces&quot; Version=&quot;3.8.0&quot; /&gt; DapperSample Install the below package 123Install-Package Dapper -Version 2.0.78dotnet add package Dapper --version 2.0.78&lt;PackageReference Include=&quot;Dapper&quot; Version=&quot;2.0.78&quot; /&gt; Then, make each below file in the project. 1234567891011121314151617181920212223242526272829303132333435363738// Student.csusing System;public class Student{ public int Id { get; set; } public string Name { get; set; } public string Family { get; set; } public DateTime BirthDate { get; set; }}// IStudentRepository.csusing System.Collections.Generic;public interface IStudentRepository{ IEnumerable&lt;Student&gt; GetStudents();}// StudentRepository.csusing Dapper;using System.Collections.Generic;using System.Data;public class StudentRepository : IStudentRepository{ private readonly IDbConnection _dbConnection; public StudentRepository(IDbConnection dbConnection) { _dbConnection = dbConnection; } public IEnumerable&lt;Student&gt; GetStudents() { return _dbConnection.Query&lt;Student&gt;(&quot;SELECT * FROM STUDENT&quot;); }} DapperSampleTest Install below package 123Install-Package Moq -Version 4.15.2dotnet add package Moq --version 4.15.2&lt;PackageReference Include=&quot;Moq&quot; Version=&quot;4.15.2&quot; /&gt; Then, add DapperSample project reference to this. Now, we are able to test our repository. 123456789101112131415161718192021// StudentRepositoryTest.csusing DapperSample;using Moq;using System.Data;using Xunit;namespace DapperSampleTest{ public class StudentRepositoryTest { [Fact] public void STUDENT_REPOSITORY_TEST() { var mockConn = new Mock&lt;IDbConnection&gt;(); var sut = new StudentRepository(mockConn.Object); var stu = sut.GetStudents(); Assert.NotNull(stu); } }} How is the test run and what happens next? Run the test then you will get a error like below 1234567891011121314DapperSampleTest.StudentRepositoryTest.STUDENT_REPOSITORY_TEST Source: StudentRepositoryTest.cs line 11 Duration: 92 ms Message: System.NullReferenceException : Object reference not set to an instance of an object. Stack Trace: CommandDefinition.SetupCommand(IDbConnection cnn, Action`2 paramReader) line 113 SqlMapper.QueryImpl[T](IDbConnection cnn, CommandDefinition command, Type effectiveType)+MoveNext() line 1080 List`1.ctor(IEnumerable`1 collection) Enumerable.ToList[TSource](IEnumerable`1 source) SqlMapper.Query[T](IDbConnection cnn, String sql, Object param, IDbTransaction transaction, Boolean buffered, Nullable`1 commandTimeout, Nullable`1 commandType) line 725 StudentRepository.GetStudents() line 18 StudentRepositoryTest.STUDENT_REPOSITORY_TEST() line 15 You may have guessed why. Because mock object of IDbConnection has no Query method in his interface. This is the problem. How to fix it? The way to mock a static method is by creating a class that wraps the call, extracting an interface, and passing in the interface. Then from your unit tests you can create a mock of the interface and pass it in. Do this step-by-step changes just like above instruction and add them to DapperSample project. Extracting an interface. 12345678// IDapperSqlMapper.csusing System.Collections.Generic;using System.Data;public interface IDapperSqlMapper{ IEnumerable&lt;T&gt; Query&lt;T&gt;(IDbConnection cnn, string sql, object param = null, IDbTransaction transaction = null, bool buffered = true, int? commandTimeout = null, CommandType? commandType = null);} The Query is the same as what Dapper has. A class that wraps the (static) call. 12345678910111213// DapperSqlMapper.csusing Dapper;using System.Collections.Generic;using System.Data;public class DapperSqlMapper : IDapperSqlMapper{ public IEnumerable&lt;T&gt; Query&lt;T&gt;(IDbConnection cnn, string sql, object param = null, IDbTransaction transaction = null, bool buffered = true, int? commandTimeout = null, CommandType? commandType = null) { // Dapper 'Query' method is here. return cnn.Query&lt;T&gt;(sql, param, transaction, buffered, commandTimeout, commandType); }} Change your StudentRepository class. 1234567891011121314151617181920// StudentRepository.csusing System.Collections.Generic;using System.Data;public class StudentRepository : IStudentRepository{ private readonly IDbConnection _dbConnection; private readonly IDapperSqlMapper _dapperSqlMapper; public StudentRepository(IDbConnection dbConnection, IDapperSqlMapper dapperSqlMapper) { _dbConnection = dbConnection; _dapperSqlMapper = dapperSqlMapper; } public IEnumerable&lt;Student&gt; GetStudents() { return _dapperSqlMapper.Query&lt;Student&gt;(_dbConnection, &quot;SELECT * FROM STUDENT&quot;); }} Now change your test in DapperSampleTest project as following. 1234567891011121314151617181920using DapperSample;using Moq;using System.Data;using Xunit;namespace DapperSampleTest{ public class StudentRepositoryTest { [Fact] public void STUDENT_REPOSITORY_TEST() { var mockConn = new Mock&lt;IDbConnection&gt;(); var mockDapper = new Mock&lt;IDapperSqlMapper&gt;(); var sut = new StudentRepository(mockConn.Object, mockDapper.Object); var stu = sut.GetStudents(); Assert.NotNull(stu); } }} Run the test, you will see the green result! What is the new problem? Everything is good but very tough repetitive work especially when you are using external libraries like Dapper with a lot of extension (static) methods to use. What if this repetitive method was already prepared for all methods? How does a source generator help us solve this problem?So far, we have learned about the problem and how to deal with it. But now we want to use a source generator to reduce the set of these repetitive tasks to zero. What if I have both of the following possibilities? Generate a wrapper class like above sample for Math class in background. 123456789// Internal usage// My class with a lot of static (extension) methods.[MockableStatic]public class Math{ public static int Add(int a, int b) { return a + b; } public static int Sub(int a, int b) { return a - b; }} Generate a wrapper class for Dapper.SqlMapper that exists in Dapper assembly in background. 12345678// External usage// A referenced assembly with a type that contains a lot of static (extension) methods.[MockableStatic(typeof(Dapper.SqlMapper))]public class StudentRepositoryTest{ // ...} If you think it’s a good idea, stay tuned. How to write a source generator?First of all, go to your MockableStaticGenerator project. Add SourceGeneratorExtensions.cs to the project. 12345678// SourceGeneratorExtensions.csnamespace Microsoft.CodeAnalysis{ internal static class SourceGeneratorExtensions { // ... } } For achieving our ultimate goal we need some useful extension methods to make source code so I will add them to SourceGeneratorExtensions class. Now, Create SyntaxReceiver class as following: 1234567891011121314151617181920using Microsoft.CodeAnalysis;using Microsoft.CodeAnalysis.CSharp.Syntax;using System.Collections.Generic;namespace MockableStaticGenerator{ internal class SyntaxReceiver : ISyntaxReceiver { internal List&lt;ClassDeclarationSyntax&gt; Classes { get; } = new List&lt;ClassDeclarationSyntax&gt;(); public void OnVisitSyntaxNode(SyntaxNode syntaxNode) { if (syntaxNode is ClassDeclarationSyntax classDeclarationSyntax &amp;&amp; classDeclarationSyntax.AttributeLists.Count &gt; 0) { Classes.Add(classDeclarationSyntax); } } }} The purpose of this class is to identify the nodes we need to process the current source and generate new code. Here we store all the received classes in the Classes property. Then, Create MockableGenerator class with below code. 123456789101112131415161718using Microsoft.CodeAnalysis;namespace MockableStaticGenerator{ [Generator] public class MockableGenerator : ISourceGenerator { public void Execute(GeneratorExecutionContext context) { } public void Initialize(GeneratorInitializationContext context) { context.RegisterForSyntaxNotifications(() =&gt; new SyntaxReceiver()); } }} As you can see, You should implement ISourceGenerator and add [Generator] attribute to your source generator class. There are two methods: Initialize(GeneratorInitializationContext context) The process of generating code starts with this method, so we get the target classes by registering our SyntaxReceiver. Execute(GeneratorExecutionContext context) You should write how to generate your code in this section and introduce the final output to the compiler. For next step, add Constants class as following to your project. 1234567891011121314151617181920namespace MockableStaticGenerator{ internal static class Constants { internal const string MockableStaticAttribute = @&quot; namespace System { [AttributeUsage(AttributeTargets.Class, Inherited = false, AllowMultiple = false)] public sealed class MockableStaticAttribute : Attribute { public MockableStaticAttribute() { } public MockableStaticAttribute(Type type) { } } }&quot;; }} As I explained before, We need an attribute (MockableStaticAttribute) to annotate our classes. So, we will use above source code text in our source generator. [MockableStatic] useful for internal usage and current class. [MockableStatic(typeof(Dapper.SqlMapper))] useful for external usage and making a wrapper for an external type. Let’s go to the Execute method, Add below code to it 12345678910111213141516171819using Microsoft.CodeAnalysis;using Microsoft.CodeAnalysis.CSharp;using Microsoft.CodeAnalysis.Text;using System.Text;public void Execute(GeneratorExecutionContext context){ // 1 context.AddSource(nameof(Constants.MockableStaticAttribute), SourceText.From(Constants.MockableStaticAttribute, Encoding.UTF8)); // 2 if (!(context.SyntaxReceiver is SyntaxReceiver receiver)) return; // 3 CSharpParseOptions options = (context.Compilation as CSharpCompilation).SyntaxTrees[0].Options as CSharpParseOptions; Compilation compilation = context.Compilation.AddSyntaxTrees(CSharpSyntaxTree.ParseText(SourceText.From(Constants.MockableStaticAttribute, Encoding.UTF8), options)); INamedTypeSymbol attributeSymbol = compilation.GetTypeByMetadataName($&quot;System.{nameof(Constants.MockableStaticAttribute)}&quot;);} (1) we added our MockableStaticAttribute text source to the project. (2) I checked if there is no SyntaxReceiver just return without any generated code. (3) The most important part is finding our MockableStaticAttribute text source from syntax tree and use its information. In summary, You need to add source code text as a part of project then get it from compiler as a Symbol type to work with it in strongly typed way. 1234567891011121314151617181920212223242526// 3// ...// 4var sources = new StringBuilder();// 5var assemblyName = &quot;&quot;;// 6foreach (var cls in receiver.Classes){ // 7 SemanticModel model = compilation.GetSemanticModel(cls.SyntaxTree); var clsSymbol = model.GetDeclaredSymbol(cls); // 8 var attr = clsSymbol.GetAttributes().FirstOrDefault(ad =&gt; ad.AttributeClass.Equals(attributeSymbol, SymbolEqualityComparer.Default)); // 9 if (attr == null) continue; // 10 var isParameterlessCtor = attr?.ConstructorArguments.Length == 0; // 11 var sbInterface = new StringBuilder(); // 12 var sbClass = new StringBuilder(); (4) We need aggregate our sources. (5) We store assembly name. (6) Our SyntaxReceiver classes were stored in receiver variable now we need to use them one-by-one. (7) Access to current class symbol. (8) Check it has the same attribute as we want or not. (9) If not, so go to next item. (10) As I talked before, We are faced with two source generating models. I- Parameterless: It generates a wrapper for the annotated class. 12[MockableStatic]public class Math { } The source generator generates a wrapper for statics methods of Math class. II- With parameter: It gets typeof as a parameter. 12[MockableStatic(typeof(Dapper.SqlMapper))]public class StudentRepository { } The source generator generates a wrapper for statics methods of SqlMapper class inside Dapper assembly. (11) (12) The generated class and interface are stored in these variables. So we continue to work in two parts. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960// 12// ...// 13if (isParameterlessCtor){ // 14 var methods = cls.DescendantNodes().OfType&lt;MethodDeclarationSyntax&gt;().Where(x =&gt; x.IsPublic() &amp;&amp; x.IsStatic()).ToList(); if (methods.Count == 0) continue; // 15 var className = clsSymbol.Name; // 16 var ns = string.IsNullOrEmpty(cls.GetNamespace()) ? &quot;&quot; : cls.GetNamespace() + &quot;.&quot;; // 17 var baseList = string.IsNullOrEmpty(cls.BaseList?.ToFullString()) ? &quot;:&quot; : cls.BaseList?.ToFullString().Trim() + &quot;,&quot;; // 18 assemblyName = clsSymbol.ContainingAssembly.Identity.Name; // 19 var wrapperClassName = !className.Contains('&lt;') ? className + &quot;Wrapper&quot; : className.Replace(&quot;&lt;&quot;, &quot;Wrapper&lt;&quot;); // 20 var classTypeParameters = cls.GetTypeParameters() ?? &quot;&quot;; // 21 var constraintClauses = cls.GetConstraintClauses() ?? &quot;&quot;; // 22 sbInterface.AppendLine($&quot;\\tpublic partial interface I{wrapperClassName}{classTypeParameters} {constraintClauses} {{&quot;); // 23 sbClass.AppendLine($&quot;\\tpublic partial class {wrapperClassName}{classTypeParameters} {baseList} I{wrapperClassName}{classTypeParameters} {constraintClauses} {{&quot;); // 24 foreach (MethodDeclarationSyntax method in methods) { // 25 var text = method.GetSignatureText(); // 26 if (!sbInterface.ToString().Contains(text)) sbInterface.AppendLine($&quot;\\t\\t{text};&quot;); // 27 if (!sbClass.ToString().Contains(text)) { // 28 var returnKeyword = method.ReturnsVoid() ? &quot;&quot; : &quot;return &quot;; // 29 var obsoleteAttrText = &quot;&quot;; var isObsolete = method.TryGetObsoleteAttribute(out obsoleteAttrText); if (isObsolete) sbClass.AppendLine($&quot;\\t\\t{obsoleteAttrText}&quot;); // 30 sbClass.AppendLine($&quot;\\t\\tpublic {method.GetSignatureText()} {{&quot;); sbClass.AppendLine($&quot;\\t\\t\\t{returnKeyword}{ns}{className}{classTypeParameters}.{method.GetCallableSignatureText()};&quot;); sbClass.AppendLine($&quot;\\t\\t}}&quot;); } } // 31 sbInterface.AppendLine($&quot;\\t}}&quot;); sbClass.AppendLine($&quot;\\t}}&quot;);} (13) Our class annotated with parameterless attribute. (14) Find all public static methods of the class. If there no one skip the process. To do this, Add two below extension methods to SourceGeneratorExtensions class. 123456789// SourceGeneratorExtensions.csinternal static bool IsPublic(this MethodDeclarationSyntax methodDeclarationSyntax){ return methodDeclarationSyntax.Modifiers.Select(x =&gt; x.ValueText).Contains(&quot;public&quot;);}internal static bool IsStatic(this MethodDeclarationSyntax methodDeclarationSyntax){ return methodDeclarationSyntax.Modifiers.Select(x =&gt; x.ValueText).Contains(&quot;static&quot;);} (15) Simple class name. (16) The Class name with namespace. To find the namespace we need a recursive extension method as following. 12345678910// SourceGeneratorExtensions.csinternal static string GetNamespace(this SyntaxNode syntaxNode){ return syntaxNode.Parent switch { NamespaceDeclarationSyntax namespaceDeclarationSyntax =&gt; namespaceDeclarationSyntax.Name.ToString(), null =&gt; string.Empty, _ =&gt; GetNamespace(syntaxNode.Parent) };} (17) If it has inherited from a class or implemented interfaces, its information is available here. (18) Assembly name. (19) We append Wrapper to end of the class name. so We will have something like these samples: SqlMapper =&gt; ISqlMapperWrapper and SqlMapperWrapperSqlMapper&lt;T&gt; =&gt; ISqlMapperWrapper and SqlMapperWrapper (20) Your class may have type parameters (generic). Add below method to SourceGeneratorExtensions class. 12345internal static string GetTypeParameters(this ClassDeclarationSyntax classDeclarationSyntax){ var result = classDeclarationSyntax.TypeParameterList?.ToFullString().Trim(); return string.IsNullOrEmpty(result) ? null : result;} Now we can check it there. (21) If your class is generic, Has it any constraint clauses? With the following extension method we can find out. 123456// SourceGeneratorExtensions.csinternal static string GetConstraintClauses(this ClassDeclarationSyntax classDeclarationSyntax){ var result = classDeclarationSyntax.ConstraintClauses.ToFullString().Trim(); return string.IsNullOrEmpty(result) ? null : result;} (22) (23) With current information we are able to create our interface and class for wrapping the main class static methods. (24) Let’s start examining the methods. (25) We should add our methods to interface so we need to know about its signature. So add the following extension method to your SourceGeneratorExtensions class. 12345678910internal static string GetSignatureText(this MethodDeclarationSyntax methodDeclarationSyntax){ var name = methodDeclarationSyntax.Identifier.ValueText; var parameters = methodDeclarationSyntax.ParameterList?.ToFullString().Trim(); var typeParameters = methodDeclarationSyntax.TypeParameterList?.ToFullString().Trim(); var constraintClauses = methodDeclarationSyntax.ConstraintClauses.ToFullString().Replace(System.Environment.NewLine, &quot;&quot;).Trim(); var returnType = methodDeclarationSyntax.ReturnType.ToFullString().Trim(); return $&quot;{returnType} {name}{typeParameters}{parameters} {constraintClauses}&quot;.Trim();} The information it returns includes: Return type. Method name. Type parameter(s), if it is generic. Method parameter(s) (with type and name). Constraint Clauses, if it is generic. (26) We check if there is no same method then we add it to our string builder. (27) Just previous step we check the same condition for adding to our class string builder. (28) The method needs return keyword or it returns nothing (void).To find out we need another extension method. 123456// SourceGeneratorExtensions.csinternal static bool ReturnsVoid(this MethodDeclarationSyntax methodDeclarationSyntax){ return methodDeclarationSyntax.ReturnType.ToFullString().Trim() == &quot;void&quot;;} (29) One of the most important things to consider is whether the method is marked with Obsolete Attribute or not. 123456789101112131415161718192021222324// SourceGeneratorExtensions.csinternal static bool TryGetObsoleteAttribute(this MethodDeclarationSyntax methodDeclarationSyntax, out string text){ var attr = methodDeclarationSyntax.AttributeLists.Where(x =&gt; x is not null &amp;&amp; IsObsolete(x.GetText().ToString())).Select(x =&gt; x.GetText().ToString()).ToList(); text = attr.Count != 0 ? ReplaceFirst(attr[0].Trim(), &quot;Obsolete&quot;, &quot;System.Obsolete&quot;) : &quot;&quot;; return attr.Count != 0; bool IsObsolete(string text) { Match match = Regex.Match(text, @&quot;\\[\\s*Obsolete[Attribute]*\\s*\\(&quot;); return match.Success; } string ReplaceFirst(string text, string search, string replace) { int pos = text.IndexOf(search); if (pos &lt; 0) { return text; } return text.Substring(0, pos) + replace + text.Substring(pos + search.Length); }} If yes, we need to add the same ObsoleteAttribute to top of our new method. (30) We need to know how call the main static method inside of a wrapper method so we should add another extension method. 12345678910111213141516171819202122internal static string GetCallableSignatureText(this MethodDeclarationSyntax methodDeclarationSyntax){ var name = methodDeclarationSyntax.Identifier.ValueText; var parameters = methodDeclarationSyntax.ParameterList.GetParametersText(); var typeParameters = methodDeclarationSyntax.TypeParameterList?.ToFullString().Trim(); return $&quot;{name}{typeParameters}{parameters}&quot;.Trim();}internal static string GetParametersText(this ParameterListSyntax parameterListSyntax){ if (parameterListSyntax == null || parameterListSyntax.Parameters.Count == 0) return &quot;()&quot;; var result = new List&lt;string&gt;(); foreach (var item in parameterListSyntax.Parameters) { var variableName = item.Identifier; var modifiers = item.Modifiers.Select(x =&gt; x.ValueText).ToList(); var modifiersText = modifiers.Count == 0 ? &quot;&quot; : modifiers.Aggregate((a, b) =&gt; a + &quot; &quot; + b); result.Add($&quot;{modifiersText} {variableName}&quot;); } return result.Count == 0 ? &quot;()&quot; : $&quot;({result.Aggregate((a, b) =&gt; a + &quot;, &quot; + b).Trim()})&quot;;} The information it returns includes: Method name. Type parameter(s), if it is generic. Method parameter(s) (with name and without type). Now, We can add the whole wrapper method. (31) At the end, we should complete our interface and class with final }. Part one finished. What happens if we want to generate a wrapper for a type? 123456789101112131415161718// 31// ...// 32else{ // 33 var ctor = ((INamedTypeSymbol)attr?.ConstructorArguments[0].Value); // 34 var assemblySymbol = ctor.ContainingAssembly.GlobalNamespace; // 35 assemblyName = ctor.ContainingAssembly.Identity.Name; // 36 var visitor = new MethodSymbolVisitor(ctor.ToDisplayString()); visitor.Visit(assemblySymbol); // 62 sbInterface.AppendLine(_interfaces.Aggregate((a, b) =&gt; a + Environment.NewLine + b) + Environment.NewLine + &quot;\\t}&quot;); sbClass.AppendLine(_classes.Aggregate((a, b) =&gt; a + Environment.NewLine + b) + Environment.NewLine + &quot;\\t}&quot;);} (32) This part is for constructor with a parameter. (33) Getting the value of the constructor argument. (34) Getting the assembly information of the type introduced. (35) Assembly name. (36) We need a visitor class to know about static methods of the type introduced in the external assembly. We sends the type’s name to the constructor of our visitor because we want to generate wrapper for that type. To write MethodSymbolVisitor add below code to MockableGenerator class as a nested class. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798// 37private static readonly List&lt;string&gt; _interfaces = new List&lt;string&gt;();private static readonly List&lt;string&gt; _classes = new List&lt;string&gt;();// 38public class MethodSymbolVisitor : SymbolVisitor{ private readonly string _typeName; public MethodSymbolVisitor(string typeName) { _typeName = typeName; } // 39 public override void VisitNamespace(INamespaceSymbol symbol) { foreach (var child in symbol.GetMembers()) { child.Accept(this); } } // 40 public override void VisitNamedType(INamedTypeSymbol symbol) { foreach (var child in symbol.GetMembers()) { child.Accept(this); } } // 41 public override void VisitMethod(IMethodSymbol symbol) { // 42 var cls = symbol.ReceiverType; var isClass = symbol.ReceiverType.TypeKind == TypeKind.Class; var isPublic = string.Equals(symbol.ReceiverType.DeclaredAccessibility.ToString().ToLowerInvariant(), &quot;public&quot;, StringComparison.InvariantCultureIgnoreCase); // 43 if (isClass &amp;&amp; isPublic &amp;&amp; symbol.IsStatic &amp;&amp; symbol.MethodKind == MethodKind.Ordinary) { // 44 var className = cls.Name; var classNameWithNs = cls.ToDisplayString(); // 45 if (classNameWithNs != _typeName) return; // 46 var wrapperClassName = !className.Contains('&lt;') ? className + &quot;Wrapper&quot; : className.Replace(&quot;&lt;&quot;, &quot;Wrapper&lt;&quot;); // 47 var classTypeParameters = ((INamedTypeSymbol)cls).GetTypeParameters(); // 48 var wrapperInterfaceName = $&quot;I{wrapperClassName}{classTypeParameters}&quot;; // 49 var constraintClauses = ((INamedTypeSymbol)cls).GetConstraintClauses(); // 50 var baseList = ((INamedTypeSymbol)cls).GetBaseList(wrapperInterfaceName); // 51 var returnKeyword = symbol.ReturnsVoid ? &quot;&quot; : &quot;return &quot;; // 52 var methodSignature = symbol.GetSignatureText(); // 53 var callableMethodSignature = symbol.GetCallableSignatureText(); // 54 var obsoleteAttribute = symbol.GetAttributes().FirstOrDefault(x =&gt; x.ToString().StartsWith(&quot;System.ObsoleteAttribute(&quot;))?.ToString(); // 55 var interfaceSource = $&quot;\\tpublic partial interface I{wrapperClassName}{classTypeParameters} {constraintClauses} {{&quot;; var classSource = $&quot;\\tpublic partial class {wrapperClassName}{classTypeParameters} {baseList} {constraintClauses} {{&quot;; // 56 if (!_interfaces.Contains(interfaceSource)) _interfaces.Add(interfaceSource); // 57 if (!_classes.Contains(classSource)) _classes.Add(classSource); // 58 if (!_interfaces.Contains(methodSignature)) { _interfaces.Add($&quot;\\t\\t{methodSignature};&quot;); } // 59 if (!_classes.Contains(methodSignature)) { // 60 if (!string.IsNullOrEmpty(obsoleteAttribute)) { _classes.Add($&quot;\\t\\t[{obsoleteAttribute}]&quot;); } // 61 _classes.Add($&quot;\\t\\tpublic {methodSignature} {{&quot;); _classes.Add($&quot;\\t\\t\\t{returnKeyword}{classNameWithNs}.{callableMethodSignature};&quot;); _classes.Add(&quot;\\t\\t}&quot;); } } }} (37) We need some lists to add our generated source codes. (38) Our nested MethodSymbolVisitor inherits from SymbolVisitor. (39) We should first visit Namespace and accepts its members to get to the details we want. (40) We need to go one step deeper to get to the methods so visit named types and its members. (41) Now it is the time to get any information we need from methods. (42) We need to check ReceiverType. It should be a public class. (43) If the ReceiverType is a public class and also the method symbol is an ordinary static method we should continue our journy. (44) We are able to get class name and its namespace. (45) If the current class is not same as what we are expecting so we need to skip the whole process. (46) Just like part one we add Wrapper at the end of our interface and class name. (47) Your class may have type parameters (generic). Add below method to SourceGeneratorExtensions class. 12345internal static string GetTypeParameters(this INamedTypeSymbol namedTypeSymbol){ return namedTypeSymbol.TypeParameters.Length == 0 ? &quot;&quot; : $&quot;&lt;{namedTypeSymbol.TypeParameters.Select(x =&gt; x.Name).Aggregate((a, b) =&gt; $&quot;{a}, {b}&quot;)}&gt;&quot;;} (48) We create the name and structure of the interface. (49) If your class is generic, Has it any constraint clauses? With the following extension method we can find out. 1234567891011121314// SourceGeneratorExtensions.csinternal static string GetConstraintClauses(this INamedTypeSymbol namedTypeSymbol){ if (namedTypeSymbol.TypeParameters.Length == 0) return &quot;&quot;; var result = new List&lt;string&gt;(); foreach (var item in namedTypeSymbol.TypeParameters) { var constraintType = item.ToDisplayString(); var constraintItems = item.ConstraintTypes.Select(x =&gt; x.ToDisplayString()).Aggregate((a, b) =&gt; $&quot;{a}, {b}&quot;).Trim(); result.Add($&quot;where {constraintType} : {constraintItems}&quot;.Trim()); } return result.Aggregate((a, b) =&gt; $&quot;{a} {b}&quot;).Trim();} (50) If it has inherited from a class or implemented interfaces, information can be accessed through the following extension method. 123456789101112131415161718192021222324// SourceGeneratorExtensions.csinternal static string GetBaseList(this INamedTypeSymbol namedTypeSymbol, params string[] others){ var result = new List&lt;string&gt;(); if (namedTypeSymbol.BaseType != null &amp;&amp; !string.Equals(namedTypeSymbol.BaseType.Name, &quot;object&quot;, StringComparison.InvariantCultureIgnoreCase)) result.Add(namedTypeSymbol.BaseType.Name); if (namedTypeSymbol.AllInterfaces.Length != 0) { foreach (var item in namedTypeSymbol.AllInterfaces) { result.Add(item.Name); } } if (others != null &amp;&amp; others.Length != 0) { foreach (var item in others) { if (!string.IsNullOrEmpty(item)) result.Add(item); } } return result.Count == 0 ? &quot;&quot; : $&quot;: {result.Aggregate((a, b) =&gt; $&quot;{a}, {b}&quot;)}&quot;.Trim();} (51) The method needs return keyword or it returns nothing (void). (52) We should add our methods to interface so we need to know about its signature. So add the following extension method to your SourceGeneratorExtensions class. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667internal static string GetSignatureText(this IMethodSymbol methodSymbol){ var name = methodSymbol.Name; var parametersText = methodSymbol.Parameters.Length == 0 ? &quot;()&quot; : &quot;(&quot; + methodSymbol.Parameters.Select(x =&gt; getKind(x) + $&quot; {x.Type} &quot; + x.Name + getDefaultValue(x)) .Aggregate((a, b) =&gt; a + &quot;, &quot; + b).Trim() + &quot;)&quot;; var returnType = methodSymbol.ReturnsVoid ? &quot;void&quot; : methodSymbol.ReturnType.ToDisplayString(); var typeParameters = methodSymbol.TypeParameters.Length == 0 ? &quot;&quot; : &quot;&lt;&quot; + methodSymbol.TypeParameters.Select(x =&gt; x.Name).Aggregate((a, b) =&gt; $&quot;{a}, {b}&quot;).Trim() + &quot;&gt;&quot;; var constraintClauses = methodSymbol.TypeParameters.Length == 0 ? &quot;&quot; : methodSymbol.TypeParameters.Select(x =&gt; getConstraintClauses(x)).Aggregate((a, b) =&gt; $&quot;{a} {b}&quot;) ; return $&quot;{returnType} {name}{typeParameters}{parametersText} {constraintClauses}&quot;.Trim();}internal static string ToStringValue(this RefKind refKind){ if (refKind == RefKind.RefReadOnly) return &quot;ref readonly&quot;; switch (refKind) { case RefKind.Ref: return &quot;ref&quot;; case RefKind.Out: return &quot;out&quot;; case RefKind.In: return &quot;in&quot;; default: return &quot;&quot;; }} private static string getKind(IParameterSymbol parameterSymbol){ return parameterSymbol.IsParams ? &quot;params&quot; : parameterSymbol.RefKind.ToStringValue();}private static string getDefaultValue(IParameterSymbol parameterSymbol){ if (parameterSymbol.HasExplicitDefaultValue) { if (parameterSymbol.ExplicitDefaultValue == null) return $&quot; = null&quot;; if (parameterSymbol.ExplicitDefaultValue is bool) return $&quot; = {parameterSymbol.ExplicitDefaultValue.ToString().ToLowerInvariant()}&quot;; if (parameterSymbol.ExplicitDefaultValue is string) return $&quot; = \\&quot;{parameterSymbol.ExplicitDefaultValue}\\&quot;&quot;; else return $&quot; = {parameterSymbol.ExplicitDefaultValue}&quot;; } return &quot;&quot;;}private static string getConstraintClauses(ITypeParameterSymbol typeParameterSymbol){ if (typeParameterSymbol.ConstraintTypes.Length &gt; 0) { var constraintType = typeParameterSymbol.ToDisplayString(); var constraintItems = typeParameterSymbol.ConstraintTypes.Select(x =&gt; x.ToDisplayString()).Aggregate((a, b) =&gt; $&quot;{a}, {b}&quot;).Trim(); return $&quot;where {constraintType} : {constraintItems}&quot;.Trim(); } return &quot;&quot;;} The information it returns includes: Return type. Method name. Type parameter(s), if it is generic. Method parameter(s) (with type and name). Constraint Clauses, if it is generic. (53) We need to know how call the main static method inside of a wrapper method so we should add another extension method. 1234567891011121314// SourceGeneratorExtensions.csinternal static string GetCallableSignatureText(this IMethodSymbol methodSymbol){ var name = methodSymbol.Name; var parametersText = methodSymbol.Parameters.Length == 0 ? &quot;()&quot; : &quot;(&quot; + methodSymbol.Parameters.Select(x =&gt; $&quot;{getKind(x)} {x.Name}&quot;) .Aggregate((a, b) =&gt; $&quot;{a}, {b}&quot;).Trim() + &quot;)&quot;; var typeParameters = methodSymbol.TypeParameters.Length == 0 ? &quot;&quot; : &quot;&lt;&quot; + methodSymbol.TypeParameters.Select(x =&gt; x.Name).Aggregate((a, b) =&gt; $&quot;{a}, {b}&quot;).Trim() + &quot;&gt;&quot;; return $&quot;{name}{typeParameters}{parametersText}&quot;.Trim();} The information it returns includes: Method name. Type parameter(s), if it is generic. Method parameter(s) (with name and without type). (54) Just like the part one, We should check the method has ObsoleteAttribute or not. (55) It’s time to build the interface and the class. (56) If the generated source code does not include it, add the interface source. (57) If the generated source code does not include it, add the class source. (58) Add the method signature to the interface if does not exist. (59) Add the method signature to the class if does not exist. (60) If the method have an ObsoleteAttribute Add it on top of the generated wrapper method too. (61) With the whole information we have, we are able to complete the wrapper method. (62) Finally, we should complete our interface and class with final }. At the end of the foreach we have 12345678910foreach (var cls in receiver.Classes){ // ... // 63 var interfaceWrapper = sbInterface.ToString(); var classWrapper = sbClass.ToString(); // 64 sources.AppendLine(interfaceWrapper); sources.AppendLine(classWrapper);} (63) Convert our interface and class string builder to string. (64) And append them to sources variable which we created at the beginning of the source code. Finally, Our Execute method ends with 123456789101112131415161718// 65var defaultUsings = new StringBuilder();defaultUsings.AppendLine(&quot;using System;&quot;);defaultUsings.AppendLine(&quot;using System.Collections.Generic;&quot;);defaultUsings.AppendLine(&quot;using System.Linq;&quot;);defaultUsings.AppendLine(&quot;using System.Text;&quot;);defaultUsings.AppendLine(&quot;using System.Threading.Tasks;&quot;);var usings = defaultUsings.ToString();// 66var src = sources.ToString();var @namespace = new StringBuilder();@namespace.AppendLine(usings);@namespace.AppendLine($&quot;namespace {assemblyName}.MockableGenerated {{&quot;);@namespace.AppendLine(src);@namespace.Append(&quot;}&quot;);var result = @namespace.ToString();// 67context.AddSource($&quot;{assemblyName}MockableGenerated&quot;, SourceText.From(result,Encoding.UTF8)); (65) We are able to add some default using statements. (66) To use the end result, we need a specific namespace to aggregate all the generated code. As you can see, the final code is accessible through the following namespace. Assembly name + .MockableGenerated =&gt; Dapper.MockableGenerated (67) Finally, we add all the generated source code to the current source so that the compiler knows about it. Now, It’s time to add MockableStaticGenerator project to DapperSample as a reference project but you should update DapperSample.csproj file as following. 12345&lt;ItemGroup&gt; &lt;ProjectReference Include=&quot;..\\MockableStaticGenerator\\MockableStaticGenerator.csproj&quot; OutputItemType=&quot;Analyzer&quot; ReferenceOutputAssembly=&quot;false&quot;/&gt;&lt;/ItemGroup&gt; This is not a “normal” ProjectReference. It needs the additional ‘OutputItemType’ and ‘ReferenceOutputAssmbly’ attributes to act as an analyzor. So you should be able to access to generated namespace. No need to use DapperSqlMapper and IDapperSqlMapper any more just update your StudentRepository as following 12345678910111213141516171819202122232425262728// StudentRepository.csusing System.Collections.Generic;using System.Data;using System;using Dapper.MockableGenerated; // HEREnamespace DapperSample{ // HERE [MockableStatic(typeof(Dapper.SqlMapper))] public class StudentRepository : IStudentRepository { private readonly IDbConnection _dbConnection; private readonly ISqlMapperWrapper _dapperSqlMapper; public StudentRepository(IDbConnection dbConnection, ISqlMapperWrapper dapperSqlMapper /*HERE*/) { _dbConnection = dbConnection; _dapperSqlMapper = dapperSqlMapper; } public IEnumerable&lt;Student&gt; GetStudents() { return _dapperSqlMapper.Query&lt;Student&gt;(_dbConnection, &quot;SELECT * FROM STUDENT&quot;); } }} And also DapperSampleTest project and StudentRepositoryTest.cs file. 123456789101112131415161718192021using DapperSample;using Moq;using System.Data;using Xunit;using Dapper.MockableGenerated; // HEREnamespace DapperSampleTest{ public class StudentRepositoryTest { [Fact] public void STUDENT_REPOSITORY_TEST() { var mockConn = new Mock&lt;IDbConnection&gt;(); var mockDapper = new Mock&lt;ISqlMapperWrapper&gt;(); // HERE var sut = new StudentRepository(mockConn.Object, mockDapper.Object /*HERE*/); var stu = sut.GetStudents(); Assert.NotNull(stu); } }} You can find the whole source code here: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439// SourceGeneratorExtensions.csusing Microsoft.CodeAnalysis.CSharp.Syntax;using System;using System.Collections.Generic;using System.Collections.Immutable;using System.Linq;using System.Text.RegularExpressions;namespace Microsoft.CodeAnalysis{ internal static class SourceGeneratorExtensions { internal static string ToStringValue(this RefKind refKind) { if (refKind == RefKind.RefReadOnly) return &quot;ref readonly&quot;; switch (refKind) { case RefKind.Ref: return &quot;ref&quot;; case RefKind.Out: return &quot;out&quot;; case RefKind.In: return &quot;in&quot;; default: return &quot;&quot;; } } internal static bool IsPublic(this ISymbol symbol) { return string.Equals(symbol.DeclaredAccessibility.ToString(), &quot;public&quot;, StringComparison.InvariantCultureIgnoreCase); } internal static string GetTypeParameters(this ClassDeclarationSyntax classDeclarationSyntax) { var result = classDeclarationSyntax.TypeParameterList?.ToFullString().Trim(); return string.IsNullOrEmpty(result) ? null : result; } internal static string GetConstraintClauses(this ClassDeclarationSyntax classDeclarationSyntax) { var result = classDeclarationSyntax.ConstraintClauses.ToFullString().Trim(); return string.IsNullOrEmpty(result) ? null : result; } internal static bool IsPublic(this MethodDeclarationSyntax methodDeclarationSyntax) { return methodDeclarationSyntax.Modifiers.Select(x =&gt; x.ValueText).Contains(&quot;public&quot;); } internal static bool IsStatic(this MethodDeclarationSyntax methodDeclarationSyntax) { return methodDeclarationSyntax.Modifiers.Select(x =&gt; x.ValueText).Contains(&quot;static&quot;); } internal static bool ReturnsVoid(this MethodDeclarationSyntax methodDeclarationSyntax) { return methodDeclarationSyntax.ReturnType.ToFullString().Trim() == &quot;void&quot;; } internal static string GetSignatureText(this MethodDeclarationSyntax methodDeclarationSyntax) { var name = methodDeclarationSyntax.Identifier.ValueText; var parameters = methodDeclarationSyntax.ParameterList?.ToFullString().Trim(); var typeParameters = methodDeclarationSyntax.TypeParameterList?.ToFullString().Trim(); var constraintClauses = methodDeclarationSyntax.ConstraintClauses.ToFullString().Replace(System.Environment.NewLine, &quot;&quot;).Trim(); var returnType = methodDeclarationSyntax.ReturnType.ToFullString().Trim(); return $&quot;{returnType} {name}{typeParameters}{parameters} {constraintClauses}&quot;.Trim(); } internal static string GetParametersText(this ParameterListSyntax parameterListSyntax) { if (parameterListSyntax == null || parameterListSyntax.Parameters.Count == 0) return &quot;()&quot;; var result = new List&lt;string&gt;(); foreach (var item in parameterListSyntax.Parameters) { var variableName = item.Identifier; var modifiers = item.Modifiers.Select(x =&gt; x.ValueText).ToList(); var modifiersText = modifiers.Count == 0 ? &quot;&quot; : modifiers.Aggregate((a, b) =&gt; a + &quot; &quot; + b); result.Add($&quot;{modifiersText} {variableName}&quot;); } return result.Count == 0 ? &quot;()&quot; : $&quot;({result.Aggregate((a, b) =&gt; a + &quot;, &quot; + b).Trim()})&quot;; } internal static string GetCallableSignatureText(this MethodDeclarationSyntax methodDeclarationSyntax) { var name = methodDeclarationSyntax.Identifier.ValueText; var parameters = methodDeclarationSyntax.ParameterList.GetParametersText(); var typeParameters = methodDeclarationSyntax.TypeParameterList?.ToFullString().Trim(); return $&quot;{name}{typeParameters}{parameters}&quot;.Trim(); } internal static bool TryGetObsoleteAttribute(this MethodDeclarationSyntax methodDeclarationSyntax, out string text) { var attr = methodDeclarationSyntax.AttributeLists.Where(x =&gt; x is not null &amp;&amp; IsObsolete(x.GetText().ToString())).Select(x =&gt; x.GetText().ToString()).ToList(); text = attr.Count != 0 ? ReplaceFirst(attr[0].Trim(), &quot;Obsolete&quot;, &quot;System.Obsolete&quot;) : &quot;&quot;; return attr.Count != 0; bool IsObsolete(string text) { Match match = Regex.Match(text, @&quot;\\[\\s*Obsolete[Attribute]*\\s*\\(&quot;); return match.Success; } string ReplaceFirst(string text, string search, string replace) { int pos = text.IndexOf(search); if (pos &lt; 0) { return text; } return text.Substring(0, pos) + replace + text.Substring(pos + search.Length); } } internal static string GetNamespace(this SyntaxNode syntaxNode) { return syntaxNode.Parent switch { NamespaceDeclarationSyntax namespaceDeclarationSyntax =&gt; namespaceDeclarationSyntax.Name.ToString(), null =&gt; string.Empty, _ =&gt; GetNamespace(syntaxNode.Parent) }; } internal static string GetTypeParameters(this INamedTypeSymbol namedTypeSymbol) { return namedTypeSymbol.TypeParameters.Length == 0 ? &quot;&quot; : $&quot;&lt;{namedTypeSymbol.TypeParameters.Select(x =&gt; x.Name).Aggregate((a, b) =&gt; $&quot;{a}, {b}&quot;)}&gt;&quot;; } internal static string GetConstraintClauses(this INamedTypeSymbol namedTypeSymbol) { if (namedTypeSymbol.TypeParameters.Length == 0) return &quot;&quot;; var result = new List&lt;string&gt;(); foreach (var item in namedTypeSymbol.TypeParameters) { var constraintType = item.ToDisplayString(); var constraintItems = item.ConstraintTypes.Select(x =&gt; x.ToDisplayString()).Aggregate((a, b) =&gt; $&quot;{a}, {b}&quot;).Trim(); result.Add($&quot;where {constraintType} : {constraintItems}&quot;.Trim()); } return result.Aggregate((a, b) =&gt; $&quot;{a} {b}&quot;).Trim(); } internal static string GetBaseList(this INamedTypeSymbol namedTypeSymbol, params string[] others) { var result = new List&lt;string&gt;(); if (namedTypeSymbol.BaseType != null &amp;&amp; !string.Equals(namedTypeSymbol.BaseType.Name, &quot;object&quot;, StringComparison.InvariantCultureIgnoreCase)) result.Add(namedTypeSymbol.BaseType.Name); if (namedTypeSymbol.AllInterfaces.Length != 0) { foreach (var item in namedTypeSymbol.AllInterfaces) { result.Add(item.Name); } } if (others != null &amp;&amp; others.Length != 0) { foreach (var item in others) { if (!string.IsNullOrEmpty(item)) result.Add(item); } } return result.Count == 0 ? &quot;&quot; : $&quot;: {result.Aggregate((a, b) =&gt; $&quot;{a}, {b}&quot;)}&quot;.Trim(); } private static string getKind(IParameterSymbol parameterSymbol) { return parameterSymbol.IsParams ? &quot;params&quot; : parameterSymbol.RefKind.ToStringValue(); } private static string getDefaultValue(IParameterSymbol parameterSymbol) { if (parameterSymbol.HasExplicitDefaultValue) { if (parameterSymbol.ExplicitDefaultValue == null) return $&quot; = null&quot;; if (parameterSymbol.ExplicitDefaultValue is bool) return $&quot; = {parameterSymbol.ExplicitDefaultValue.ToString().ToLowerInvariant()}&quot;; if (parameterSymbol.ExplicitDefaultValue is string) return $&quot; = \\&quot;{parameterSymbol.ExplicitDefaultValue}\\&quot;&quot;; else return $&quot; = {parameterSymbol.ExplicitDefaultValue}&quot;; } return &quot;&quot;; } private static string getConstraintClauses(ITypeParameterSymbol typeParameterSymbol) { if (typeParameterSymbol.ConstraintTypes.Length &gt; 0) { var constraintType = typeParameterSymbol.ToDisplayString(); var constraintItems = typeParameterSymbol.ConstraintTypes.Select(x =&gt; x.ToDisplayString()).Aggregate((a, b) =&gt; $&quot;{a}, {b}&quot;).Trim(); return $&quot;where {constraintType} : {constraintItems}&quot;.Trim(); } return &quot;&quot;; } internal static string GetSignatureText(this IMethodSymbol methodSymbol) { var name = methodSymbol.Name; var parametersText = methodSymbol.Parameters.Length == 0 ? &quot;()&quot; : &quot;(&quot; + methodSymbol.Parameters.Select(x =&gt; getKind(x) + $&quot; {x.Type} &quot; + x.Name + getDefaultValue(x)) .Aggregate((a, b) =&gt; a + &quot;, &quot; + b).Trim() + &quot;)&quot;; var returnType = methodSymbol.ReturnsVoid ? &quot;void&quot; : methodSymbol.ReturnType.ToDisplayString(); var typeParameters = methodSymbol.TypeParameters.Length == 0 ? &quot;&quot; : &quot;&lt;&quot; + methodSymbol.TypeParameters.Select(x =&gt; x.Name).Aggregate((a, b) =&gt; $&quot;{a}, {b}&quot;).Trim() + &quot;&gt;&quot;; var constraintClauses = methodSymbol.TypeParameters.Length == 0 ? &quot;&quot; : methodSymbol.TypeParameters.Select(x =&gt; getConstraintClauses(x)).Aggregate((a, b) =&gt; $&quot;{a} {b}&quot;) ; return $&quot;{returnType} {name}{typeParameters}{parametersText} {constraintClauses}&quot;.Trim(); } internal static string GetCallableSignatureText(this IMethodSymbol methodSymbol) { var name = methodSymbol.Name; var parametersText = methodSymbol.Parameters.Length == 0 ? &quot;()&quot; : &quot;(&quot; + methodSymbol.Parameters.Select(x =&gt; $&quot;{getKind(x)} {x.Name}&quot;) .Aggregate((a, b) =&gt; $&quot;{a}, {b}&quot;).Trim() + &quot;)&quot;; var typeParameters = methodSymbol.TypeParameters.Length == 0 ? &quot;&quot; : &quot;&lt;&quot; + methodSymbol.TypeParameters.Select(x =&gt; x.Name).Aggregate((a, b) =&gt; $&quot;{a}, {b}&quot;).Trim() + &quot;&gt;&quot;; return $&quot;{name}{typeParameters}{parametersText}&quot;.Trim(); } }}// MockableGenerator.csusing Microsoft.CodeAnalysis;using Microsoft.CodeAnalysis.CSharp;using Microsoft.CodeAnalysis.CSharp.Syntax;using Microsoft.CodeAnalysis.Text;using System;using System.Collections.Generic;using System.Linq;using System.Text;namespace MockableStaticGenerator{ [Generator] public class MockableGenerator : ISourceGenerator { private static readonly List&lt;string&gt; _interfaces = new List&lt;string&gt;(); private static readonly List&lt;string&gt; _classes = new List&lt;string&gt;(); public class MethodSymbolVisitor : SymbolVisitor { private readonly string _typeName; public MethodSymbolVisitor(string typeName) { _typeName = typeName; } public override void VisitNamespace(INamespaceSymbol symbol) { foreach (var child in symbol.GetMembers()) { child.Accept(this); } } public override void VisitNamedType(INamedTypeSymbol symbol) { foreach (var child in symbol.GetMembers()) { child.Accept(this); } } public override void VisitMethod(IMethodSymbol symbol) { var cls = symbol.ReceiverType; var isClass = symbol.ReceiverType.TypeKind == TypeKind.Class; var isPublic = string.Equals(symbol.ReceiverType.DeclaredAccessibility.ToString().ToLowerInvariant(), &quot;public&quot;, StringComparison.InvariantCultureIgnoreCase); if (isClass &amp;&amp; isPublic &amp;&amp; symbol.IsStatic &amp;&amp; symbol.MethodKind == MethodKind.Ordinary) { var className = cls.Name; var classNameWithNs = cls.ToDisplayString(); if (classNameWithNs != _typeName) return; var wrapperClassName = !className.Contains('&lt;') ? className + &quot;Wrapper&quot; : className.Replace(&quot;&lt;&quot;, &quot;Wrapper&lt;&quot;); var classTypeParameters = ((INamedTypeSymbol)cls).GetTypeParameters(); var wrapperInterfaceName = $&quot;I{wrapperClassName}{classTypeParameters}&quot;; var constraintClauses = ((INamedTypeSymbol)cls).GetConstraintClauses(); var baseList = ((INamedTypeSymbol)cls).GetBaseList(wrapperInterfaceName); var returnKeyword = symbol.ReturnsVoid ? &quot;&quot; : &quot;return &quot;; var methodSignature = symbol.GetSignatureText(); var callableMethodSignature = symbol.GetCallableSignatureText(); var obsoleteAttribute = symbol.GetAttributes().FirstOrDefault(x =&gt; x.ToString().StartsWith(&quot;System.ObsoleteAttribute(&quot;))?.ToString(); var interfaceSource = $&quot;\\tpublic partial interface I{wrapperClassName}{classTypeParameters} {constraintClauses} {{&quot;; var classSource = $&quot;\\tpublic partial class {wrapperClassName}{classTypeParameters} {baseList} {constraintClauses} {{&quot;; if (!_interfaces.Contains(interfaceSource)) _interfaces.Add(interfaceSource); if (!_classes.Contains(classSource)) _classes.Add(classSource); if (!_interfaces.Contains(methodSignature)) { _interfaces.Add($&quot;\\t\\t{methodSignature};&quot;); } if (!_classes.Contains(methodSignature)) { if (!string.IsNullOrEmpty(obsoleteAttribute)) { _classes.Add($&quot;\\t\\t[{obsoleteAttribute}]&quot;); } _classes.Add($&quot;\\t\\tpublic {methodSignature} {{&quot;); _classes.Add($&quot;\\t\\t\\t{returnKeyword}{classNameWithNs}.{callableMethodSignature};&quot;); _classes.Add(&quot;\\t\\t}&quot;); } } } } public void Execute(GeneratorExecutionContext context) { context.AddSource(nameof(Constants.MockableStaticAttribute), SourceText.From(Constants.MockableStaticAttribute, Encoding.UTF8)); if (context.SyntaxReceiver is not SyntaxReceiver receiver) return; CSharpParseOptions options = (context.Compilation as CSharpCompilation).SyntaxTrees[0].Options as CSharpParseOptions; Compilation compilation = context.Compilation.AddSyntaxTrees(CSharpSyntaxTree.ParseText(SourceText.From(Constants.MockableStaticAttribute, Encoding.UTF8), options)); INamedTypeSymbol attributeSymbol = compilation.GetTypeByMetadataName($&quot;System.{nameof(Constants.MockableStaticAttribute)}&quot;); var sources = new StringBuilder(); var assemblyName = &quot;&quot;; foreach (var cls in receiver.Classes) { SemanticModel model = compilation.GetSemanticModel(cls.SyntaxTree); var clsSymbol = model.GetDeclaredSymbol(cls); var attr = clsSymbol.GetAttributes().FirstOrDefault(ad =&gt; ad.AttributeClass.Equals(attributeSymbol, SymbolEqualityComparer.Default)); if (attr == null) continue; var isParameterlessCtor = attr?.ConstructorArguments.Length == 0; var sbInterface = new StringBuilder(); var sbClass = new StringBuilder(); if (isParameterlessCtor) { var methods = cls.DescendantNodes().OfType&lt;MethodDeclarationSyntax&gt;().Where(x =&gt; x.IsPublic() &amp;&amp; x.IsStatic()).ToList(); if (methods.Count == 0) continue; var className = clsSymbol.Name; var ns = string.IsNullOrEmpty(cls.GetNamespace()) ? &quot;&quot; : cls.GetNamespace() + &quot;.&quot;; var baseList = string.IsNullOrEmpty(cls.BaseList?.ToFullString()) ? &quot;:&quot; : cls.BaseList?.ToFullString().Trim() + &quot;,&quot;; assemblyName = clsSymbol.ContainingAssembly.Identity.Name; var wrapperClassName = !className.Contains('&lt;') ? className + &quot;Wrapper&quot; : className.Replace(&quot;&lt;&quot;, &quot;Wrapper&lt;&quot;); var classTypeParameters = cls.GetTypeParameters() ?? &quot;&quot;; var constraintClauses = cls.GetConstraintClauses() ?? &quot;&quot;; sbInterface.AppendLine($&quot;\\tpublic partial interface I{wrapperClassName}{classTypeParameters} {constraintClauses} {{&quot;); sbClass.AppendLine($&quot;\\tpublic partial class {wrapperClassName}{classTypeParameters} {baseList} I{wrapperClassName}{classTypeParameters} {constraintClauses} {{&quot;); foreach (MethodDeclarationSyntax method in methods) { var text = method.GetSignatureText(); if (!sbInterface.ToString().Contains(text)) sbInterface.AppendLine($&quot;\\t\\t{text};&quot;); if (!sbClass.ToString().Contains(text)) { var returnKeyword = method.ReturnsVoid() ? &quot;&quot; : &quot;return &quot;; var obsoleteAttrText = &quot;&quot;; var isObsolete = method.TryGetObsoleteAttribute(out obsoleteAttrText); if (isObsolete) sbClass.AppendLine($&quot;\\t\\t{obsoleteAttrText}&quot;); sbClass.AppendLine($&quot;\\t\\tpublic {method.GetSignatureText()} {{&quot;); sbClass.AppendLine($&quot;\\t\\t\\t{returnKeyword}{ns}{className}{classTypeParameters}.{method.GetCallableSignatureText()};&quot;); sbClass.AppendLine($&quot;\\t\\t}}&quot;); } } sbInterface.AppendLine($&quot;\\t}}&quot;); sbClass.AppendLine($&quot;\\t}}&quot;); } else { var ctor = ((INamedTypeSymbol)attr?.ConstructorArguments[0].Value); var assemblySymbol = ctor.ContainingAssembly.GlobalNamespace; assemblyName = ctor.ContainingAssembly.Identity.Name; var visitor = new MethodSymbolVisitor(ctor.ToDisplayString()); visitor.Visit(assemblySymbol); sbInterface.AppendLine(_interfaces.Aggregate((a, b) =&gt; a + Environment.NewLine + b) + Environment.NewLine + &quot;\\t}&quot;); sbClass.AppendLine(_classes.Aggregate((a, b) =&gt; a + Environment.NewLine + b) + Environment.NewLine + &quot;\\t}&quot;); } var interfaceWrapper = sbInterface.ToString(); var classWrapper = sbClass.ToString(); sources.AppendLine(interfaceWrapper); sources.AppendLine(classWrapper); } var defaultUsings = new StringBuilder(); defaultUsings.AppendLine(&quot;using System;&quot;); defaultUsings.AppendLine(&quot;using System.Collections.Generic;&quot;); defaultUsings.AppendLine(&quot;using System.Linq;&quot;); defaultUsings.AppendLine(&quot;using System.Text;&quot;); defaultUsings.AppendLine(&quot;using System.Threading.Tasks;&quot;); var usings = defaultUsings.ToString(); var src = sources.ToString(); var @namespace = new StringBuilder(); @namespace.AppendLine(usings); @namespace.AppendLine($&quot;namespace {assemblyName}.MockableGenerated {{&quot;); @namespace.AppendLine(src); @namespace.Append(&quot;}&quot;); var result = @namespace.ToString(); context.AddSource($&quot;{assemblyName}MockableGenerated&quot;, SourceText.From(result, Encoding.UTF8)); } public void Initialize(GeneratorInitializationContext context) { // System.Diagnostics.Debugger.Launch(); context.RegisterForSyntaxNotifications(() =&gt; new SyntaxReceiver()); } }} Visual Studio does not detect my source generators, What should I do?Unfortunately, the current version of Visual Studio (16.8.2) has a lot of problems while you are using code generators, but you can try the following steps. Make sure you follow the steps above correctly. Use dotnet clean, Maybe you need to delete all bin and obj folders. After that, use dotnet build to make sure your source code has no error and the problem is caused by Visual Studio. Reset your Visual Studio. How to debug it?To start debug you can add System.Diagnostics.Debugger.Launch(); as following: 12345public void Initialize(GeneratorInitializationContext context){ System.Diagnostics.Debugger.Launch(); // HERE context.RegisterForSyntaxNotifications(() =&gt; new SyntaxReceiver());} Run the debugger and you will see it stops at System.Diagnostics.Debugger.Launch() line. If you have any problem for debugging, like what I had before Make sure you are running Visual Studio as administrator. Open Visual Studio as Administrator If you want to start Visual Studio as Administrator you can do the following: Right-click on your VS task bar shortcut Right-click on your VS product and select Properties From Properties window select Advanced… From Advanced Properties check on Run as Administrator option select Ok in Advanced Properties window, Apply and then Ok on VS 2019 Properties. Open every Visual Studio Solution (.sln) as Administrator Although not the best idea if you open third-party VS solutions, it may come in handy if you need to open the same solutions as Administrator again and again. To do so, right-click on devenv.exe and select Troubleshoot Compatibility. You may then proceed to the following steps: On the Program Compatibility Troubleshooter window, click on Troubleshoot Program Check The program requires additional permissions and click Next On the next window, click on Test the program… and VS will open as administrator Click next and then click on Yes, save these settings for this program Following the above, whenever you open a solution (.sln) it will always open as Adminsitrator. If you want to disable this function, you will need to follow again the steps above without checking though The Program requires additional permissions. How to work with files?If you are using a specific physical file with source generators you should use AdditionalFiles in your csproj. 1234&lt;ItemGroup&gt; &lt;AdditionalFiles Include=&quot;People.csv&quot; CsvLoadType=&quot;Startup&quot; /&gt; &lt;AdditionalFiles Include=&quot;Cars.csv&quot; CsvLoadType=&quot;OnDemand&quot; CacheObjects=&quot;true&quot; /&gt;&lt;/ItemGroup&gt; To access your attributes like CsvLoadType or CacheObjects, You are able to use the following approach: 12345678910111213141516171819static IEnumerable&lt;(CsvLoadType, bool, AdditionalText)&gt; GetLoadOptions(SourceGeneratorContext context){ foreach (AdditionalText file in context.AdditionalFiles) { if (Path.GetExtension(file.Path).Equals(&quot;.csv&quot;, StringComparison.OrdinalIgnoreCase)) { // HERE context.AnalyzerConfigOptions.GetOptions(file) .TryGetValue(&quot;build_metadata.additionalfiles.CsvLoadType&quot;, out string? loadTimeString); Enum.TryParse(loadTimeString, ignoreCase: true, out CsvLoadType loadType); context.AnalyzerConfigOptions.GetOptions(file) .TryGetValue(&quot;build_metadata.additionalfiles.CacheObjects&quot;, out string? cacheObjectsString); bool.TryParse(cacheObjectsString, out bool cacheObjects); yield return (loadType, cacheObjects, file); } }} How to publish it through Nuget?To do this you have two important xml blocks in your csproj as folowing. 1234567&lt;PropertyGroup&gt; &lt;IncludeBuildOutput&gt;false&lt;/IncludeBuildOutput&gt;&lt;/PropertyGroup&gt;&lt;ItemGroup&gt; &lt;None Include=&quot;$(OutputPath)\\$(AssemblyName).dll&quot; Pack=&quot;true&quot; PackagePath=&quot;analyzers/dotnet/cs&quot; Visible=&quot;false&quot; /&gt;&lt;/ItemGroup&gt; Source CodeYou can check the source of this project and its nuget package from the following addresses: GitHub Nuget Reference(s)Some of the information in this article has gathered from various references. https://makolyte.com/how-to-mock-static-methods/ https://devblogs.microsoft.com/dotnet/introducing-c-source-generators/ https://devblogs.microsoft.com/dotnet/new-c-source-generator-samples/ https://github.com/dotnet/roslyn/blob/master/docs/features/source-generators.cookbook.md https://ppolyzos.com/2017/08/08/always-run-visual-studio-as-administrator/","link":"/the-dotnet-world-csharp-source-generator/"},{"title":"The .NET World - Guard","text":"I want to introduce a high-performance, extensible argument validation library. Guard is a fluent argument validation library that is intuitive, fast and extensible. Guard takes advantage of almost all the new features introduced in C# 7.2. Install the below package 123Install-Package Dawn.Guard -Version 1.12.0dotnet add package Dawn.Guard --version 1.12.0&lt;PackageReference Include=&quot;Dawn.Guard&quot; Version=&quot;1.12.0&quot; /&gt; IntroductionHere is a sample constructor that validates its arguments without Guard: 1234567891011121314public Person(string name, int age){ if (name == null) throw new ArgumentNullException(nameof(name), &quot;Name cannot be null.&quot;); if (name.Length == 0) throw new ArgumentException(&quot;Name cannot be empty.&quot;, nameof(name)); if (age &lt; 0) throw new ArgumentOutOfRangeException(nameof(age), age, &quot;Age cannot be negative.&quot;); Name = name; Age = age;} And this is how we write the same constructor with Guard: 1234567using Dawn; // Bring Guard into scope.public Person(string name, int age){ Name = Guard.Argument(name, nameof(name)).NotNull().NotEmpty(); Age = Guard.Argument(age, nameof(age)).NotNegative();} Standard ValidationsBelow is a complete list of validations that are included with the library. Optional parameters thatallow you to specify custom exception messages are omitted for brevity. Null Guards For ArgumentInfo&lt;T&gt; where T : class and ArgumentInfo&lt;T?&gt; where T : struct Null() NotNull() - When called for an argument of T?, returns an argument of T. Static without type constraints: NotAllNull(ArgumentInfo&lt;T1&gt;, ArgumentInfo&lt;T2&gt;) NotAllNull(ArgumentInfo&lt;T1&gt;, ArgumentInfo&lt;T2&gt;, ArgumentInfo&lt;T3&gt;) Equality Guards For ArgumentInfo&lt;T&gt; Equal(T) Equal(T, IEqualityComparer&lt;T&gt;) NotEqual(T) NotEqual(T, IEqualityComparer&lt;T&gt;) For ArgumentInfo&lt;T&gt; where T : class Same(T) NotSame(T) For ArgumentInfo&lt;T|T?&gt; where T : struct Default() NotDefault() Comparison Guards For ArgumentInfo&lt;T&gt; where T : IComparable&lt;T&gt; Min(T) Max(T) GreaterThan(T) LessThan(T) InRange(T, T) For ArgumentInfo&lt;T|T?&gt; where T : struct, IComparable&lt;T&gt; Zero() NotZero() Positive() NotPositive() Negative() NotNegative() Boolean Guards For ArgumentInfo&lt;bool|bool?&gt; True() False() Collection Guards For ArgumentInfo&lt;T&gt; where T : IEnumerable Empty() NotEmpty() Count(int) NotCount(int) MinCount(int) MaxCount(int) CountInRange(int, int) Contains&lt;TItem&gt;(TItem) Contains&lt;TItem&gt;(TItem, IEqualityComparer&lt;TItem&gt;) DoesNotContain&lt;TItem&gt;(TItem) DoesNotContain&lt;TItem&gt;(TItem, IEqualityComparer&lt;TItem&gt;) ContainsNull() DoesNotContainNull() DoesNotContainDuplicate() DoesNotContainDuplicate(IEqualityComparer&lt;TItem&gt;) For ArgumentInfo&lt;T&gt; In&lt;TCollection&gt;(TCollection) In&lt;TCollection&gt;(TCollection, IEqualityComparer&lt;T&gt;) NotIn&lt;TCollection&gt;(TCollection) NotIn&lt;TCollection&gt;(TCollection, IEqualityComparer&lt;T&gt;) String Guards For ArgumentInfo&lt;string&gt; Empty() NotEmpty() WhiteSpace() NotWhiteSpace() Length(int) NotLength(int) MinLength(int) MaxLength(int) LengthInRange(int, int) Equal(string, StringComparison) NotEqual(string, StringComparison) StartsWith(string) StartsWith(string, StringComparison) DoesNotStartWith(string) DoesNotStartWith(string, StringComparison) EndsWith(string) EndsWith(string, StringComparison) DoesNotEndWith(string) DoesNotEndWith(string, StringComparison) Matches(string) Matches(string, TimeSpan) Matches(Regex) DoesNotMatch(string) DoesNotMatch(string, TimeSpan) DoesNotMatch(Regex) Time Guards For ArgumentInfo&lt;DateTime|DateTime?&gt; KindSpecified() KindUnspecified() Floating-Point Number Guards For ArgumentInfo&lt;float|float?|double|double?&gt; NaN() NotNaN() Infinity() NotInfinity() PositiveInfinity() NotPositiveInfinity() NegativeInfinity() NotNegativeInfinity() Equal(T, T) - Approx. equality. NotEqual(T, T) - Approx. unequality. URI Guards For ArgumentInfo&lt;Uri&gt; Absolute Relative Scheme(string) NotScheme(string) Http() Http(bool) Https() Enum GuardsFor ArgumentInfo&lt;T|T?&gt; where T : struct, Enum Defined() HasFlag(T) DoesNotHaveFlag(T) Email GuardsFor ArgumentInfo&lt;MailAddress&gt; HasHost(string) DoesNotHaveHost(string) HostIn(IEnumerable&lt;string&gt;) HostNotIn(IEnumerable&lt;string&gt;) HasDisplayName() DoesNotHaveDisplayName() Type Guards For ArgumentInfo&lt;T&gt; Compatible&lt;TTarget&gt;() NotCompatible&lt;TTarget&gt;() Cast&lt;TTarget&gt; - Returns an argument of TTarget For ArgumentInfo&lt;object&gt; Type&lt;T&gt;() - Returns an argument of T. NotType&lt;T&gt;() Type(Type) NotType(Type) Member GuardsFor ArgumentInfo&lt;T&gt; Member&lt;TMember&gt;(Expression&lt;Func&lt;T, TMember&gt;&gt;, Action&lt;ArgumentInfo&lt;TMember&gt;&gt;) Member&lt;TMember&gt;(Expression&lt;Func&lt;T, TMember&gt;&gt;, Action&lt;ArgumentInfo&lt;TMember&gt;&gt;, bool) Normalization Guards For ArgumentInfo&lt;T&gt; Modify&lt;TTarget&gt;(TTarget value) - Returns an argument of TTarget Modify&lt;TTarget&gt;(Func&lt;T, TTarget&gt;) - Returns an argument of TTarget Wrap&lt;TTarget&gt;(Func&lt;T, TTarget&gt;) - Returns an argument of TTarget For ArgumentInfo&lt;T&gt; where T : class, ICloneable Clone() Predicate Guards For ArgumentInfo&lt;T&gt; Require(bool) Require&lt;TException&gt;(bool) Require(Func&lt;T, bool&gt;) Require&lt;TException&gt;(Func&lt;T, bool&gt;) State Guards For validating instance states instead of method arguments: Operation(bool) - Throws InvalidOperationException for false Support(bool) - Throws NotSupportedException for false Disposal(bool, string) - Throws ObjectDisposedException for true Initializing a Guarded ArgumentGuard needs to know the argument’s value to test it against preconditions and its name to include ina potential exception. There are three ways to initialize a guarded argument: 12345678// First, by specifying the argument value and name separately.Guard.Argument(arg, nameof(arg));// Second, omitting the optional argument name.Guard.Argument(arg);// Third, creating a MemberExpression via a lambda expression.Guard.Argument(() =&gt; arg); The first sample initializes a guarded argument by specifying both the argument’s value and name. The second sample does not specify the argument name. This is allowed but not recommended sincethe argument name proves a valuable piece of information when you try to identify the error causefrom logs or crash dumps. The third sample initializes a MemberExpression that provides both the argument’s value andname. Although compiling an expression tree is an expensive operation, it is a convenientalternative that can be used in applications that are not performance-critical. Exception TypesEach validation in Guard has a specific exception type it throws when its precondition is notsatisfied. NotNull throws an ArgumentNullException. The validations on IComparable&lt;T&gt;arguments like MinValue and NotZero throw ArgumentOutOfRangeExceptions. Most othersthrow ArgumentExceptions. (See Modifying Arguments for exceptional cases.) Throwing custom exceptions from standard validations seems counter-intuitive and right now, the onlyway to do so is to use the generic Require&lt;TException&gt; validation. 1Guard.Argument(() =&gt; arg).Require&lt;KeyNotFoundException&gt;(a =&gt; a != 0); The above code throws a KeyNotFoundException if the arg is passed 0. Exception MessagesGuard creates a meaningful exception message that contains the argument name and a descriptionspecific to the validation when a precondition can’t be satisfied. Additionaly, every validation inGuard accepts an optional parameter letting the user specify a custom error message. 12345// Throws an ArgumentException if the arg is not null.Guard.Argument(() =&gt; arg).Null(a =&gt; &quot;The argument must be null but it is: &quot; + a);// Throws an ArgumentNullException if the arg is null.Guard.Argument(() =&gt; arg).NotNull(&quot;The argument cannot be null.&quot;); In the first example above, we specify a factory that will create the error message if thevalidation fails. arg is passed to the factory as a so it can be used in the error message. Wecould of course use arg directly but that would cause it to be captured by the lambda expression,thus prevent the expression from being cached. We could make the Null validation accept astring parameter instead of a Func&lt;T, string&gt;, but that would require the error message tobe initialized even when the precondition is satisfied, i.e. when the argument is null. In the second example, we see that the NotNull validation accepts the error message as a stringinstead of a factory. This is because it only throws an exception if the argument value is null.Therefore the only possible value that can be passed to a factory would be null. Secure ArgumentsExceptions thrown for failed Guard validations contain very descriptive messages. 12345// Throws with message: &quot;token must be a2C-p.&quot;Guard.Argument(&quot;abc&quot;, &quot;token&quot;).Equal(&quot;a2C-p&quot;);// Throws with message: &quot;number must be one of the following: 1, 2, 3&quot;Guard.Argument(0, &quot;number&quot;).In(1, 2, 3); There may be cases where you don’t want to expose that additional data to the caller. For thesescenarios, you can specify the optional “secure” flag when you initialize the argument. 12345// Throws with message: &quot;token is invalid.&quot;Guard.Argument(&quot;abc&quot;, &quot;token&quot;, true).Equal(&quot;a2C-p&quot;);// Throws with message: &quot;number is invalid.&quot;Guard.Argument(0, &quot;number&quot;, true).In(1, 2, 3); Things to note: Parameter names are never secured. Min/Max values of range checks are never secured. Type names are never secured. Exceptions that are not directly thrown by the library are never secured. Modifying ArgumentsA method that validates its arguments can also apply some normalization routines before using them.Trimming a string before assigning it to a field/property is a good example for that. Guard providesthe Modify overloads that can be used for normalizing argument values. 1234567public Person(string name){ Name = Guard.Argument(() =&gt; name) .NotNull() .Modify(s =&gt; s.Trim()) .MinLength(3); // Validates the trimmed version.} Since the arguments can be modified to have any value, including null, NotNull validationsapplied to modified arguments shouldn’t throw ArgumentNullExceptions. 1234567public Person GetOwner(Car car){ return Guard.Argument(() =&gt; car) .NotNull() .Modify(c =&gt; c.Owner) .NotNull();} The first call to NotNull in the above example throws an ArgumentNullException if car isnull but the second call to NotNull should throw an ArgumentException. This is becausethrowing an ArgumentNullException there would indicate that car is null when in fact itsOwner is null. The same goes for ArgumentOutOfRangeExceptions. If the original argument is modified, anArgumentException is thrown instead of a more specialized exception. For validations to detectwhether the argument is modified, ArgumentInfo&lt;T&gt; contains a boolean Modified flag alongwith the argument’s name and value. Validating Argument MembersSome arguments may contain fields/properties that we want to validate individually. Guard providesMember overloads that can be used to validate these members without modifying the arguments. 12345678910111213public void BuyCar(Person buyer, Car car){ Guard.Argument(() =&gt; buyer) .NotNull() .Member(p =&gt; p.Age, a =&gt; a.Min(18)) .Member(p =&gt; p.Address.City, c =&gt; c.NotNull().NotEmpty()); Guard.Argument(() =&gt; car) .NotNull() .Member(c =&gt; c.Owner, o =&gt; o.Null()); car.Owner = buyer;} What makes Member overloads powerful is that they provide members as guarded arguments so you candirectly start chaining validations. What’s better is when a member validation fails, the exceptionis still thrown for the original argument (same ParamName) but also with a clear error messagethat contains the actual member’s name. 1234var address = new Address { City = null };var buyer = new Person { Age = 18, Address = address };var car = new Car(&quot;Dodge&quot;, &quot;Power Wagon&quot;);BuyCar(buyer, car); The above code throws an ArgumentException with the parameter name “buyer” and message“Address.City cannot be null.”. Keep in mind that member validations require building MemberExpressions. Even though thecompiled delegates get cached and reused, creating expression trees may still be expensive for yourparticular application. State GuardsAlong with its arguments, a method may also need to validate the state of the instance it belongsto. Guard currently provides three validations to handle these cases: Operation Throws an InvalidOperationException when the first parameter (valid) is passed false. A custom message can be specified using the second parameter (message). A third parameter marked with [CallerMemberName] exists to retrieve the invoked method’s name. 1234567// Throws an InvalidOperationException with the message:// &quot;TestOperation call is not valid due to the current state of the object.&quot;Guard.Operation(false);// Throws an InvalidOperationException with the message:// &quot;Custom message.&quot;Guard.Operation(false, &quot;Custom message.&quot;); Support Throws a NotSupportedException when the first parameter (supported) is passed false. A custom message can be specified using the second parameter (message). A third parameter marked with [CallerMemberName]] exists to retrieve the invoked method’s name. 1234567// Throws a NotSupportedException with the message:// &quot;TestSupport is not supported&quot;Guard.Support(false);// Throws a NotSupportedException with the message:// &quot;Custom message.&quot;Guard.Support(false, &quot;Custom message.&quot;); Disposal Throws an ObjectDisposedException when the first parameter (disposed) is passed true. The object name can be specified using the second parameter (objectName). A custom message can be specified using the third parameter (message). 1234567891011// Throws an ObjectDisposedException with the message:// &quot;Cannot access a disposed object.&quot;Guard.Disposal(true);// Throws an ObjectDisposedException with the message:// &quot;Cannot access a disposed object.\\r\\nObject name: 'TestClass'.&quot;Guard.Disposal(true, nameof(TestClass));// Throws an ObjectDisposedException with the message:// &quot;Custom message.&quot;Guard.Disposal(true, nameof(TestClass), &quot;Custom message.&quot;); Guarding ScopesScopes can be created to intercept exceptions that are caused by failed validations. 12345678910111213void Foo(){ using (Guard.BeginScope((ex, stackTrace) =&gt; _logger.Log(stackTrace))) { Print(null); }}void Print(string message){ Guard.Argument(() =&gt; message).NotNull(); Console.WriteLine(message);} In the above example we create a scope with an exception interceptor that logs the stack traces offailed validations. When we call Print with a null argument, NotNull validation fails and anArgumentNullException is created. This exception is passed to the interceptor right before it isthrown. Since the exception hasn’t been thrown yet, its StackTrace property is null at the point ofinterception. This is why the stack trace is passed as a separate argument to the interceptordelegate. Scopes are implemented using AsyncLocal&lt;T&gt;, so they are bound to the execution context.This makes them available to use on asynchronous code. The existence of a scope is checked only when a validation fails, so this has no performanceoverhead for successful validations. Scopes can be nested and by default, the exceptions bubble-up to parent scopes. BeginScopeaccepts a second, optional parameter that can be used to disable this behavior. Scopes do not have to end. You can create one in Main and not dispose it to provide anapplication-wide scope; or in the BeginRequest of an ASP.NET application to provide arequest-wide scope. ExtensibilityThis document describes how to add custom validations to Guard by writing simple extension methods. A Basic Validation Here is a basic extension that throws an ArgumentException if a GUID argument is passeduninitialized. It is not included among the standard validations because the NotDefault methoddefined for structs covers its functionality. 123456789101112131415161718192021222324public static class GuardExtensions{ public static ref readonly Guard.ArgumentInfo&lt;Guid&gt; NotEmpty( in this Guard.ArgumentInfo&lt;Guid&gt; argument) { if (argument.Value == default) // Check whether the GUID is empty. { throw Guard.Fail(new ArgumentException( $&quot;{argument.Name} is not initialized. &quot; + &quot;Consider using the static Guid.NewGuid method.&quot;, argument.Name)); } return ref argument; }}public class Program{ public Record GetRecord(Guid id) { Guard.Argument(() =&gt; id).NotEmpty(); }} What Did We Do? We wrote an extension method for ArgumentInfo&lt;Guid&gt;. We accepted the argument as a readonly referenceand returned the same reference. We passed the argument name to the ArgumentException, also mentioning it in the exception message. We passed the exception to Guard.Fail before throwing it to support scopes. What if the argument was nullable? 123456789101112public class Program{ public Record GetRecord(Guid? id) { // This won't compile since the id is not a Guid, it's a Nullable&lt;Guid&gt;. Guard.Argument(() =&gt; id).Valid(); // Calling NotNull converts the ArgumentInfo&lt;Guid?&gt; to an ArgumentInfo&lt;Guid&gt;. // After that we can use our NotEmpty extension. Guard.Argument(() =&gt; id).NotNull().NotEmpty(); }} But forcing the argument to be non-null contradicts the convention followed by the standard validations where null arguments are ignored. Let’s add an overload to our extension, this time specifically for nullable GUIDs. 1234567891011121314151617181920212223242526public static class GuardExtensions{ public static ref readonly Guard.ArgumentInfo&lt;Guid?&gt; NotEmpty( in this Guard.ArgumentInfo&lt;Guid?&gt; argument) { if (argument.HasValue() &amp;&amp; // Ignore if the GUID is null. argument.Value.Value == default) // Check whether the GUID is empty. { throw Guard.Fail(new ArgumentException( $&quot;{argument.Name} is not initialized. &quot; + &quot;Consider using the static Guid.NewGuid method.&quot;, argument.Name)); } return ref argument; }}public class Program{ public Record GetRecord(Guid? id) { // Ignored if `id` is null. Guard.Argument(() =&gt; id).NotEmpty(); }} What Did We Do? We wrote an extension method for ArgumentInfo&lt;Guid?&gt;. We used the HasValue method to check whether the GUID is null. We ignored the arguments that are null. The rest is the same with our non-nullable validation. Accepting and Returning the Argument by Reference Being a struct, ArgumentInfo&lt;T&gt; is subject to copy-by-value semantics. This means that it wouldget copied once to send it as a parameter, and once to return it to the caller with each validation.Think of a validation chain like .NotNull().CountInRange(1, 5).DoesNotContainNull().This would cause our argument instance to be copied six times if we didn’t accept and returnedit as reference. Sending and returning values as reference add a small overhead but it’s negligible for valuesheavier than four bytes and the benefits start to overweight this overhead as the value gets bigger.An ArgumentInfo&lt;T&gt; instance contains three fields: The value of the argument of type T. A string that contains the argument name. A boolean that is used to determine whether the argument is modified. A boolean that is used to determine whether the exception messages should not contain sensitive information. So an ArgumentInfo&lt;int&gt; instance on a 32-bit system is at least 10 bytes and anArgumentInfo&lt;long&gt; instance on a 64-bit system is at least 18 bytes. Even more if we use heavierstructs like a Guid or decimal. So accepting and returning our validation arguments as referenceallows us to avoid copying heavier instances around. The HasValue Method In our examples above where we specifically targeted GUID arguments, we could just check whether theargument is null by writing argument.Value != null. Using argument.HasValue() here made nodifference. But if we targeted a generic argument T where T is a struct, the argument.Value != null checkwould cause boxing. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public interface IDuck{ bool CanQuack { get; } string Quack();}public class RefDuck : IDuck { /*...*/ }public struct ValueDuck : IDuck { /*...*/ }public static class GuardExtensions{ public static ref readonly Guard.ArgumentInfo&lt;T&gt; CanQuack&lt;T&gt;( in this Guard.ArgumentInfo&lt;T&gt; argument) where T : IDuck { // Writing `argument.Value != null` here would box a `ValueDuck`. if (argument.HasValue() &amp;&amp; !argument.Value.CanQuack) { // Throw is it is a non-null duck who sadly cannot quack. throw Guard.Fail(new ArgumentException( $&quot;{argument.Name} must be able to quack.&quot;, argument.Name)); } return ref argument; }}public class Program{ public static void Main() { var refDuck = new RefDuck(); MakeItQuack(refDuck); var valueDuck = new ValueDuck(); MakeItQuack(valueDuck); // No boxing. } public static void MakeItQuack&lt;T&gt;(T duck) where T : IDuck { Guard.Argument(() =&gt; duck).CanQuack(); Console.WriteLine(duck.Quack()); }} Reference(s)Most of the information in this article has gathered from various references. https://github.com/safakgur/guard","link":"/the-dotnet-world-guard/"},{"title":"The .NET World - Mixin","text":"In object-oriented programming, a mixin is a type that contains methods for use by other classes without having to be the parent class of those other classes. C# does not natively support mixins, but developers have devised various ways to mimic this functionality. Pros: Code Reusability: Mixins can encapsulate behaviour that can be reused across different classes. It promotes the DRY (Don’t Repeat Yourself) principle. Code Organization: Mixins allow us to separate different functionalities into different classes, making the code easier to read and maintain. Flexibility: Unlike inheritance, where a class can only inherit from a single class, a class can mix in multiple other classes, providing more flexibility. Avoiding Class Explosion: In languages or scenarios where multiple inheritances are not allowed or lead to complexity, mixins can add class functionality without creating new subclasses for every possible combination of behaviours. Cons: Complexity: Mixins can increase complexity, as it may take time to determine where a particular method or property is defined. Using multiple mixins can lead to problems understanding the flow and interaction of different class functionalities. Conflicts: If two mixins implement a method with the same name, it can lead to naming conflicts. This could lead to unexpected behaviour if not properly managed. Indirection: Mixins introduce an additional level of indirection, making code harder to understand and debug. Lack of Explicit Support in C#: As C# does not natively support mixins, the workaround solutions (like using extension methods on interfaces) may not be as clean and straightforward as in languages that support them directly. This may lead to additional complexity or misuse. So, the need for mixins comes from the requirement of sharing functionality across classes that do not share a common parent in the class hierarchy outside of the base object class. They can be a powerful tool when used properly but can lead to confusion and complexity when misused. In this article, we will explore four methods of implementing mixins in C#: Stateless mixins using extension methods Stateless mixins using default interface methods Stateful mixins using extension methods Stateful mixins using default interface methods 1. Stateless Mixins with Extension MethodsThe first method employs extension methods to add behaviour to classes that implement a specific interface, often called a “marker interface”. Here’s an example of a mixin named IPrintable, which provides a Print method: 123456789public interface IPrintable { }public static class PrintableExtensions{ public static void Print(this IPrintable printable, string message) { Console.WriteLine(message); }} We can apply this mixin to any class: 1public class MyClass : IPrintable { } And then utilize the Print method: 12var myObject = new MyClass();myObject.Print(&quot;Hello, world!&quot;); // Outputs &quot;Hello, world!&quot; This approach cannot add properties or state to the mixin because C# does not support extension properties. 2. Stateless Mixins with Default Interface MethodsIn C# 8.0, default interface methods were introduced. These allow us to define methods with a default implementation directly in the interface itself, creating an opportunity to build mixins. Here’s an example: 1234567public interface IPrintable{ void Print(string message) { Console.WriteLine(message); }} Now any class implementing IPrintable can call the Print method: 1234public class MyClass : IPrintable { }var myObject = new MyClass();myObject.Print(&quot;Hello, world!&quot;); // Outputs &quot;Hello, world!&quot; This method allows properties to be added directly to the interface. However, these properties cannot hold any state: 123456789public interface IPrintable{ string Creator { get; set; } void Print(string message) { Console.WriteLine(message); }} Any class that implements IPrintable will have a Creator property and a Print method. 3. Stateful Mixins with Extension MethodsWe can use the ConditionalWeakTable class for stateful mixins using extension methods, which lets us associate additional data with class instances without altering the class itself. This approach uses a marker interface and a static extension class, with the ConditionalWeakTable holding the state of the mixin. The ConditionalWeakTable&lt;TKey, TValue&gt; is used in stateful mixins in C# because it holds weak references to its keys, allowing them to be garbage collected when no other strong references exist. Unlike a regular Dictionary, where keys (and associated values) are kept in memory as long as the dictionary exists, potentially causing memory leaks or undesired extension of object lifetimes, ConditionalWeakTable allows the garbage collector to automatically remove the entries when the key objects are collected, thus ensuring more efficient memory usage and preventing unintentional lifetime extension of the associated objects. This makes it a preferred choice for associating state with objects in mixins. Here’s an example of a stateful IPrintable mixin, which keeps track of the number of times Print has been called: 12345678910111213141516171819public interface IPrintable { }public static class PrintableExtensions{ private sealed class PrintableState { internal int PrintCount; } private static readonly ConditionalWeakTable&lt;IPrintable, PrintableState&gt; stateTable = new ConditionalWeakTable&lt;IPrintable, PrintableState&gt;(); public static void Print(this IPrintable printable, string message) { var state = stateTable.GetOrCreateValue(printable); state.PrintCount++; Console.WriteLine($&quot;{message} (Printed {state.PrintCount} times)&quot;); }} This mixin can be used in the same way as previous ones, but the Print method now has a state: 123var myObject = new MyClass();myObject.Print(&quot;Hello, world!&quot;); // Outputs &quot;Hello, world! (Printed 1 times)&quot;myObject.Print(&quot;Hello again!&quot;); // Outputs &quot;Hello again! (Printed 2 times)&quot; While properties cannot hold a state due to the lack of support for extension properties, properties can be simulated through methods: 12345678910public static void SetCreator(this IPrintable printable, string creator){ // Save the creator}public static string GetCreator(this IPrintable printable){ // Retrieve and return the creator return &quot;Placeholder&quot;; } 4. Stateful Mixins with Default Interface MethodsFinally, stateful mixins can be implemented using default interface methods, and a similar ConditionalWeakTable technique as before. Here’s a more complex example of an IPrintable interface with multiple methods and properties: 12345678910111213141516171819202122232425262728public interface IPrintable{ private sealed class PrintableState { internal int PrintCount; internal int ErrorCount; } private static readonly ConditionalWeakTable&lt;IPrintable, PrintableState&gt; stateTable = new ConditionalWeakTable&lt;IPrintable, PrintableState&gt;(); string Creator { get; set; } string DocumentName { get; set; } void Print(string message) { var state = stateTable.GetOrCreateValue(this); state.PrintCount++; Console.WriteLine($&quot;{message} (Printed {state.PrintCount} times)&quot;); } void Error(string message) { var state = stateTable.GetOrCreateValue(this); state.ErrorCount++; Console.WriteLine($&quot;{message} (Error number {state.ErrorCount})&quot;); }} Now, Creator and DocumentName are regular properties and can hold state as long as the IPrintable instance exists: 1234567IMixinExample myClass = new MyClass();myClass.Creator = &quot;John Doe&quot;;myClass.DocumentName = &quot;My First Document&quot;;Console.WriteLine(myClass.Creator); // Outputs &quot;John Doe&quot;Console.WriteLine(myClass.DocumentName); // Outputs &quot;My First Document&quot;myClass.Print(&quot;Hello, world!&quot;); // Outputs &quot;Hello, world! (Printed 1 times)&quot;myClass.Error(&quot;Something went wrong.&quot;); // Outputs &quot;Something went wrong. (Error number 1)&quot; As shown, it’s possible to develop fairly complex and feature-rich mixins in C# despite the limitations regarding mixin implementation. Depending on your specific use case, these methods can offer a powerful way to add functionality to your classes. ConclusionWhile C# does not natively support mixins, various methods exist to imitate them. Each technique has its own strengths and weaknesses, so the best choice depends on the specific use case. However, with a little ingenuity, mixins can become a potent tool in your C# toolbox. Reference(s)Most of the information in this article has been gathered from various references. https://learn.microsoft.com/en-us/dotnet/csharp/advanced-topics/interface-implementation/mixins-with-default-interface-methods https://www.c-sharpcorner.com/article/learn-about-mixin-pattern/ https://www.c-sharpcorner.com/UploadFile/b942f9/how-to-create-mixin-using-C-Sharp-4-0/","link":"/the-dotnet-world-mixin/"},{"title":"Using Puppeteer with Mocha&#x2F;Jest and Aurelia 2","text":"What is Puppeteer? Puppeteer is a Node library which provides a high-level API to control Chrome or Chromium over the DevTools Protocol. Puppeteer runs headless by default, but can be configured to run full (non-headless) Chrome or Chromium. Most things that you can do manually in the browser can be done using Puppeteer! Here are a few examples to get you started: Generate screenshots and PDFs of pages. Crawl a SPA (Single-Page Application) and generate pre-rendered content (i.e. “SSR” (Server-Side Rendering)). Automate form submission, UI testing, keyboard input, etc. Create an up-to-date, automated testing environment. Run your tests directly in the latest version of Chrome using the latest JavaScript and browser features. Capture a timeline trace of your site to help diagnose performance issues. Test Chrome Extensions. What browsers are supported?After version 3.0, Puppeteer supports Firefox in addition to the Chrome browser. Puppeteer, Mocha &amp; Aurelia 2 (Typescript) integrationHow to set it up is as follows: 1- Run the following command in your terminal 1npx makes aurelia 2- Make your Custom Aurelia 2 App with these options Typescript Mocha + Chai Don’t choose Cypress for e2e testing, we will set Puppeteer up soon! 3- Install the following Node packages 1npm install puppeteer @types/puppeteer ts-node -D 4- Create the ts_hook.js file beside tsconfig.json in the root folder then copy the below snippet code into it. 123456require(&quot;ts-node&quot;).register({ // project: &quot;./tsconfig-e2e.json&quot;, compilerOptions: { module: &quot;commonjs&quot;, },}); As you see, you can use project option to define a separated tsconfig just for using E2E test instead of defining compilerOptions but the most important thing to consider is set module to commonjs otherwise you will get an Cannot use import statement outside a module error (Does not matter choose which one). 5- Create my-app.e2e.ts file inside test folder and copy the following code 12345678910111213141516171819202122232425262728293031import { expect } from &quot;chai&quot;;import puppeteer from &quot;puppeteer&quot;;describe(&quot;Duck Duck Go search using basic Puppeteer&quot;, () =&gt; { let browser; let page; beforeEach(async () =&gt; { browser = await puppeteer.launch(); page = await browser.newPage(); await page.goto(&quot;https://duckduckgo.com&quot;); }); afterEach(async () =&gt; { await browser.close(); }); it(&quot;should have the correct page title&quot;, async () =&gt; { expect(await page.title()).to.eql(&quot;DuckDuckGo — Privacy, simplified.&quot;); }); it(&quot;should show a list of results when searching actual word&quot;, async () =&gt; { await page.type(&quot;input[id=search_form_input_homepage]&quot;, &quot;puppeteer&quot;); await page.click('input[type=&quot;submit&quot;]'); await page.waitForSelector(&quot;h2 a&quot;); const links = await page.evaluate(() =&gt; { return Array.from(document.querySelectorAll(&quot;h2 a&quot;)); }); expect(links.length).to.be.greaterThan(0); });}); This code is a very simple and classic sample to start using Puppeteer. (Not related to Aurelia) 6- Open package.json and append the below script to scripts block. 1&quot;test:e2e&quot;: &quot;node ./node_modules/mocha/bin/mocha --require ./ts_hook.js --timeout=30000 test/**/*.e2e.ts&quot; As you see, we have filtered the files in test folder that ends with .e2e.ts for E2E testing and using Puppeteer. 7- To run tests, execute the below command. 1npm run test:e2e Puppeteer, Jest &amp; Aurelia 2 (Typescript) integrationSOON! Congrats.","link":"/using-puppeteer-with-mocha-or-jest-and-aurelia-2/"},{"title":"Write a custom plugin with Aurelia 2 and Lerna","text":"In this article, We want to write a simple Bootstrap 5 plugin for Aurelia 2 and manage our packages via Lerna. With help of my friend, Sayan, I want to discuss about writing a custom plugin. At the end, you will have a good knowledge to write your own plugins, so stay tuned. What is Bootstrap? Bootstrap is the most popular CSS Framework for developing responsive and mobile-first websites. The main purpose of this article is to create a component of Bootstrap 5 as a plugin for Aurelia 2. What is Lerna? A tool for managing JavaScript projects with multiple packages.Splitting up large codebases into separate independently versioned packages is extremely useful for code sharing. However, making changes across many repositories is messy and difficult to track, and testing across repositories becomes complicated very quickly.To solve these (and many other) problems, some projects will organize their codebases into multi-package repositories (sometimes called monorepos). To achieve the ultimate goal of this article, we will create our project in the form of monorepos. What is a plugin? In computing, a plug-in (or plugin, add-in, addin, add-on, or addon) is a software component that adds a specific feature to an existing computer program. When a program supports plug-ins, it enables customization. I want the user to be able to customize their requirements while using this plugin so in the following we will examine how to add config to our plugin. Aurelia 1 vs Aurelia 2Aurelia 1 Writing a new Aurelia Plugin is not difficult but it requires a lot of work that you can read through here. To be honest, it was not really straightforward! 1234567891011// src/main(.js|.ts)export function configure(aurelia: Aurelia): void {aurelia.use.plugin(PLATFORM.moduleName('bootstrap-v5'));// OR// aurelia.use.plugin(PLATFORM.moduleName('bootstrap-v5/button')); aurelia.start() .then(() =&gt; aurelia.setRoot(PLATFORM.moduleName('app')));} Aurelia 2 In version 2, everything is straightforward, just introduce the items you export to the register method. In fact, everything is possible by the register method so we will see how it works. 123456789101112// main.tsimport Aurelia from 'aurelia';import { App } from './app';import * as BsComponents from 'bootstrap-v5';Aurelia .register( BsComponents // This globalizes all the exports. ) .app(App) .start(); The structureWe want to separate our plugin in three packages. bootstrap-v5-core We will add the Bootstrap 5 configurations in this package. bootstrap-v5 Our Bootstrap 5 components will define in this package. bootstrap-v5 depends bootstrap-v5-core packages. demo We will use our plugin in this package as a demo. demo depends on bootstrap-v5-core and bootstrap-v5. Lerna configurationTo config your monorepos, you should do as following: Install Lerna as a global tool. 1npm i lerna -g Go to a folder that you want to make project and run 1lerna init The result should contain packages: The folder you will create your repositories there. lerna.json: Lerna’s configuration file. package.json: Node’s configuration file. Open your packages folder and install the projects inside it. 123npx makes aurelia bootstrap-v5-core -s typescriptnpx makes aurelia bootstrap-v5 -s typescriptnpx makes aurelia demo -s typescript After creating, delete all files inside src folders of bootstrap-v5-core and bootstrap-v5. We will add our files there. To continue we need to config Lerna, Open your lerna.json and paste the followimg code: 12345678910{ &quot;version&quot;: &quot;0.1.0&quot;, &quot;npmClient&quot;: &quot;npm&quot;, &quot;command&quot;: { &quot;bootstrap&quot;: { &quot;hoist&quot;: &quot;**&quot; } }, &quot;packages&quot;: [&quot;packages/*&quot;]} version: the current version of the repository. npmClient: an option to specify a specific client to run commands with (this can also be specified on a per command basis). Change to “yarn” to run all commands with yarn. Defaults to “npm”. command.bootstrap.hoist: Common dependencies will be installed only to the top-level node_modules, and omitted from individual package node_modules. packages: Array of globs to use as package locations. DependenciesAs described in the structure section defined packages depend on each other. So, we link them together and add the other prerequisites for each. bootstrap-v5-core This package has no dependency. bootstrap-v5 Go to package.json and add the following dependencies: 123456// bootstrap-v5/package.json&quot;dependencies&quot;: { &quot;aurelia&quot;: &quot;dev&quot;, &quot;bootstrap&quot;: &quot;^5.0.0-alpha2&quot;, &quot;bootstrap-v5-core&quot;: &quot;0.1.0&quot;}, demo Go to package.json and add the following dependencies 123456// demo/package.json&quot;dependencies&quot;: { &quot;aurelia&quot;: &quot;dev&quot;, &quot;bootstrap-v5-core&quot;: &quot;0.1.0&quot;, &quot;bootstrap-v5&quot;: &quot;0.1.0&quot;}, Note: All created packages have 0.1.0 version so pay attention if the version changes, update it in other packages. Finally, run the below command inside your root folder (where lerna.json is) to install packages. 1lerna bootstrap Plugin configurationGo to the src folder of bootstrap-v5-core package and create each of below files there. Size As I mentioned before, I want to write a configurable Bootstrap plugin so create src/Size.ts file. 1234567export enum Size { ExtraSmall = 'xs', Small = 'sm', Medium = 'md', Large = 'lg', ExtraLarge = 'xl',} I made a Size enum to handle all Bootstrap sizes. Next we can manage our components according to size value. Global Bootstrap 5 Options Create src/IGlobalBootstrapV5Options.ts file. 1234567import { Size } from &quot;./Size&quot;;export interface IGlobalBootstrapV5Options { defaultSize?: Size;}export const defaultOptions: IGlobalBootstrapV5Options = { defaultSize: Size.Medium}; You need to define your configs via an interface With its default values as a constant. DI Create src/BootstrapV5Configuration.ts file. 12345678910111213141516171819import { DI, IContainer, Registration } from &quot;aurelia&quot;;import { IGlobalBootstrapV5Options, defaultOptions } from './IGlobalBootstrapV5Options';export const IBootstrapV5Options = DI.createInterface&lt;IGlobalBootstrapV5Options&gt;('IBootstrapV5Options').noDefault();function createIBootstrapV5Configuration(optionsProvider: (options: IGlobalBootstrapV5Options) =&gt; void) { return { optionsProvider, register(container: IContainer) { optionsProvider(defaultOptions); return container.register(Registration.instance(IBootstrapV5Options, defaultOptions)) }, customize(cb?: (options: IGlobalBootstrapV5Options) =&gt; void) { return createIBootstrapV5Configuration(cb ?? optionsProvider); }, };}export const BootstrapV5Configuration = createIBootstrapV5Configuration(() =&gt; {}); We can define our IGlobalBootstrapV5Options to DI container so this happened via IBootstrapV5Options constant. createIBootstrapV5Configuration is the most important part of creating settings. register(container: IContainer) helps us to introduce our default config to DI container. customize(cb?: (options: IGlobalBootstrapV5Options) =&gt; void) alse helps us to introduce our custom config to the DI container. Finally, we should export our current configuration with default options via BootstrapV5Configuration. Exports Create src/index.ts file. 123export * from './BootstrapV5Configuration';export * from './IGlobalBootstrapV5Options';export * from './Size'; Create new index.ts file inside bootstrap-v5-core package. 1export * from './src'; Plugin implementationGo to the src folder of bootstrap-v5 package, create a button folder then create each of below files there. Resource Create resource.d.ts file. 123456789101112131415declare module '*.html' { import { IContainer } from '@aurelia/kernel'; import { IBindableDescription } from '@aurelia/runtime'; export const name: string; export const template: string; export default template; export const dependencies: string[]; export const containerless: boolean | undefined; export const bindables: Record&lt;string, IBindableDescription&gt;; export const shadowOptions: { mode: 'open' | 'closed'} | undefined; export function register(container: IContainer);}declare module '*.css';declare module '*.scss'; View Create bs-button.html file. 123&lt;button class=&quot;btn btn-primary&quot; ref=&quot;bsButtonTemplate&quot;&gt; Primary Button&lt;/button&gt; ViewModel Create bs-button.ts file. 123456789101112131415161718192021222324252627282930import { customElement, INode, containerless } from &quot;aurelia&quot;;import template from &quot;./bs-button.html&quot;;import { IBootstrapV5Options, IGlobalBootstrapV5Options, Size } from &quot;bootstrap-v5-core&quot;;@customElement({ name: &quot;bs-button&quot;, template })@containerlessexport class BootstrapButton { private bsButtonTemplate: Element; constructor( @IBootstrapV5Options private options: IGlobalBootstrapV5Options ) { } afterAttach() { if (this.options.defaultSize) { switch (this.options.defaultSize) { case Size.ExtraSmall: case Size.Small: this.bsButtonTemplate.classList.add(&quot;btn-sm&quot;); break; case Size.Large: case Size.ExtraLarge: this.bsButtonTemplate.classList.add(&quot;btn-lg&quot;); break; default: this.bsButtonTemplate.classList.remove(&quot;btn-sm&quot;, &quot;btn-lg&quot;); } } }} As you can see we are able to access to plugin options easy via ctor (DI) and react appropriately to its values. In this example I get the size from the user and apply it to the button component. Button Index Create src/button/index.ts file. 1export * from './bs-button'; Src Index Create src/index.ts file. 1export * from './button'; Global Index Create new index.ts file inside bootstrap-v5 package. 12import 'bootstrap/dist/css/bootstrap.min.css';export * from './src'; Plugin usageOpen demo package and go to the src and update main.ts. 1234567891011121314151617import Aurelia from 'aurelia';import { MyApp } from './my-app';import { BootstrapV5Configuration, Size } from 'bootstrap-v5-core';// import { BootstrapButton } from 'bootstrap-v5';import * as BsComponents from 'bootstrap-v5';Aurelia //.register(BootstrapButton) .register(BsComponents) //.register(BootstrapV5Configuration) .register(BootstrapV5Configuration.customize((options) =&gt; { options.defaultSize = Size.Small })) .app(MyApp) .start(); Importing is available for whole components 1import * as BsComponents from 'bootstrap-v5'; Or just a component 1import { BootstrapButton } from 'bootstrap-v5'; To register your components you should add them to register method. 123.register(BsComponents) // For whole components// Or.register(BootstrapButton) // For a component Proudly, we support configuration so we should introduce it to register method too. 1234 // With default options.register(BootstrapV5Configuration)// Or with a custom option.register(BootstrapV5Configuration.customize((options) =&gt; { options.defaultSize = Size.Small })) Now, You are able to use your bs-button inside src/my-app.html. 12&lt;div class=&quot;message&quot;&gt;${message}&lt;/div&gt;&lt;bs-button&gt;&lt;/bs-button&gt; To run the demo easily, go to the root folder (where lerna.json is) and add the following script to package.json. 123&quot;scripts&quot;: { &quot;start&quot;: &quot;lerna run start --stream --scope demo&quot;} Then, call the command 1npm start Enjoy!","link":"/write-a-custom-plugin-with-aurelia-2-and-lerna/"}],"tags":[{"name":"dotnet","slug":"dotnet","link":"/tags/dotnet/"},{"name":"aspnetcore","slug":"aspnetcore","link":"/tags/aspnetcore/"},{"name":"webapi","slug":"webapi","link":"/tags/webapi/"},{"name":"backgroundtask","slug":"backgroundtask","link":"/tags/backgroundtask/"},{"name":"hostedservices","slug":"hostedservices","link":"/tags/hostedservices/"},{"name":"cache","slug":"cache","link":"/tags/cache/"},{"name":"caching","slug":"caching","link":"/tags/caching/"},{"name":"inmemory","slug":"inmemory","link":"/tags/inmemory/"},{"name":"distributed","slug":"distributed","link":"/tags/distributed/"},{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"sqlserver","slug":"sqlserver","link":"/tags/sqlserver/"},{"name":"cors","slug":"cors","link":"/tags/cors/"},{"name":"di","slug":"di","link":"/tags/di/"},{"name":"ioc","slug":"ioc","link":"/tags/ioc/"},{"name":"dryioc","slug":"dryioc","link":"/tags/dryioc/"},{"name":"api","slug":"api","link":"/tags/api/"},{"name":"polly","slug":"polly","link":"/tags/polly/"},{"name":"refit","slug":"refit","link":"/tags/refit/"},{"name":"resiliency","slug":"resiliency","link":"/tags/resiliency/"},{"name":"featuremanagement","slug":"featuremanagement","link":"/tags/featuremanagement/"},{"name":"feature","slug":"feature","link":"/tags/feature/"},{"name":"featureflag","slug":"featureflag","link":"/tags/featureflag/"},{"name":"validation","slug":"validation","link":"/tags/validation/"},{"name":"fluentvalidation","slug":"fluentvalidation","link":"/tags/fluentvalidation/"},{"name":"exception","slug":"exception","link":"/tags/exception/"},{"name":"middleware","slug":"middleware","link":"/tags/middleware/"},{"name":"healthy","slug":"healthy","link":"/tags/healthy/"},{"name":"unhealthy","slug":"unhealthy","link":"/tags/unhealthy/"},{"name":"health","slug":"health","link":"/tags/health/"},{"name":"healthcheck","slug":"healthcheck","link":"/tags/healthcheck/"},{"name":"localization","slug":"localization","link":"/tags/localization/"},{"name":"profiler","slug":"profiler","link":"/tags/profiler/"},{"name":"miniprofiler","slug":"miniprofiler","link":"/tags/miniprofiler/"},{"name":"paging","slug":"paging","link":"/tags/paging/"},{"name":"pagination","slug":"pagination","link":"/tags/pagination/"},{"name":"fakedata","slug":"fakedata","link":"/tags/fakedata/"},{"name":"bogus","slug":"bogus","link":"/tags/bogus/"},{"name":"testdata","slug":"testdata","link":"/tags/testdata/"},{"name":"masstransit","slug":"masstransit","link":"/tags/masstransit/"},{"name":"rabbitmq","slug":"rabbitmq","link":"/tags/rabbitmq/"},{"name":"easynetq","slug":"easynetq","link":"/tags/easynetq/"},{"name":"amqp","slug":"amqp","link":"/tags/amqp/"},{"name":"queue","slug":"queue","link":"/tags/queue/"},{"name":"messagebroker","slug":"messagebroker","link":"/tags/messagebroker/"},{"name":"ratelimit","slug":"ratelimit","link":"/tags/ratelimit/"},{"name":"security","slug":"security","link":"/tags/security/"},{"name":"header","slug":"header","link":"/tags/header/"},{"name":"log","slug":"log","link":"/tags/log/"},{"name":"openapi","slug":"openapi","link":"/tags/openapi/"},{"name":"swagger","slug":"swagger","link":"/tags/swagger/"},{"name":"versioning","slug":"versioning","link":"/tags/versioning/"},{"name":"file","slug":"file","link":"/tags/file/"},{"name":"upload","slug":"upload","link":"/tags/upload/"},{"name":"pipeline","slug":"pipeline","link":"/tags/pipeline/"},{"name":"request","slug":"request","link":"/tags/request/"},{"name":"response","slug":"response","link":"/tags/response/"},{"name":"model","slug":"model","link":"/tags/model/"},{"name":"binding","slug":"binding","link":"/tags/binding/"},{"name":"modelbinding","slug":"modelbinding","link":"/tags/modelbinding/"},{"name":"rss","slug":"rss","link":"/tags/rss/"},{"name":"aurelia2","slug":"aurelia2","link":"/tags/aurelia2/"},{"name":"tailwindcss","slug":"tailwindcss","link":"/tags/tailwindcss/"},{"name":"webpack","slug":"webpack","link":"/tags/webpack/"},{"name":"awesome","slug":"awesome","link":"/tags/awesome/"},{"name":"css-in-js","slug":"css-in-js","link":"/tags/css-in-js/"},{"name":"emotionjs","slug":"emotionjs","link":"/tags/emotionjs/"},{"name":"dotnet5","slug":"dotnet5","link":"/tags/dotnet5/"},{"name":"sourcegenerator","slug":"sourcegenerator","link":"/tags/sourcegenerator/"},{"name":"roslyn","slug":"roslyn","link":"/tags/roslyn/"},{"name":"csharp9","slug":"csharp9","link":"/tags/csharp9/"},{"name":"csharp","slug":"csharp","link":"/tags/csharp/"},{"name":"guard","slug":"guard","link":"/tags/guard/"},{"name":"mixon","slug":"mixon","link":"/tags/mixon/"},{"name":"extension-method","slug":"extension-method","link":"/tags/extension-method/"},{"name":"default-interface-method","slug":"default-interface-method","link":"/tags/default-interface-method/"},{"name":"test","slug":"test","link":"/tags/test/"},{"name":"e2e","slug":"e2e","link":"/tags/e2e/"},{"name":"end-to-end","slug":"end-to-end","link":"/tags/end-to-end/"},{"name":"puppeteer","slug":"puppeteer","link":"/tags/puppeteer/"},{"name":"mocha","slug":"mocha","link":"/tags/mocha/"},{"name":"chai","slug":"chai","link":"/tags/chai/"},{"name":"jest","slug":"jest","link":"/tags/jest/"},{"name":"plugin","slug":"plugin","link":"/tags/plugin/"},{"name":"lerna","slug":"lerna","link":"/tags/lerna/"},{"name":"bootstrap5","slug":"bootstrap5","link":"/tags/bootstrap5/"},{"name":"monorepository","slug":"monorepository","link":"/tags/monorepository/"}],"categories":[{"name":"aspnetcore-api","slug":"aspnetcore-api","link":"/categories/aspnetcore-api/"},{"name":"aspnetcore","slug":"aspnetcore","link":"/categories/aspnetcore/"},{"name":"aurelia","slug":"aurelia","link":"/categories/aurelia/"},{"name":"dotnet","slug":"dotnet","link":"/categories/dotnet/"}],"pages":[{"title":"About Me","text":"Hello! I’m a seasoned software developer with over a decade of experience in programming. I’ve spent my career broadening my skills in software development, keeping pace with the ever-evolving tech industry. My professional journey started in Iran, where I earned an Associate, Bachelor, and Master of Science in Computer Software Engineering. These formal educational endeavours shaped the foundation of my knowledge in the field, allowing me to cultivate my technical abilities and apply them in the real world. I’ve served in various capacities throughout my career, each role adding a unique facet to my skillset. From my early days as a Software Developer at Behpardaz Jahan to my tenure as a Senior Software Developer at the Iranian National Tax Administration (INTA), I honed my proficiency in Microsoft’s .NET ecosystem, JavaScript, TypeScript, and React. While working at INTA, I was crucial in projects like the Management Information System (MIS) application, Integrated Tax System (ITS), and a system to detect money-laundering activities. Each endeavour allowed me to apply my technical prowess, leadership skills, and innovative thinking to solve complex problems and contribute to significant national projects. My passion for ensuring the highest quality in software led me to a Quality Assurance (QA) Engineer role at Ringana GmbH in Austria. Here, I pioneered automated strategies to streamline testing processes, increase the precision and reliability of test results, and drive workflow efficiency. My technical expertise and my knack for problem-solving helped me create systems that reinforced the QA process. I am an Artificial Intelligence (AI) Engineer at Ringana GmbH. In this role, I implement AI-driven strategies to enhance the company’s operational workflows, revolutionizing business processes using Azure Cognitive Services and Azure OpenAI Service. I’m also proud to be a part of the open-source community, and my contributions are a testament to my ability to work as part of a team. I’m known for my creativity, technical acumen, determination, and unwavering commitment to pushing the boundaries of tech and helping my team reach our shared objectives. My hobbies reflect my passion for continuous learning and my curiosity about the world. I enjoy staying up-to-date with the latest technological advancements, actively contributing to open-source software projects, and writing technical articles to share my knowledge. Literature and entertainment form the lighter side of my interests, as I often find myself engrossed in renowned novels, the latest movies, TV series, and engaging computer games. In a nutshell, I’m a .NET guru, problem resolver, passionate self-learner, and dedicated team player. My multifaceted career and lifelong pursuit of knowledge have helped me become a well-rounded software developer. I continuously strive to drive innovation and achieve excellence in all my endeavours. Whether I’m on the job or off, I always seek to learn, grow, and contribute to the world of tech. You can find more about my contributions to the tech community on my GitHub account (https://github.com/HamedFathi). Let’s connect and create something amazing together!","link":"/about/index.html"}]}